:PROPERTIES:
:ID: DBBD0C4F-EA14-4684-7583-D78AAF7AABFF
:END:
#+title: Sprint Backlog 06
#+options: <:nil c:nil ^:nil d:nil date:nil author:nil toc:nil html-postamble:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED BLOCKED
#+tags: { code(c) infra(i) analysis(n) agile(a) }
#+startup: inlineimages

* Sprint Mission

- finish up all remaining tasks around domain entities.
- templatise domain entity generation.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :tags t :indent nil :emphasize nil :scope file :narrow 75 :formula % :block today
#+TBLNAME: today_summary
#+CAPTION: Clock summary at [2025-12-02 Tue 12:41], for Tuesday, December 02, 2025.
|       | <75>                                  |        |      |      |       |
| Tags  | Headline                              | Time   |      |      |     % |
|-------+---------------------------------------+--------+------+------+-------|
|       | *Total time*                          | *3:29* |      |      | 100.0 |
|-------+---------------------------------------+--------+------+------+-------|
|       | Stories                               | 3:29   |      |      | 100.0 |
|       | Active                                |        | 3:29 |      | 100.0 |
| agile | Sprint and product backlog refinement |        |      | 0:18 |   8.6 |
| infra | OCR scan notebooks for this sprint    |        |      | 1:29 |  42.6 |
| code  | Implement session cancellation        |        |      | 1:42 |  48.8 |
#+end:

#+begin: clocktable :maxlevel 3 :scope subtree :tags t :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+TBLNAME: sprint_summary
#+CAPTION: Clock summary at [2025-12-02 Tue 12:42]
|       | <75>                                  |        |      |      |       |
| Tags  | Headline                              | Time   |      |      |     % |
|-------+---------------------------------------+--------+------+------+-------|
|       | *Total time*                          | *3:29* |      |      | 100.0 |
|-------+---------------------------------------+--------+------+------+-------|
|       | Stories                               | 3:29   |      |      | 100.0 |
|       | Active                                |        | 3:29 |      | 100.0 |
| agile | Sprint and product backlog refinement |        |      | 0:18 |   8.6 |
| infra | OCR scan notebooks for this sprint    |        |      | 1:29 |  42.6 |
| code  | Implement session cancellation        |        |      | 1:42 |  48.8 |
#+end:

*** STARTED Sprint and product backlog refinement                     :agile:
    :LOGBOOK:
    CLOCK: [2025-12-02 Tue 10:54]--[2025-12-02 Tue 10:58] =>  0:04
    CLOCK: [2025-12-02 Tue 10:40]--[2025-12-02 Tue 10:54] =>  0:14
    :END:

Updates to sprint and product backlog.

#+begin_src emacs-lisp :exports none
;; agenda
(org-agenda-file-to-front)
#+end_src

#+name: pie-stories-chart
#+begin_src R :var sprint_summary=sprint_summary :results file graphics :exports results :file sprint_backlog_06_stories_pie_sorted.png :width 1920 :height 1080
library(conflicted)
library(ggplot2)
library(tidyverse)
library(tibble)

# Remove unnecessary rows (Total time, Stories, Active)
clean_sprint_summary <- tail(sprint_summary, -4)
stories <- unlist(clean_sprint_summary[2])
percent_values <- as.numeric(unlist(clean_sprint_summary[6]))

# Create a data frame and explicitly sort the stories by defining factor levels
df <- data.frame(
  stories = stories,
  percent = percent_values
) %>%
  # 1. Sort the data frame by percentage in descending order
  arrange(desc(percent)) %>%
  # 2. Convert 'stories' to a factor, setting the levels based on the sorted order.
  # This makes the order of the slices explicit for ggplot.
  mutate(
    stories = factor(stories, levels = stories),
    lab.pos = cumsum(percent) - 0.5 * percent
  )

# Manually selected colors to resemble the screenshot
custom_palette <- c(
  "#21518f", "#f37735", "#ffc425", "#81b214", "#d7385e",
  "#662e91", "#00a9ae", "#5c5c5c", "#a0c6e0", "#f8b195",
  "#ffe385", "#bde0fe", "#c5e0d4", "#e0b8a0", "#a56f8f",
  "#7a448a", "#4a9a9b", "#9b9b9b", "#6fa8dc", "#f7a072",
  "#ffd166", "#99d98c", "#ef5d60", "#9d529f", "#3a86ff",
  "#c1d6e1", "#f9e0ac", "#c2d6a4", "#e69a8d", "#a07d9f"
)

# Ensure the palette has enough colors for all stories.
if (length(custom_palette) < length(df$stories)) {
  warning("Not enough custom colors for all stories. Colors will repeat.")
  custom_palette <- rep(custom_palette, length.out = length(df$stories))
}


p <- ggplot(df, aes(x = "", y = percent, fill = stories)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  scale_fill_manual(values = custom_palette) +
  ggtitle("Sprint 5: Resourcing per Story")  +
  labs(x = NULL, y = NULL, fill = "Stories") +
  theme_minimal() +
  theme(
    axis.text.x = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    plot.title = element_text(hjust = 0.5, size = 18),
    legend.position = "right",
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)
  )

print(p)
#+end_src

#+RESULTS: pie-stories-chart
[[file:sprint_backlog_06_stories_pie_sorted.png]]

#+name: stories-chart
#+begin_src R :var sprint_summary=sprint_summary :results file graphics :exports results :file sprint_backlog_06_stories.png :width 1200 :height 650
library(conflicted)
library(grid)
library(tidyverse)
library(tibble)

# Remove unnecessary rows.
clean_sprint_summary <- tail(sprint_summary, -4)
names <- unlist(clean_sprint_summary[2])
values <- as.numeric(unlist(clean_sprint_summary[6]))

# Create a data frame.
df <- data.frame(
  cost = values,
  stories = factor(names, levels = names[order(values, decreasing = FALSE)]),
  y = seq(length(names)) * 0.9
)

# Setup the colors
blue <- "#076fa2"

p <- ggplot(df) +
  aes(x = cost, y = stories) +
  geom_col(fill = blue, width = 0.6) +
  ggtitle("Sprint 5: Resourcing per Story") +
  xlab("Resourcing (%)") + ylab("Stories") +
  theme(text = element_text(size = 15))

print(p)
#+end_src

#+RESULTS: stories-chart
[[file:sprint_backlog_06_stories.png]]

#+name: tags-chart
#+begin_src R :var sprint_summary=sprint_summary :results file graphics :exports results :file sprint_backlog_06_tags.png :width 600 :height 400
library(conflicted)
library(grid)
library(tidyverse)
library(tibble)

# Remove unnecessary rows.
clean_sprint_summary <- tail(sprint_summary, -4)
names <- unlist(clean_sprint_summary[1])
values <- as.numeric(unlist(clean_sprint_summary[6]))

# Create a data frame.
df <- data.frame(
  cost = values,
  tags = names,
  y = seq(length(names)) * 0.9
)
# factor(names, levels = names[order(values, decreasing = FALSE)])

df2 <- setNames(aggregate(df$cost, by = list(df$tags), FUN = sum),  c("cost", "tags"))
# Setup the colors
blue <- "#076fa2"

p <- ggplot(df2) +
  aes(x = cost, y = tags) +
  geom_col(fill = blue, width = 0.6) +
  ggtitle("Sprint 5: Resourcing per Tag") +
  xlab("Resourcing (%)") + ylab("Story types") +
  theme(text = element_text(size = 15))

print(p)
#+end_src

#+RESULTS: tags-chart
[[file:sprint_backlog_06_tags.png]]

[[file:sprint_backlog_05_plan.png]]

[[file:sprint_backlog_05_resources.png]]

*** STARTED OCR scan notebooks for this sprint                        :infra:
    :LOGBOOK:
    CLOCK: [2025-12-02 Tue 09:10]--[2025-12-02 Tue 10:39] =>  1:29
    :END :

We need to scan all of our finance notebooks so we can use them with AI. Each
sprint will have a story similar to this until we scan and process them all.

*** Add AI generated sprint summary                                   :infra:

At the end of the sprint, generate the sprint summary using the prompt.

*** STARTED Implement session cancellation                             :code:
    DEADLINE: <2025-12-10 Tue>
    :LOGBOOK:
    CLOCK: [2025-12-02 Tue 10:59]--[2025-12-02 Tue 12:41] =>  1:42
    :END:

When the server stops (via SIGINT or programmatic shutdown), all active
sessions currently continue running indefinitely, preventing clean shutdown.
The server needs to gracefully cancel all ongoing session I/O operations
without waiting indefinitely.

This is critical for production deployment where clean shutdown is required
for container orchestration, service restarts, and graceful degradation scenarios.

Acceptance criteria:
- Server can stop cleanly with multiple active sessions running
- All session I/O operations are cancelled when server::stop() is called
- No indefinite hangs during shutdown process
- Sessions log their cancellation for observability
- Existing cancellation architecture (cancellation_signal) is preserved
- Solution uses Asio's hierarchical cancellation model

- Tasks

  - [ ] Add root cancellation signal for sessions in server class
  - [ ] Expose cancellation slot method in server (get_session_cancellation_slot)
  - [ ] Pass cancellation slot to each new session in accept_loop
  - [ ] Update session constructor to accept and store cancellation slot
  - [ ] Bind all session I/O operations to the cancellation slot
  - [ ] Update server::stop() to emit session cancellation signal
  - [ ] Add session cleanup logging for operation_aborted cases
  - [ ] Write integration test with multiple concurrent sessions
  - [ ] Test shutdown behavior with Ctrl+C signal
  - [ ] Verify no resource leaks during cancellation

- Notes

  Implementation approach: Use hierarchical cancellation model where server
  owns a root cancellation signal and each session inherits a slot from this
  root signal. When server stops, it emits cancellation which propagates to
  all sessions automatically.

  Benefits:
  - No manual session tracking required
  - Automatic propagation via Asio's native cancellation
  - Thread-safe and idempotent
  - Composable with nested coroutines

  Files likely affected:
  - =projects/ores.comms/include/ores/comms/server.hpp= - Add session_stop_signal_
  - =projects/ores.comms/src/server.cpp= - Update accept_loop and stop()
  - =projects/ores.comms/include/ores/comms/session.hpp= - Add stop_slot_ member
  - =projects/ores.comms/src/session.cpp= - Update constructor and run()

**** Code review from Gemini

***** projects/ores.service/src/main.cpp

- priority: high
- Comment on lines +61 to +69:

#+begin_src c++
    // Install signal handlers to allow graceful shutdown
    // This prevents the default SIGINT/SIGTERM handlers from terminating
    // the process immediately, giving the server time to clean up
    boost::asio::signal_set signals(io_ctx, SIGINT, SIGTERM);
    signals.async_wait([&io_ctx](const boost::system::error_code&, int signal) {
        std::cout << "\nReceived signal " << signal << ", initiating shutdown..." << std::endl;
        // Don't stop io_context here - let the server's signal handler do the cleanup
        // The server will stop the io_context when it's done
    });
#+end_src

This new signal handler in main creates a race condition with the server's
internal signal handler (server::watch_for_stop_signals). Both handlers wait for
SIGINT/SIGTERM on the same io_context, but it's undefined which one will be
invoked. If this handler in main is triggered, it only prints a message and does
not initiate the server shutdown, which would prevent the graceful shutdown from
occurring.

The server's own signal handler is sufficient to both prevent immediate process
termination and trigger the graceful shutdown by calling server::stop(). Relying
on the server's handler alone will make the shutdown process more reliable.

Additionally, the comment on line 68 is slightly misleading. The server's stop()
method doesn't stop the io_context; it's stopped on line 75 after async_main
completes, which is the correct behavior.

***** projects/ores.comms/src/net/client.cpp

- priority: medium
- Comment on lines +259 to +263

#+begin_src c++
            {
                std::lock_guard guard{state_mutex_};
                connected_ = false;
            }
            BOOST_LOG_SEV(lg(), warn) << "Connection lost - server may have closed the connection";
#+end_src

To ensure the client is in a clean state after a read failure, it's good
practice to explicitly close the connection socket. A read failure, especially
one that results from the server closing the connection, means the connection is
no longer viable. This change makes the error handling here consistent with the
catch (=const boost::system::system_error& e=) block.

#+begin_src c++
            {
                std::lock_guard guard{state_mutex_};
                connected_ = false;
            }
            if (conn_) {
                conn_->close();
            }
            BOOST_LOG_SEV(lg(), warn) << "Connection lost - server may have closed the connection";
#+end_src

***** projects/ores.comms/tests/net_client_tests.cpp

- priority: medium
- Comment on lines +251 to +254

#+begin_src c++
        // We can verify by attempting to send a dummy request - it should fail
        // Note: This test primarily verifies that server->stop() successfully
        // cancelled all sessions without hanging, which is the main goal of
        // the session cancellation feature.
#+end_src

The comment here correctly identifies a way to strengthen this test. By adding
an explicit check to ensure clients can no longer communicate after the server
has been stopped, the test will more comprehensively verify the end-to-end
behavior of the session cancellation, including the effect on the client side.

#+begin_src c++
        // We can verify by attempting to send a dummy request - it should fail.
        BOOST_LOG_SEV(lg, info) << "Verifying clients can no longer communicate";
        for (auto& client : clients) {
            ores::comms::protocol::frame dummy_request{
                ores::comms::protocol::message_type::handshake_request, 0, {}};
            auto result = co_await client->send_request(dummy_request);
            CHECK(!result.has_value());
            CHECK(!client->is_connected());
        }
#+end_src


**** Old implementation plan from Qwen

  #+begin_src markdown
  Here's a **step-by-step implementation plan** to **cancel all active sessions
  when the server stops**‚Äîbuilding cleanly on your current Asio coroutine-based
  server design.

  ---

  ### üéØ Goal
  When `server::stop()` is called (e.g., via SIGINT or programmatic shutdown):
  1. **Immediately cancel** all ongoing session I/O operations (reads/writes, etc.).
  2. **Gracefully terminate** all sessions without waiting indefinitely.
  3. Preserve your existing cancellation architecture (based on `cancellation_signal`).

  ---

  ### ‚úÖ High-Level Strategy

  Use a **hierarchical cancellation model**:
  - The **server owns a root cancellation signal**.
  - Each **session inherits a slot** from this root signal.
  - When the server stops, it **emits cancellation**, which **propagates to all sessions**.

  This avoids manual session tracking and leverages Asio's built-in cancellation propagation.

  ---

  ## üìù Implementation Plan

  ### Step 1: Add a Root Cancellation Signal for Sessions
  In `server.hpp`, add:

  ```cpp
  private:
      boost::asio::cancellation_signal session_stop_signal_;
  ```

  > This signal will be used to cancel **all sessions** simultaneously.

  ---

  ### Step 2: Expose a Cancellation Slot to Sessions
  Add a **public (or private, if sessions are friends)** method:

  ```cpp
  public:
      boost::asio::cancellation_slot get_session_cancellation_slot() const noexcept {
          return session_stop_signal_.slot();
      }
  ```

  > Alternatively, make `session` a `friend class` and pass the slot directly in `accept_loop`.

  ---

  ### Step 3: Pass the Slot to Each Session
  In `accept_loop`, when creating a session:

  ```cpp
  auto sess = std::make_shared<session>(
      std::move(conn),
      options_.server_identifier,
      dispatcher_,
      get_session_cancellation_slot()  // ‚Üê pass the slot
  );
  ```

  > You'll need to **update `session`'s constructor** to accept and store this slot (or a copy of it).

  ---

  ### Step 4: Update `session` to Use the Cancellation Slot
  In `session.hpp`:

  ```cpp
  class session {
  public:
      session(
          std::unique_ptr<connection> conn,
          std::string server_id,
          std::shared_ptr<protocol::message_dispatcher> dispatcher,
          boost::asio::cancellation_slot stop_slot);  // ‚Üê new parameter

  private:
      boost::asio::cancellation_slot stop_slot_;
      // ... other members
  };
  ```

  In `session.cpp` constructor:

  ```cpp
  session::session(
      std::unique_ptr<connection> conn,
      std::string server_id,
      std::shared_ptr<protocol::message_dispatcher> dispatcher,
      boost::asio::cancellation_slot stop_slot)
      : conn_(std::move(conn))
      , server_id_(std::move(server_id))
      , dispatcher_(std::move(dispatchor))
      , stop_slot_(std::move(stop_slot)) {
  }
  ```

  ---

  ### Step 5: Bind Session I/O to the Cancellation Slot
  In `session::run()` or wherever you do `co_await socket.async_read(...)`:

  ```cpp
  // Example: reading from SSL stream
  co_await conn_->ssl_stream().async_read_some(
      buffer,
      boost::asio::bind_cancellation_slot(
          stop_slot_,
          boost::asio::use_awaitable));
  ```

  > Repeat for **all** async operations in the session (read, write, timers, etc.).

  This ensures that when the server emits cancellation, **all session I/O is aborted**.

  > üí° Tip: If you have a session-level read/write loop, you only need to bind the **outermost** `co_await`‚Äîcancellation will propagate.

  ---

  ### Step 6: Update `server::stop()` to Cancel Sessions Too
  Modify your existing `stop()`:

  ```cpp
  void server::stop() {
      BOOST_LOG_SEV(lg(), info) << "Stopping server...";

      // Cancel all sessions first
      session_stop_signal_.emit(boost::asio::cancellation_type::all);

      // Then cancel accept loop
      stop_signal_.emit(boost::asio::cancellation_type::all);
  }
  ```

  > Order doesn't strictly matter, but canceling sessions first is more logical.

  ---

  ### Step 7: (Optional) Add Session Cleanup Logging
  In `session::run()`, catch `operation_aborted` to log graceful exit:

  ```cpp
  try {
      co_await /* session work */;
  } catch (const boost::system::system_error& e) {
      if (e.code() == boost::asio::error::operation_aborted) {
          BOOST_LOG_SEV(lg(), debug) << "Session cancelled.";
      } else {
          BOOST_LOG_SEV(lg(), error) << "Session error: " << e.what();
      }
  }
  ```

  ---

  ### ‚úÖ Benefits of This Approach
  - **No manual session tracking** (no list of sessions to iterate over).
  - **Automatic propagation**: One `emit()` cancels everything.
  - **Safe and efficient**: Uses Asio's native cancellation.
  - **Composable**: Works with nested coroutines inside sessions.

  ---

  ### üîí Safety Notes
  - The `session_stop_signal_` lives as long as the `server` object.
  - Sessions capture a **slot**, not a reference to the signal‚Äîsafe even if the session outlives the emit (which it won't, because you're stopping the server).
  - No race conditions: `emit()` is thread-safe and idempotent.

  ---

  ### üß™ Testing
  1. Start server, open 2 connections.
  2. Send Ctrl+C.
  3. Verify:
     - "Stopping server..." log appears.
     - Both sessions log "Session cancelled." (or similar).
     - Program exits promptly.

  ---

  Let me know if you'd like the full code patches for `session.hpp/cpp` or help adapting this to your exact `connection`/`ssl_stream` usage!
  #+end_src

*** STARTED Experiment with simple code generation                     :code:
    :LOGBOOK:
    CLOCK: [2025-12-02 Tue 16:56]
    CLOCK: [2025-12-02 Tue 14:35]--[2025-12-02 Tue 16:05] =>  1:30
    :END:

It should be easy enough to add a simple code generator that creates the basic
infrastructure for a domain type, so that we don't have to waste Claude Code
tokens.

*** Add tests for messaging handler                                    :code:

We need tests in comms which create a test request and response and a test
handler.

*** Implement client heartbeat for proactive disconnect detection      :code:

Currently, the client only detects server disconnections when attempting to
send a request. If the server closes the connection (e.g., via graceful
shutdown), the client remains unaware until the next user action. This creates
poor user experience where the Qt application appears connected but operations
fail unexpectedly.

A heartbeat mechanism would allow the client to proactively detect when the
server closes the connection and notify the application immediately, enabling
proper UI updates (connection status indicators, reconnection prompts, etc.).

Business value:
- Improved user experience with immediate disconnect notifications
- Better error handling and recovery workflows
- Reduced user frustration from "silent" disconnections
- Foundation for future features (connection quality monitoring, auto-reconnect)

Acceptance criteria:
- Client sends periodic heartbeat/ping messages to server (configurable interval)
- Server responds to heartbeat messages with minimal overhead
- Client detects failed heartbeats and marks connection as disconnected
- Client provides callback/signal mechanism for disconnect notification
- Qt application can register disconnect callback to update UI
- Heartbeat can be enabled/disabled via client configuration
- Heartbeat does not interfere with normal request/response operations
- Logging clearly indicates heartbeat activity and failures

Implementation considerations:
- Add ping/pong message types to protocol (lightweight, no payload)
- Use async timer in client to trigger periodic heartbeats
- Heartbeat interval should be configurable (default: 30 seconds)
- Server should handle ping messages in message dispatcher
- Client should expose disconnect_callback_t for applications to register
- Ensure thread-safe callback invocation for Qt integration
- Consider making heartbeat optional to support existing clients

Files likely affected:
- =projects/ores.comms/include/ores.comms/protocol/messages.hpp= - Add ping/pong types
- =projects/ores.comms/include/ores.comms/net/client.hpp= - Add callback mechanism
- =projects/ores.comms/src/net/client.cpp= - Implement heartbeat coroutine
- =projects/ores.comms/src/protocol/message_dispatcher.cpp= - Handle ping messages
- =projects/ores.qt/...= - Register disconnect callback, update UI

Related to completed story: "Implement session cancellation" - that story
addresses graceful server shutdown, this story addresses client-side detection
of that shutdown.

*** Create a variability service for feature flags                     :code:

We should not expose the repository directly. Instead, consumers should use a
service interface which queries the repository as needed.

*** Add screen in qt to exit bootstrap mode                            :code:

As per claude:

The create_initial_admin_request message type serves several important purposes
that differentiate it from the CLI and REPL approaches:

Why We Need create_initial_admin_request

  1. Network-accessible bootstrap flow
  - Allows remote initial setup from localhost without requiring shell/CLI access
  to the server
  - Enables a web-based "first-run" setup experience (like many web applications)
  - The Qt client can provide a proper UI for initial admin account creation

  2. Localhost-only security enforcement
  - The endpoint enforces that it can only be called from localhost (127.0.0.1 or
  ::1) at line
  projects/ores.accounts/src/messaging/accounts_message_handler.cpp:320
  - Provides network-accessible bootstrap with security guarantees
  - Prevents remote bootstrap attacks

  3. Atomic mode transition
  - The endpoint both creates the admin AND exits bootstrap mode in a single atomic
   operation (lines 362-367 in accounts_message_handler.cpp)
  - Guarantees consistency - can't create admin without exiting bootstrap mode

  4. Service-layer validation
  - Goes through full service layer with password validation and business logic
  - The CLI is essentially an "administrative backdoor" that bypasses the service
  layer and writes directly to the database

  5. Protocol-compliant workflow
  - Clients speaking the binary protocol need a proper bootstrap endpoint
  - REPL create_account_request is blocked in bootstrap mode (by enforcement logic)
  - create_initial_admin_request is the only endpoint that works in bootstrap mode

  The Distinction

  - CLI approach: Administrative backdoor, direct database access, bypasses all
  service logic
  - create_initial_admin_request: Proper network-accessible bootstrap flow with
  localhost restriction and atomic mode transition
  - REPL create_account_request: Normal account creation, blocked in bootstrap mode

  The create_initial_admin_request enables a proper "first-run experience" for
  clients connecting via the network protocol, while maintaining security through
  localhost-only access.



*** Users cannot update their passwords                                :code:

At present it is not possible to update passwords, or any other property of an
account.

*** Cli clean-ups                                                      :code:

- we still seem to support =--entity currencies=. This should now be invalid.
- we are still exporting as JSON. We should instead allow CSV and XML exports
  only.
- add recipes for all commands.
- should be able to list all admin accounts.
- list command should support table output.
- is admin should be a bool: =--is-admin arg (=0)=
- add account duplicates logic. We should have a single service for this.
- split application into entities.

*** Multi-threaded scenarios with comms                                :code:

At present we are relying on request-response patterns: the client sends a
request and the next frame coming in is the response. However, in the future we
will have many dialog windows open, each of them sending requests and awaiting
responses. It will not be possible to know what response is coming back from
what window. We need to take this into account.

*** Add listen/notify support                                          :code:

When data changes for a given entity in the database and we have the dialog of
that entity open, we need to make the reload button a different colour (suggest
a colour). For this we need to listen/notify in the database and then send a
message to the client. This requires a change at the protocol because at present
we send a request from the client first and then expect a response. This is more
like a callback where the handler will call a callback when a certain message is
received. Listen code from deepseek:

#+begin_src c++
#include <sqlgen.h>
#include <libpq-fe.h>
#include <thread>
#include <iostream>

class TableWatcher {
private:
    sqlgen::Connection conn_;
    std::thread listener_thread_;
    bool running_;

public:
    TableWatcher(const std::string& connection_string)
        : conn_(connection_string), running_(false) {}

    void start() {
        running_ = true;
        listener_thread_ = std::thread(&TableWatcher::listen_loop, this);
    }

    void stop() {
        running_ = false;
        if (listener_thread_.joinable()) {
            listener_thread_.join();
        }
    }

private:
    void listen_loop() {
        // Get raw PGconn for async operations
        auto raw_conn = conn_.native_handle(); // You might need to expose this

        // Listen to channel
        PGresult* res = PQexec(raw_conn, "LISTEN table_updates;");
        if (PQresultStatus(res) != PGRES_COMMAND_OK) {
            PQclear(res);
            return;
        }
        PQclear(res);

        while (running_) {
            // Non-blocking check for notifications
            PQconsumeInput(raw_conn);

            PGnotify* notify;
            while ((notify = PQnotifies(raw_conn)) != nullptr) {
                handle_notification(notify);
                PQfreemem(notify);
            }

            std::this_thread::sleep_for(std::chrono::milliseconds(100));
        }
    }

    void handle_notification(PGnotify* notify) {
        std::cout << "Received notification: " << notify->relname
                  << " - " << notify->extra << std::endl;

        // Parse the extra data (usually JSON) and handle accordingly
        // {"table": "users", "operation": "INSERT", "id": 123}
    }
};
#+end_src

*** Add version support to entities                                    :code:

We need a "version" field which is incremented automatically by a trigger. It is
used as follows:

- domain entities have a version field which is loaded from database.
- if we try to save at version =n= but current version is not =n-1=, it should
  fail to save.
- version is incremented automatically on save.
- display version in UI prominently (/e.g./ next to entity key, iso code for
  currencies) so that we can see when we reload.

*** Disconnect closes currencies window                                :code:

It should just disable the icons, etc.

*** Add search to currencies                                           :code:

It should be possible to filter the open currencies by a string. This should be
any field. The user needs to know when the list has been filtered. Ideally we
should have buttons at the top per field and filter using those. It should go
back to database rather than just filter what is available in UI.



* Footer

| Previous: [[id:154212FF-BB02-8D84-1E33-9338B458380A][Version Zero]] |
