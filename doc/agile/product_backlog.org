:PROPERTIES:
:ID: 558650A4-C3E5-8964-4193-7D9125E29B83
:END:
#+options: date:nil toc:nil author:nil num:nil
#+title: Product Backlog
#+tags: { reviewing(r) }
#+tags: { code(c) infra(i) doc(d) agile(a) }

This document contains the [[http://www.mountaingoatsoftware.com/agile/scrum/product-backlog][product backlog]] for VisualOre.

* Product Vision

Here we define what we consider to be the [[http://www.scaledagileframework.com/vision/][the vision]] for the product; what
guides us when we think about the product and what can and cannot go into the
product backlog.

** Vision Statement

The vision for ORE Studio is to build on top of [[https://github.com/OpenSourceRisk/Engine][ORE]] with the aim of providing:

- a persistent database storage for all of its inputs and outputs;
- a graphical user interface both for data generation as well as data exploration;
- the ability to configure and orchestrate ORE execution.

** Vision Quotes

#+begin_quote
People think focus means saying yes to the thing you've got to focus on. But
that's not what it means at all. It means saying no to the hundred other good
ideas that there are. You have to pick carefully. I'm actually as proud of the
things we haven't done as the things I have done. Innovation is saying no to
1,000 things. -- Steve Jobs
#+end_quote

* Release Checklist

Steps to create a new release.

** Close previous sprint

To be done on the last Sunday of the sprint.

1. Make a copy of current sprint backlog and name it current sprint + 1.
2. Move all untouched stories into product backlog.
3. Close current sprint: close all open tasks, delete tasks we did not work on,
   update clocks.
4. Push commit and wait for builds. This ensures that if there are any failures
   you can fix them before the release tag.
4. Tag commit and sign it with key.
5. Push tag. You can generate new builds overnight.

** Open new sprint

1. Open new sprint, updating CMake version, README, GitHub (packages. Build all
   and run tests. This should all be in one commit.
2. Create a demo. Publish it on youtube.
3. Write up release notes, publish them in github.
4. When tag build is finished, unpack and copy binaries into release, announce
   twitter and linked in.

* Stories

** Near

Stories we may get two in the next two or three sprints.

*** Log file for Qt application is non-standard                        :code:

At present we need to manually create the log directory for the gui to fix this
error:

#+begin_quote
[marco@lovelace bin]$ ./ores.qt
terminate called after throwing an instance of 'boost::filesystem::filesystem_error'
  what():  boost::filesystem::create_directories: Permission denied [system:13]: "/opt/OreStudio/0.0.3/bin/../log", "/opt/OreStudio/0.0.3/bin/../log"
Aborted                    ./ores.qt
#+end_quote

We should really output the log file in a standard location such as /var/log or
something.

*** Create shared object interfaces                                    :code:

At present we are building shared objects / DLLs for the ores components, but we
did not bother defining proper interfaces, exporting symbols etc. This causes
problems on windows:

#+begin_src sh
LINK : fatal error LNK1104: cannot open file 'projects\ores.utility\ores.utility.lib'
#+end_src

This is happening because we are not exporting explicitly any symbols. To fix
this we did a hack:

#+begin_src cmake
if(WIN32 AND MSVC)
    # Export all symbols on windows for now. Bit of a hack.
    set(CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS ON)
endif()
#+end_src

The right solution for this is to annotate all the public types of each SO
correctly, exporting symbols for all platforms:

Deep seek analysis:

#+begin_src markdown
Yes, Boost provides a cross-platform wrapper for exporting symbols using the
`BOOST_SYMBOL_EXPORT` macro from the **Boost.DLL** library. This macro abstracts
away the compiler-specific keywords required for different platforms.

### üóÇÔ∏è Boost's Cross-Platform Symbol Exporting

To export a symbol, you use the `BOOST_SYMBOL_EXPORT` macro in your code. Under
the hood, it expands to the correct compiler-specific attribute:

- On **Windows** with MSVC, it becomes `__declspec(dllexport)`
- On **macOS** and **Linux** with GCC/Clang, it becomes `__attribute__((visibility("default")))`

Here is a basic example of how to use it to export a global variable:

```cpp
#include <boost/config.hpp> // For BOOST_SYMBOL_EXPORT

class my_plugin_api {
    // Your interface definition
};

namespace my_namespace {
    class my_plugin_sum : public my_plugin_api {
        // Implementation
    };

    // Export the 'plugin' variable
    extern "C" BOOST_SYMBOL_EXPORT my_plugin_sum plugin;
    my_plugin_sum plugin;
}
```
,*Note: The `extern "C"` is used here to prevent C++ name mangling, making the symbol name
predictable for tools that use C linkage. This is often crucial for a library's public API.*

For exporting factory functions, Boost offers the `BOOST_DLL_ALIAS` macro, which
is often more convenient:

```cpp
#include <boost/dll/alias.hpp> // For BOOST_DLL_ALIAS

namespace my_namespace {
    class my_plugin_aggregator : public my_plugin_api {
        // Implementation
    };

    // Factory function
    boost::shared_ptr<my_plugin_api> create() {
        return boost::shared_ptr<my_plugin_aggregator>(new my_plugin_aggregator());
    }

    // Export the factory function with the alias "create_plugin"
    BOOST_DLL_ALIAS(my_namespace::create, create_plugin)
}
```

### üí° A Complementary Approach: Controlling Visibility

While Boost's macro solves the declaration problem, for finer control and to
minimize your shared library's public API, combine it with compiler flags that
hide all symbols by default.

- **On Linux and other ELF platforms**, use the `-fvisibility=hidden` flag. You
  can then use a **linker version script** to explicitly list the symbols you
  want to export.
- **On macOS**, use the `-fvisibility=hidden` flag and an **exported symbols
  list** with `-exported_symbols_list` during linking.
- **On Windows**, symbol visibility is typically controlled explicitly via
  `__declspec(dllexport)` or a module definition (.def) file, which
  `BOOST_SYMBOL_EXPORT` already handles.

Setting default visibility to hidden helps create a cleaner, more efficient
library by reducing its footprint, improving load times, and avoiding potential
symbol conflicts.

### üîß Summary

For a complete cross-platform solution:

1. **Use Boost.DLL macros**: Incorporate `BOOST_SYMBOL_EXPORT` or
   `BOOST_DLL_ALIAS` in your code to handle platform-specific export keywords.
2. **Hide symbols by default**: Compile your shared library with
   `-fvisibility=hidden` on Linux and macOS. This works in conjunction with the
   Boost macros.
3. **Use version scripts (optional)**: For maximum control on ELF platforms
   (Linux) or via an exported symbols list on macOS, use these linker features
   to define a precise public API.

I hope this helps you build your cross-platform shared library! If you have more
questions about using the Boost.DLL library for loading these symbols at
runtime, feel free to ask.
#+end_src

Links:

- [[https://stackoverflow.com/questions/76338106/cmake-how-to-produce-both-dll-and-lib-as-outputs][SO: "CMAKE" - how to produce both ".dll" and ".lib" as outputs]]

*** Copy across icons and other assets to package                      :code:

At present when you start the gui you get:

: /opt/OreStudio/0.0.3/bin/ores.qt
: qt.svg: Cannot open file '/home/marco/money-pound-box-line.svg', because: No such file or directory
: qt.svg: Cannot open file '/home/marco/money-pound-box-line.svg', because: No such file or directory

We need to put the assets under a suitable directory in opt and try to open them
from there.

*** Update timestamps to use timezone                                  :code:

Links:

- [[https://justatheory.com/2012/04/postgres-use-timestamptz/][Always Use TIMESTAMP WITH TIME ZONE]]

*** Add more account commands                                          :code:

See the azeroth account commands for inspiration.

Links:

- [[https://www.azerothcore.org/wiki/gm-commands][GM Commands]]

*** CLI Importing needs to read from database                          :code:

After we do the import into the database, we need to read the currencies again
to get the valid from/to.

*** Fix gemini cli action                                              :code:

The action to review PRs using gemini is failing.

*** Tidy-up database code                                              :code:

- add helpers to utility to ensure success, execute query, etc.
- add helpers for max timestamp, timestamp.

*** Split console recipes by entity                                    :code:

At present we have one very long file, but this is not scalable. We could split
out:

- general args (help, info, etc)
- by entity

Notes:

- Rename console to CLI.
- reduce output, only first few entries are needed.
- add a toc.

*** Add support for JWT                                                :code:

When we add support for HTTP/REST, we need to ensure it uses JWT.

Links:

- [[https://iniakunhuda.medium.com/building-secure-jwt-authentication-in-go-with-postgresql-94b6724f9b75][Building Secure JWT Authentication in Go with PostgreSQL]]
- [[https://github.com/Thalhammer/jwt-cpp][GH jwt-cpp]]

*** Read up on ECS                                                 :analysis:

Links:

- [[https://en.wikipedia.org/wiki/Entity_component_system][wikipedia: Entity component system]]
- [[https://github.com/skypjack/entt][GH entt]]: "EnTT is a header-only, tiny and easy to use library for game
  programming and much more written in modern C++."

*** Consider adding otel support                                       :code:

Links:

- [[https://github.com/destrex271/postgresexporter][GH postgresexporter]]: "Unofficial Postgres Exporter for OTEL"
- [[https://opentelemetry-cpp.readthedocs.io/en/latest/otel_docs/classopentelemetry_1_1sdk_1_1trace_1_1SpanExporter.html][SpanExporter]]: create your own exporter.

*** Add chat support                                                   :code:

Links:

- [[https://github.com/communi/libcommuni][GH libcommuni]]: "A cross-platform IRC framework written with Qt."
- [[https://github.com/inspircd/inspircd/tree/insp4][GH insp4]]: "InspIRCd is a modular C++ Internet Relay Chat (IRC) server for
  UNIX-like and Windows systems."
- https://www.inspircd.org/

*** Consider exposing end points via HTTP                              :code:

Having a binary protocol is helpful for performance but it may make life easier
to expose some functionality via HTTP.

Links:

- [[https://github.com/dfleury2/beauty][GH: beauty]]: "Beauty is a layer above Boost.Beast which provide facilities to
  create Http server or client. Beauty allows the creation of synchronous or
  asynchronous server and client, and adds some signals and timer management
  based on Boost.Asio"

*** Consider using getML to integrate ML                               :code:

Links:

- [[https://github.com/getml/getml-community][GH: getml]]: "getML is a tool for automating feature engineering on relational
  data and time series. It includes a specifically customized database Engine
  for this very purpose."
- [[https://getml.com/latest/user_guide/quick_start/][user guide quick start]]

*** Configure postgres with async IO                                   :code:

Links:

- [[https://neon.com/postgresql/postgresql-18/asynchronous-io][PostgreSQL 18 Asynchronous I/O]]

*** Consider using sqls for LSP                                        :code:

We are presently testing postgrestools. If that does not work well, we should
consider sqls.

Links:

- [[https://www.reddit.com/r/emacs/comments/ijbvwv/eglot_sqls_sql_client/][eglot + sqls = SQL client?]]

*** Add workspace as a container                                       :code:
    :LOGBOOK:
    CLOCK: [2025-02-13 Thu 22:18]--[2025-02-13 Thu 22:35] =>  0:17
    CLOCK: [2025-02-13 Thu 21:21]--[2025-02-13 Thu 22:17] =>  0:56
    :END:

Core needs to have a container for all of the data stored within a context.

Actually, according to Data Priented Principles, we may not need it. This may be
a UI concept but not a code concept.

*** Add portfolio support                                              :code:

Links:

- [[https://leonardqmarcq.com/posts/modeling-hierarchical-tree-data][Modeling Hierarchical Tree Data in PostgreSQL]]

*** Setup code quality actions                                        :infra:

We added a test password to the repo on purpose to see if it was going to be
detected by the github actions:

#+begin_src c++
    std::string connection_string("postgresql://ores:ores@localhost:5433/oresdb");
#+end_src

It wasn't. We need to figure out which actions need to be setup for this. Add
any other actions we may be missing.

The build seems to be failing:

#+begin_src sh
-- SCCache NOT found.
 CMake Error at /usr/local/share/cmake-3.30/Modules/CMakeDetermineSystem.cmake:152 (message):
   Could not find toolchain file:
   /home/runner/work/OreStudio/OreStudio/vcpkg/scripts/buildsystems/vcpkg.cmake
 Call Stack (most recent call first):
 CMakeLists.txt:61 (project)


 CMake Error: CMake was unable to find a build program corresponding to "Unix Makefiles".  CMAKE_MAKE_PROGRAM is not set.  You probably need to select a different build tool.
 CMake Error: CMAKE_CXX_COMPILER not set, after EnableLanguage
 -- Configuring incomplete, errors occurred!
 ~/work/OreStudio/OreStudio ~/work/OreStudio/OreStudio
 ~/work/OreStudio/OreStudio
 cpp/autobuilder: No supported build command succeeded.
 cpp/autobuilder: autobuild summary.
 Error: We were unable to automatically build your code. Please replace the call to the autobuild action with your custom build steps. Encountered a fatal error while running "/opt/hostedtoolcache/CodeQL/2.18.0/x64/codeql/cpp/tools/autobuild.sh". Exit code was 1 and last log line was: cpp/autobuilder: autobuild summary. See the logs for more details.
#+end_src

This may be due to a missing sub-module for vcpkg.

*** Add a message queue                                                :code:

Links:

- [[https://www.oliverlambson.com/pgmq][Use what you already have: Building a message queue on Postgres]]

*** Implement database connectivity                                    :code:

We have hard coded database configuration. Implement this properly both for
console and UI.

*** Starting UI from file manager does not work                       :infra:

At present we can't start the Qt UI because the file manager thinks its a video.
Maybe we need a desktop file.

Example desktop file:

#+begin_src conf
[Desktop Entry]
Comment=
Terminal=true
Name=fixvideo
Exec=/home/user/fixvideo.sh %f
Type=Application
Icon=/usr/share/icons/gnome/48x48/apps/gnome-settings-theme.png
Encoding=UTF-8
Hidden=false
NoDisplay=false
Categories=AudioVideo;Player;Recorder;
MimeType=video/dv;v
#+end_src

Source: [[https://emacs.stackexchange.com/questions/58037/is-there-a-standard-mode-for-ini-files][Is there a standard mode for .ini files?]]

Tasks:

- create a desktop file for the application.
- add an icon.

*** Consider adding the update copyrights action from quantlib        :infra:

We should remove copyrights from each file and instead have it only at the
top-level to make maintenance easier.

See [[https://github.com/OpenSourceRisk/QuantLib/blob/master/.github/workflows/copyrights.yml][=copyrights.yml=]] in QuantLib repo.

*** Consider adding clang-tidy build                                  :infra:

As per QuantLib build: [[https://github.com/OpenSourceRisk/QuantLib/blob/master/.github/workflows/tidy.yml][=tidy.yml=]].

*** Consider adding test times build                                  :infra:

As per QuantLib build: [[https://github.com/OpenSourceRisk/QuantLib/blob/master/.github/workflows/test-times.yml][=test-times.yml=]].

*** Consider adding sanitizer build                                   :infra:

As per QuantLib build: [[https://github.com/OpenSourceRisk/QuantLib/blob/master/.github/workflows/sanitizer.yml][=sanitizer.yml=]].

*** Use string views for static strings                               :infra:

We are creating =std::strings= where we don't need them, use string views
instead.

This is not trivial, when we tried a lot of things were borked.

*** Create HTTP end point for currencies                              :infra:

Add a basic HTTP server using boost beast. Then we just need a couple of verbs:

- GET: return all currencies in database.
- POST: add one or more currencies.

*** Fix site links to main page                                         :doc:

At present we renamed readme to index in the HTML export. Do a symlink or a copy
of this file to fix links.

*** Add discord support to app                                        :infra:

Links:

- [[https://github.com/RealTimeChris/DiscordCoreAPI][DiscordCoreAPI]]

*** Recipes do not show variables in org-babel                        :infra:

At present when we look at a recipe in the site, we cannot tell what the
environment variables are:

#+begin_src sh
./ores.console import ${log_args} --currency-configuration ${currency_config_dir}/currencies.xml
#+END_SRC

It would be nice if =log_args= etc showed up in the recipe.

Links:

- [[https://kitchingroup.cheme.cmu.edu/blog/2019/02/12/Using-results-from-one-code-block-in-another-org-mode/][Using results from one code block in another org-mode]]

*** Install Windows package on Windows machine                        :infra:

We need to install and run the windows package and make sure it works. Check
console and GUI start.

*** Install OSX package on OSX machine                                :infra:

We need to install and run the windows package and make sure it works. Check
console and GUI start.

*** Add packaging support for images                                  :infra:

At present we are not adding images to packages.

*** Create an icon for the application                                :infra:

We copied the Dogen icon to get us going. We should really grab our own logo.

*** Add JSON parsing support for currency                              :code:

We need to have the ability to read and write currencies from JSON.

*** Work through all types required for Example 1                      :code:

We want to be able to visualise all the data types needed in order to be able to
run the most basic example of ORE. For each of these types, create a stories.

The files are as follows. First, there are the files in the =Input= directory:

- [[https://github.com/OpenSourceRisk/Engine/tree/master/Examples/Example_1/Input][Example 1 Inputs]]

Specifically:

- =currencies.xml=
- =netting.xml=
- =ore.xml=
- =ore_swaption.xml=
- =plot.gp=
- =portfolio.xml=
- =portfolio_swap.xml=
- =portfolio_swap_20151023.xml=
- =portfolio_swaption.xml=
- =portfolio_swaption_20151023.xml=
- =simulation.xml=

In addition, we need all of the common inputs under:

- [[https://github.com/OpenSourceRisk/Engine/tree/master/Examples/Input][Examples - Common Inputs]]

These are:

- =calendaradjustment.xml=
- =conventions.xml=
- =currencies.xml=
- =curveconfig.xml=
- =fixings_20160205.txt=
- =market_20160205.txt=
- =market_20160205_flat.txt=
- =pricingengine.xml=
- =todaysmarket.xml=

Finally, we need support for the outputs. We can grab these from the expected
outputs:

- [[https://github.com/OpenSourceRisk/Engine/tree/master/Examples/Example_1/ExpectedOutput][Example 1 Expected Outputs]]

These are:

- =colva_nettingset_CPTY_A.csv=
- =curves.csv=
- =exposure_nettingset_CPTY_A.csv=
- =exposure_trade_Swap_20y.csv=
- =flows.csv=
- =log_progress.json=
- =netcube.csv=
- =npv.csv=
- =swaption_npv.csv=
- =xva.csv=

*** Consider adding support for A/B testing                            :code:

At present feature flags are global. However, we may want to enable a feature
for a subset of the population. Analysis:

#+begin_src markdown
To support **gradual rollout (ramping)** of features‚Äîe.g., enabling a feature for 10% of users, then 50%, then 100%‚Äîyou need to extend your feature flag system beyond a simple boolean toggle. The current temporal table design (`feature_flags` with validity periods) is great for time-based control, but **not sufficient for user-based targeting**.

Here‚Äôs a practical, scalable approach that integrates well with your C++23/Qt/PostgreSQL stack:

---

### üéØ Goal
Enable a feature **conditionally** based on:
- User identity (e.g., user ID, tenant ID, or client ID)
- A **rollout percentage** (e.g., 10%)
- Optional: user attributes (role, region, etc.)

---

### ‚úÖ Step 1: Enhance the Feature Flag Schema

Add **rollout strategy metadata** to your `feature_flags` table:

```sql
ALTER TABLE oresdb.feature_flags
ADD COLUMN rollout_percentage INTEGER CHECK (rollout_percentage BETWEEN 0 AND 100) DEFAULT 100,
ADD COLUMN targeting_criteria JSONB; -- optional, for advanced rules
```

Now each flag version can specify:
- `rollout_percentage = 10` ‚Üí enable for ~10% of users
- `targeting_criteria = '{"role": "beta_tester"}'` ‚Üí (future extensibility)

> Keep your temporal primary key and exclusion constraint ‚Äî they still apply.

---

### ‚úÖ Step 2: Determine a Stable User Identifier

Your client must provide a **consistent, hashable ID** per user or session, such as:
- User ID (if authenticated)
- Device ID / client UUID (if anonymous)
- Tenant ID (for multi-tenant apps)

This ID must be **stable** across sessions so the same user doesn‚Äôt see the feature flicker on/off.

> üí° In your Qt client, generate or retrieve this ID at startup and pass it to the feature flag service.

---

### ‚úÖ Step 3: Implement Consistent Hash-Based Sampling in C++

Use a **deterministic hash** to map user IDs into a 0‚Äì99 bucket:

```cpp
#include <functional>
#include <string>

bool should_enable_for_user(std::string_view feature_name,
                            std::string_view user_id,
                            int rollout_percentage) {
    if (rollout_percentage <= 0) return false;
    if (rollout_percentage >= 100) return true;

    // Combine feature name + user ID to avoid correlation across features
    std::string key = std::string(feature_name) + ":" + std::string(user_id);

    // Use a stable hash (e.g., std::hash, but note: not guaranteed consistent across runs)
    // For production, prefer a consistent hash like FNV-1a or CityHash
    auto hash = std::hash<std::string>{}(key);
    int bucket = static_cast<int>(hash % 100);
    return bucket < rollout_percentage;
}
```

> ‚ö†Ô∏è **Warning**: `std::hash` is **not guaranteed to be stable across program runs or platforms**.
> For reliable rollout, use a **stable hashing algorithm** like **FNV-1a**, **MurmurHash3**, or **xxHash**.

Example with a simple FNV-1a (C++23-friendly):

```cpp
constexpr uint32_t fnv1a_32(std::string_view s) {
    uint32_t hash = 2166136261u; // FNV offset basis
    for (char c : s) {
        hash ^= static_cast<uint8_t>(c);
        hash *= 16777619u; // FNV prime
    }
    return hash;
}

bool should_enable_for_user(std::string_view feature_name,
                            std::string_view user_id,
                            int rollout_percentage) {
    if (rollout_percentage <= 0) return false;
    if (rollout_percentage >= 100) return true;

    std::string key{feature_name};
    key += ':';
    key += user_id;

    uint32_t hash = fnv1a_32(key);
    return (hash % 100) < static_cast<uint32_t>(rollout_percentage);
}
```

This ensures:
- Same user ‚Üí same decision
- Uniform distribution across users
- Independent per-feature rollout

---

### ‚úÖ Step 4: Update Your Feature Flag Service

Modify your C++ `FeatureFlagService`:

```cpp
class FeatureFlagService {
public:
    // Returns true if the feature is enabled AND user qualifies
    bool is_enabled_for_user(Feature f, std::string_view user_id) const;

private:
    struct FlagConfig {
        bool enabled;
        int rollout_percentage; // 0‚Äì100
        // add targeting_criteria later if needed
    };
    std::unordered_map<Feature, FlagConfig> cache_;
};
```

Implementation:

```cpp
bool FeatureFlagService::is_enabled_for_user(Feature f, std::string_view user_id) const {
    auto it = cache_.find(f);
    if (it == cache_.end() || !it->second.enabled) {
        return false;
    }
    return should_enable_for_user(to_string(f), user_id, it->second.rollout_percentage);
}
```

---

### ‚úÖ Step 5: Integrate in Qt UI

```cpp
QString userId = getCurrentUserId(); // from auth, settings, etc.

if (featureFlagService.is_enabled_for_user(Feature::ExperimentalUI, userId.toStdString())) {
    ui->experimentalPanel->show();
}
```

---

### ‚úÖ Optional: Advanced Targeting (Future-Proofing)

Use the `targeting_criteria JSONB` column to store rules like:
```json
{
  "min_version": "2.1.0",
  "regions": ["EU", "NA"],
  "roles": ["admin", "beta"]
}
```

Then evaluate these in C++ (or push filtering to DB with JSONB queries if you fetch per-user flags).

But for **simple ramp-up**, percentage-based hashing is sufficient and efficient.

---

### ‚úÖ Operational Benefits

- **No client-side config changes** needed to ramp from 10% ‚Üí 50% ‚Üí 100% ‚Äî just update the DB.
- **Auditability**: Every rollout change is versioned in your temporal table.
- **Safety**: You can instantly roll back by setting `rollout_percentage = 0`.

---

### Summary

| Component           | Change |
|---------------------|--------|
| **Database**        | Add `rollout_percentage INT` to `feature_flags` |
| **C++ Service**     | Add `is_enabled_for_user(feature, user_id)` |
| **Hashing**         | Use stable hash (e.g., FNV-1a) over `feature:user_id` |
| **Qt UI**           | Pass user ID to flag checks |

This gives you **safe, gradual, observable rollouts** while keeping your architecture clean and performant.
#+end_src



** Far

Stories that we want to capture, but won't work on for a while.

*** LLM Integration                                                    :code:

LLMs can be useful when learning a new subject as they can provide additional
context to the information displayed in the screen. For example, a user can ask
the LLM to explain a graph or a table. It would probably be fairly straight
forward to allow dumping some of the information in a format that is friendly to
LLMs (.e.g./ PNG, Markdown, plain text) and then make an API call to a local or
remote LLM. We could probably create a set of useful canned prompts (explain
this report, explain this chart).

On a more blue skies approach, one could conceive asking the LLM for suggestions
on how to act, on the basis of the analysis. This could result in suggestions
for action the user could implement, or even on actions directly taken based on
the LLM's suggestions. This is conceptually straightforward: the LLM could for
example generate a well defined JSON with the proposed action, and the system
would look for some predefined markers in the LLM output:

#+begin_src text
----- ACTION START
<JSON>
----- ACTION END
#+end_src

The JSON payload would describe the action:

#+begin_src json
{
    "action": "some_action_type",
    "key1": "value1",
    ....
#+end_src

A trivial lookup table could de-serialise the JSON and execute the action. All
that is required is for the LLM to "learn" how to generate JSON compliant with
the desired format, which should be quite straightforward (perhaps with the help
of fine-tuning). Agents probably provide most of this infrastructure already.
The key thing is to ensure all functionality in the core becomes UI agnostic
such that one could bolt an NLP UI around it.

Links:

- [[https://llama.meta.com/docs/how-to-guides/prompting/][How-to guides: Prompting]]
- [[https://mychen76.medium.com/practical-techniques-to-constraint-llm-output-in-json-format-e3e72396c670][Practical Techniques to constraint LLM output in JSON format]]

*** Support multiple ORE "toolchains"                                  :code:

Much like with an IDE, where one can have multiple toolchains configured, we
need to also support multiple versions of ORE. Unlike with IDEs, it may be
desirable to run computations with more than one version of ORE for comparison
purposes. This means we need a way to associate outputs with their ORE version.
This approach does not necessarily fit the existing example code, because these
have a single "output directory". However, we just need  way to associate N
toolchains with a given workspace or possibly component; when present, the
output directory starts to reflect the toolchain configuration. For example,
with CMake we use presets:

- =linux-clang-debug=
- =linux-clang-release=
- =linux-gcc-debug=
- =linux-gcc-release=

For ORE the only dimension under which variability is possible is the version.
We can then have pricing engine configurations that are either the same, or
possibly different:

- for a workspace;
- for a component;
- for a toolchain version.



*** Add faker support to model                                         :code:

vcpkg will support faker soon:

- [[https://github.com/microsoft/vcpkg/pull/38583][#38583: [faker-cxx] add new port]]

When that is available, we should try to add support for it.

*** Base the compute approach on BOINC                                 :code:

Copy the BOINC data model.

Links:

- [[https://boinc.berkeley.edu/trac/wiki/DataBase][wiki: DataBase]]
- [[https://wiki.debian.org/BOINC/ServerGuide][BOINC Debian Server Guide]]
- [[https://boinc.berkeley.edu/trac/wiki/ProjectMain][wiki: BOINC Project Main]]
- [[https://www.reddit.com/r/BOINC/][BOINC reddit]]


*** Create a set of fake currencies                                    :code:

We need to create fake data so we can explore the problem domain. This is
something to work on in the future. We can use LLMs to help with the fake data,
where it makes sense.

Example:

| Country code | Country name | Currency Code | Currency Number | Currency           |
|--------------+--------------+---------------+-----------------+--------------------|
| AL           | Aerilon      | ALD           |           10001 | Aerilonian Dollar  |
| AR           | Arcturia     | ARA           |           10002 | Arcturian Arct     |
| BA           | Balthoria    | BAF           |           10003 | Balthorian Florin  |
| BE           | Belloria     | BEB           |           10004 | Bellorian Bell     |
| CA           | Calandria    | CAC           |           10005 | Calandrian Crown   |
| CD           | Caledonia    | CDC           |           10006 | Caledonian Caled   |
| DA           | Daeloria     | DAD           |           10007 | Daelorian Dinar    |
| DE           | Delvadia     | DED           |           10008 | Delvadian Delv     |
| ER           | Eriador      | ERE           |           10009 | Eriadoran Euro     |
| ES           | Esteria      | ESE           |           10010 | Esterian Est       |
| FE           | Feloria      | FEF           |           10011 | Felorian Franc     |
| FN           | Fendaria     | FNF           |           10012 | Fendarian Fen      |
| GA           | Galdoria     | GAG           |           10013 | Galdorian Galleon  |
| GR           | Grendoria    | GRG           |           10014 | Grendorian Grend   |
| HE           | Helvetia     | HEF           |           10015 | Helvetian Franc    |
| HY           | Hydronia     | HYH           |           10016 | Hydronian Hyd      |
| IR           | Iridia       | IRD           |           10017 | Iridian Dollar     |
| IT           | Ithaca       | ITI           |           10018 | Ithacan Ith        |
| JE           | Jethro       | JEJ           |           10019 | Jethronian Jet     |
| JO           | Jorvik       | JOK           |           10020 | Jorvikian Krona    |
| KA           | Kaelor       | KAK           |           10021 | Kaelorian Krown    |
| KR           | Krynn        | KRK           |           10022 | Krynnish Krynn     |
| LU           | Luminia      | LUL           |           10023 | Luminian Lum       |
| LY           | Lysandria    | LYL           |           10024 | Lysandrian Lira    |
| MA           | Maldoria     | MAM           |           10025 | Maldorian Mal      |
| MR           | Mariposa     | MRP           |           10026 | Mariposan Peso     |
| NE           | Nektonia     | NEN           |           10027 | Nektonian Nek      |
| NT           | Netharia     | NTN           |           10028 | Netharian Naira    |
| OR           | Orinoco      | ORB           |           10029 | Orinocan Bolivar   |
| OL           | Orlanthia    | OLO           |           10030 | Orlanthian Orl     |
| PA           | Paldoria     | PAP           |           10031 | Paldorian Peso     |
| PY           | Pyrrhia      | PYP           |           10032 | Pyrrhian Pyr       |
| QU           | Quentaria    | QUQ           |           10033 | Quentarian Quen    |
| QN           | Quinaria     | QNQ           |           10034 | Quinarian Quetzal  |
| RE           | Rendellia    | RER           |           10035 | Rendellian Rend    |
| RI           | Rivenia      | RIR           |           10036 | Rivenian Ruble     |
| SE           | Serendia     | SES           |           10037 | Serendian Shilling |
| SI           | Sildoria     | SIS           |           10038 | Sildorian Sild     |
| TA           | Tandor       | TAT           |           10039 | Tandorian Taka     |
| TE           | Tenebria     | TET           |           10040 | Tenebrian Ten      |
| UL           | Uldoria      | ULU           |           10041 | Uldorian Uld       |
| UT           | Utopia       | UTU           |           10042 | Utopian Unit       |
| VA           | Valoria      | VAV           |           10042 | Valorian Valt      |
| VL           | Valtaria     | VLV           |           10043 | Valtarian Val      |
| WI           | Wintervale   | WIW           |           10044 | Wintervalean Won   |
| WY           | Wysteria     | WYW           |           10045 | Wysterian Wys      |
| XA           | Xandria      | XAX           |           10046 | Xandrian Xan       |
| XE           | Xenoria      | XEX           |           10047 | Xenorian Xen       |
| YS           | Yslandia     | YSY           |           10048 | Yslandian Yen      |
| ZE           | Zephyria     | ZEZ           |           10049 | Zephyrian Zephyr   |

| Previous: [[id:E5635EAC-CCE9-C0A4-A00B-C1780FF4A88E][Agile]] |
