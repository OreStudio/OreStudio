:PROPERTIES:
:ID: 98E12E24-FC8E-11F0-8B62-40B0768014EB
:END:
#+title: Sprint Backlog 11
#+options: <:nil c:nil ^:nil d:nil date:nil author:nil toc:nil html-postamble:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED BLOCKED
#+tags: { code(c) infra(i) analysis(n) agile(a) }
#+startup: inlineimages

* Sprint Mission

- Add multi-tenant support.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :tags t :indent nil :emphasize nil :scope file :narrow 75 :formula % :block today
#+TBLNAME: today_summary
#+CAPTION: Clock summary at [2026-02-06 Fri 23:04], for Friday, February 06, 2026.
|          | <75>                                                     |         |       |      |       |
| Tags     | Headline                                                 | Time    |       |      |     % |
|----------+----------------------------------------------------------+---------+-------+------+-------|
|          | *Total time*                                             | *11:32* |       |      | 100.0 |
|----------+----------------------------------------------------------+---------+-------+------+-------|
|          | Stories                                                  | 11:32   |       |      | 100.0 |
|          | Active                                                   |         | 11:32 |      | 100.0 |
| agile    | Sprint and product backlog refinement                    |         |       | 0:11 |   1.6 |
| code     | Refactor message handlers for per-request tenant context |         |       | 1:48 |  15.6 |
| analysis | Review DQ metadata tables for multi-tenancy support      |         |       | 1:41 |  14.6 |
| code     | vcpkg is still not caching correctly                     |         |       | 1:25 |  12.3 |
| code     | Check that data librarian can publish across tenants     |         |       | 2:51 |  24.7 |
| code     | Check that eventing works correctly across tenants       |         |       | 3:36 |  31.2 |
#+end:

#+begin: clocktable :maxlevel 3 :scope subtree :tags t :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+TBLNAME: sprint_summary
#+CAPTION: Clock summary at [2026-02-06 Fri 23:04]
|          | <75>                                                     |         |       |       |       |
| Tags     | Headline                                                 | Time    |       |       |     % |
|----------+----------------------------------------------------------+---------+-------+-------+-------|
|          | *Total time*                                             | *72:58* |       |       | 100.0 |
|----------+----------------------------------------------------------+---------+-------+-------+-------|
|          | Stories                                                  | 72:58   |       |       | 100.0 |
|          | Active                                                   |         | 72:58 |       | 100.0 |
| agile    | Sprint and product backlog refinement                    |         |       |  2:35 |   3.5 |
| code     | Address past review comments                             |         |       |  1:14 |   1.7 |
| code     | Split "god" admin account                                |         |       | 10:05 |  13.8 |
| code     | Move all database entities to public schema              |         |       |  1:22 |   1.9 |
| code     | Check directory structure in SQL                         |         |       |  0:36 |   0.8 |
| code     | Add tenancy support                                      |         |       |  3:55 |   5.4 |
| code     | Use tenancy to isolate tests                             |         |       |  5:00 |   6.9 |
| code     | Add NOTICE logging support to sqlgen                     |         |       |  0:53 |   1.2 |
| code     | Update codegen for tenancy                               |         |       |  3:32 |   4.8 |
| code     | Add entity types for tenants                             |         |       |  9:43 |  13.3 |
| code     | Add sink to log to database directly                     |         |       |  5:00 |   6.9 |
| code     | Add system accounts for services                         |         |       |  3:32 |   4.8 |
| code     | Test shell functionality with tenancy enabled            |         |       |  9:44 |  13.3 |
| code     | Fix apt-get failures on nightly build                    |         |       |  0:20 |   0.5 |
| code     | Refactor tenant lookup functions to accept const context |         |       |  0:58 |   1.3 |
| code     | Refactor message handlers for per-request tenant context |         |       |  4:56 |   6.8 |
| analysis | Review DQ metadata tables for multi-tenancy support      |         |       |  1:41 |   2.3 |
| code     | vcpkg is still not caching correctly                     |         |       |  1:25 |   1.9 |
| code     | Check that data librarian can publish across tenants     |         |       |  2:51 |   3.9 |
| code     | Check that eventing works correctly across tenants       |         |       |  3:36 |   4.9 |
#+end:

*** COMPLETED Sprint and product backlog refinement                   :agile:
    :LOGBOOK:
    CLOCK: [2026-02-06 Fri 22:22]--[2026-02-06 Fri 22:33] =>  0:11
    CLOCK: [2026-01-31 Sat 07:55]--[2026-01-31 Sat 08:17] =>  0:22
    CLOCK: [2026-01-31 Sat 01:53]--[2026-01-31 Sat 01:58] =>  0:05
    CLOCK: [2026-01-31 Sat 01:03]--[2026-01-31 Sat 01:22] =>  0:19
    CLOCK: [2026-01-29 Thu 09:04]--[2026-01-29 Thu 09:56] =>  0:52
    CLOCK: [2026-01-28 Wed 22:50]--[2026-01-28 Wed 23:36] =>  0:46
    :END:

Updates to sprint and product backlog.

#+begin_src emacs-lisp :exports none
;; agenda
(org-agenda-file-to-front)
#+end_src

#+name: pie-stories-chart
#+begin_src R :var sprint_summary=sprint_summary :colnames yes :results file graphics :exports results :file sprint_backlog_11_stories_pie_sorted.png :width 1920 :height 1080
library(conflicted)
library(ggplot2)
library(tidyverse)
library(tibble)

# Filter to only rows with actual story data (non-empty Tags column)
clean_sprint_summary <- sprint_summary %>% dplyr::filter(!is.na(Tags) & nzchar(Tags))
stories <- unlist(clean_sprint_summary[2])
percent_values <- as.numeric(unlist(clean_sprint_summary[6]))

# Create a data frame and explicitly sort the stories by defining factor levels
df <- data.frame(
  stories = stories,
  percent = percent_values
) %>%
  # 1. Sort the data frame by percentage in descending order
  arrange(desc(percent)) %>%
  # 2. Convert 'stories' to a factor, setting the levels based on the sorted order.
  # This makes the order of the slices explicit for ggplot.
  mutate(
    stories = factor(stories, levels = stories),
    lab.pos = cumsum(percent) - 0.5 * percent
  )

# Manually selected colors to resemble the screenshot
custom_palette <- c(
  "#21518f", "#f37735", "#ffc425", "#81b214", "#d7385e",
  "#662e91", "#00a9ae", "#5c5c5c", "#a0c6e0", "#f8b195",
  "#ffe385", "#bde0fe", "#c5e0d4", "#e0b8a0", "#a56f8f",
  "#7a448a", "#4a9a9b", "#9b9b9b", "#6fa8dc", "#f7a072",
  "#ffd166", "#99d98c", "#ef5d60", "#9d529f", "#3a86ff",
  "#c1d6e1", "#f9e0ac", "#c2d6a4", "#e69a8d", "#a07d9f"
)

# Ensure the palette has enough colors for all stories.
if (length(custom_palette) < length(df$stories)) {
  warning("Not enough custom colors for all stories. Colors will repeat.")
  custom_palette <- rep(custom_palette, length.out = length(df$stories))
}


p <- ggplot(df, aes(x = "", y = percent, fill = stories)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  scale_fill_manual(values = custom_palette) +
  ggtitle("Sprint 11: Resourcing per Story")  +
  labs(x = NULL, y = NULL, fill = "Stories") +
  theme_minimal() +
  theme(
    axis.text.x = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    plot.title = element_text(hjust = 0.5, size = 18),
    legend.position = "right",
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)
  )

print(p)
#+end_src

#+RESULTS: pie-stories-chart
[[file:sprint_backlog_11_stories_pie_sorted.png]]

#+name: stories-chart
#+begin_src R :var sprint_summary=sprint_summary :colnames yes :results file graphics :exports results :file sprint_backlog_11_stories.png :width 1200 :height 650
library(conflicted)
library(grid)
library(tidyverse)
library(tibble)

# Filter to only rows with actual story data (non-empty Tags column)
clean_sprint_summary <- sprint_summary %>% dplyr::filter(Tags != "")
names <- unlist(clean_sprint_summary[2])
values <- as.numeric(unlist(clean_sprint_summary[6]))

# Create a data frame.
df <- data.frame(
  cost = values,
  stories = factor(names, levels = names[order(values, decreasing = FALSE)]),
  y = seq(length(names)) * 0.9
)

# Setup the colors
blue <- "#076fa2"

p <- ggplot(df) +
  aes(x = cost, y = stories) +
  geom_col(fill = blue, width = 0.6) +
  ggtitle("Sprint 11: Resourcing per Story") +
  xlab("Resourcing (%)") + ylab("Stories") +
  theme(text = element_text(size = 15))

print(p)
#+end_src

#+RESULTS: stories-chart
[[file:sprint_backlog_11_stories.png]]

#+name: tags-chart
#+begin_src R :var sprint_summary=sprint_summary :colnames yes :results file graphics :exports results :file sprint_backlog_11_tags.png :width 600 :height 400
library(conflicted)
library(grid)
library(tidyverse)
library(tibble)

# Filter to only rows with actual story data (non-empty Tags column)
clean_sprint_summary <- sprint_summary %>% dplyr::filter(Tags != "")
names <- unlist(clean_sprint_summary[1])
values <- as.numeric(unlist(clean_sprint_summary[6]))

# Create a data frame.
df <- data.frame(
  cost = values,
  tags = names,
  y = seq(length(names)) * 0.9
)
# factor(names, levels = names[order(values, decreasing = FALSE)])

df2 <- setNames(aggregate(df$cost, by = list(df$tags), FUN = sum),  c("cost", "tags"))
# Setup the colors
blue <- "#076fa2"

p <- ggplot(df2) +
  aes(x = cost, y = tags) +
  geom_col(fill = blue, width = 0.6) +
  ggtitle("Sprint 11: Resourcing per Tag") +
  xlab("Resourcing (%)") + ylab("Story types") +
  theme(text = element_text(size = 15))

print(p)
#+end_src

#+RESULTS: tags-chart
[[file:sprint_backlog_11_tags.png]]

*** COMPLETED Address past review comments                             :code:
    :LOGBOOK:
    CLOCK: [2026-01-29 Thu 00:22]--[2026-01-29 Thu 00:52] =>  0:30
    CLOCK: [2026-01-28 Wed 23:37]--[2026-01-29 Thu 00:21] =>  0:44
    :END:

We have a number of comments we did not address from past PRs. PRs:

- https://github.com/OreStudio/OreStudio/pull/389
- https://github.com/OreStudio/OreStudio/pull/387

#+begin_quote
This pull request focuses on addressing various code review feedback points and
performing general maintenance across the Qt, DQ, and ORE components. The
changes aim to improve UI robustness, enhance code maintainability through
refactoring and dependency management, and provide more informative user
feedback, ultimately contributing to a more stable and user-friendly
application. The updates also include minor documentation clean-up and copyright
year adjustments.

Highlights:

- Qt Component Enhancements: Multiple MDI windows (ChangeReasonCategory,
  ChangeReason, Country, Currency, DataLibrarian, DatasetBundle,
  OriginDimension) now robustly restore their header states. If saved settings
  are corrupted, they gracefully fall back to default column visibility,
  preventing potential UI issues. The DataLibrarianWindow::getDatasetsUnderNode
  method has been optimized to efficiently handle root and category parent
  nodes, avoiding redundant dataset iterations and ensuring unique entries.
  Validation feedback for dataset bundles is more specific, pinpointing missing
  required fields. Batch deletion error messages for dataset bundles now include
  the codes of failed bundles and their specific failure reasons, improving user
  clarity. Lambda capture ordering in DatasetBundleController has been adjusted
  for better readability.
- DQ Component Refactoring: The write_dataset and read_dataset serialization
  helpers have been extracted from an anonymous namespace in
  dataset_protocol.cpp and exposed in dataset_protocol.hpp. This change promotes
  code reuse, eliminating approximately 200 lines of duplicated serialization
  logic previously found in publication_protocol.cpp.
- ORE Component Maintenance: CMake dependencies for the ORE library
  (projects/ores.ore/src/CMakeLists.txt) have been updated to align with actual
  code usage and the architecture diagram. This involved removing unused
  dependencies (e.g., ores.variability.lib, ores.comms.lib, sqlgen::sqlgen,
  faker-cxx::faker-cxx, libfort::fort) and adding required ones
  (ores.logging.lib, ores.platform.lib). The copyright year in
  projects/ores.ore/tests/CMakeLists.txt has been updated from 2024 to 2025.
- Documentation Updates: The doc/agile/product_backlog.org file has been
  significantly pruned, removing numerous outdated or completed backlog items.
  The doc/agile/v0/sprint_backlog_11.org file has been updated to reflect
  current clock summaries and the status of a sprint backlog item.
#+end_quote

*** COMPLETED Split "god" admin account                                :code:
    :LOGBOOK:
    CLOCK: [2026-01-31 Sat 01:23]--[2026-01-31 Sat 01:53] =>  0:30
    CLOCK: [2026-01-31 Sat 00:55]--[2026-01-31 Sat 01:03] =>  0:08
    CLOCK: [2026-01-30 Fri 22:36]--[2026-01-31 Sat 00:28] =>  2:27
    CLOCK: [2026-01-29 Thu 21:04]--[2026-01-29 Thu 23:04] =>  2:00
    CLOCK: [2026-01-29 Thu 14:40]--[2026-01-29 Thu 18:03] =>  3:23
    CLOCK: [2026-01-29 Thu 11:10]--[2026-01-29 Thu 13:08] =>  1:58
    CLOCK: [2026-01-29 Thu 10:56]--[2026-01-29 Thu 11:10] =>  0:14
    :END:

We are using a single account with all the rights. This is not a good idea.

Analysis by Gemini:

#+begin_src markdown

Moving away from a single "god user" is a classic architectural glow-up. Your
plan aligns well with the **Principle of Least Privilege (PoLP)** and standard
PostgreSQL security patterns.

In the Postgres ecosystem, this is often referred to as **Role-Based Access
Control (RBAC)**. Here is a breakdown of your proposal and how to refine it to
match industry "best practices."

---

### 1. Refined Role Hierarchy

Instead of managing permissions for every single service user individually, most
Postgres pros use **Group Roles**. You create "nologin" roles that hold the
permissions, and then your service users "inherit" those permissions.

| Role Type            | Name (Example)   | Purpose                                                        |
| ---                  | ---              | ---                                                            |
| **Owner (DDL)**      | `ores_owner`     | Owns all tables/schemas. Used for migrations.                  |
| **Read/Write (DML)** | `ores_rw`        | Group role with `SELECT`, `INSERT`, `UPDATE`, `DELETE`.        |
| **Read Only (RO)**   | `ores_ro`        | Group role with only `SELECT`. Great for analytics/debugging.  |
| **Service Users**    | `ores_http_user` | These roles have `LOGIN` and belong to `ores_rw` or `ores_ro`. |

---

### 2. Feedback on Your Specific Categories

#### **Application Service Users**

Your breakdown (`cli`, `wt`, `comms`, `http`) is excellent for **auditability**.
If you see a spike in slow queries, you’ll know exactly which service is the
culprit.

,**Pro Tip:**

Ensure these users do not own the tables they write to. If a service user
creates a table, the `ores_ddl_user` might not be able to modify it later
without a `REASSIGN OWNED` command.

#### **The DDL User (The Migrator)**

In Postgres, the most idiomatic way is to make this user the **Owner** of the
schema.

,**Why?**

Only the owner (or a superuser) can perform `ALTER TABLE` or `DROP INDEX`.

,**Safety:**

Your CI/CD pipeline should use this user, but your application code should
,**never** have these credentials.

#### **Read-Only & Admin Roles**

- **Read-Only:**: This is non-negotiable for production. Give it to your BI
  tools (Metabase, Tableau) or developers who need to run manual `SELECT`
  queries to troubleshoot.
- **Admin User:**: Usually, the cloud provider (like RDS or GCP) gives you a
  `postgres` or `cloudsqladmin` user. You rarely need to create a custom one
  unless you have a dedicated DBA team.

---

### 3. Implementation Gotchas

Postgres permissions can be "sticky." Keep these two things in mind:

1. **Default Privileges:** By default, when `ores_ddl_user` creates a new table,
   `ores_http_user` won't have access to it unless you use:

```sql
ALTER DEFAULT PRIVILEGES FOR ROLE ores_ddl_user
IN SCHEMA public GRANT SELECT, INSERT, UPDATE ON TABLES TO ores_rw;

```


2. **Schema Ownership:** Keep the `public` schema (or your custom schema) owned
   by your DDL user.

---

### 4. Summary Verdict

Your approach is **solid and highly recommended**. It prevents a vulnerability
in your `http` service from being used to `DROP TABLE`, and it makes your logs
much more readable.
#+end_src

*** COMPLETED Remove postgres passwords from github workflows          :code:

*Rationale*: done as part of the ores user split.

As a quick hack we added the dev passwords to the workflows. We should really
generate these on the fly and supply them to the tests.

*** COMPLETED Move all database entities to public schema              :code:
    :LOGBOOK:
    CLOCK: [2026-01-31 Sat 09:40]--[2026-01-31 Sat 09:49] =>  0:09
    CLOCK: [2026-01-31 Sat 08:18]--[2026-01-31 Sat 09:31] =>  1:13
    :END:

Gemini:

#+begin_quote
## The Agile Story: The Burden of the "Clean" Wall

### 1. The Starting Point: The "Two-Room" Architecture

We initially separated our database into two schemas: **Metadata** and
**Production**. We did this for "cleanliness"—believing that physical walls
would make the system easier to navigate.

### 2. The Friction (The "Blockers")

As our feature set grew, we encountered three main "Agile anti-patterns":

- **The Search-Path Tax:** Every time a developer wrote a query, they had to
  manage the `search_path` or use long-winded prefixes (e.g.,
  `metadata.system_config JOIN production.ores_iam_accounts`). This added
  cognitive load and slowed down every PR.
- **The Catalog Bottleneck:** PostgreSQL's internal brain (the catalog) had to
  work harder to resolve table locations across multiple namespaces.
- **Deployment Fragility:** Our CI/CD pipelines became complex. We had to ensure
  schemas were created in the exact right order, or our foreign key constraints
  would fail during migration.

### 3. The Pivot: Moving to the "Unified Grand Hall"

We decided to adopt the **Odoo-style Namespacing** approach. We tore down the
schema walls and moved everything into the `public` schema, but with a strict,
tiered naming convention: `ores_iam_accounts`.

### 4. The Result (The "Definition of Done")

By consolidating into one schema, we achieved:

- **Higher Velocity:** Joins are now simple and "local." No more prefixing every
  table name in the code.
- **Natural Organization:** Because we use the `ores_` prefix, our 2,000+ tables
  aren't a mess; they are **auto-alphabetized**. All IAM tables sit together,
  all Financial tables sit together.

- **Standardized Tooling:** Every standard PostgreSQL tool, backup script, and
  ORM works better with a single schema. We stopped fighting the tools and
  started using them as intended.

---

### The Executive Summary

> **"We traded the illusion of cleanliness for the reality of speed."** > By
moving to a single schema with prefixes, we kept the organizational benefits of
schemas without the operational debt of cross-schema management.
#+end_quote

*** COMPLETED Check directory structure in SQL                         :code:
    :LOGBOOK:
    CLOCK: [2026-01-31 Sat 19:28]--[2026-01-31 Sat 20:04] =>  0:36
    :END:

- why is there a projects/ores.sql/create/change_control directory.
- why are these dq?

: projects/ores.sql/create/refdata/dq_account_types_artefact_create.sql

#+begin_quote
This pull request significantly refactors the ores.sql project's file structure
and naming conventions. The primary goal is to enhance clarity, consistency, and
maintainability by standardizing SQL file names, consolidating data governance
scripts into a single dq directory, and removing numerous orphaned reference
data files. These changes improve the overall organization and reduce redundancy
within the SQL codebase.

Highlights:

- Standardized SQL File Naming: All SQL files now consistently use a
  [name]_[purpose].sql suffix pattern (e.g., iam_create.sql instead of
  create_iam.sql) for improved clarity and consistency.
- Consolidated Data Governance: The change_control/ directory has been merged
  into the dq/ directory, centralizing data quality and governance-related SQL
  scripts.
- Removed Orphaned Reference Data Files: Approximately 45 duplicate or unused
  SQL files related to reference data (refdata/) have been removed, streamlining
  the codebase.
- Sprint Backlog Updates: The sprint backlog was updated, marking 'Move all
  database entities to public schema' and 'Check directory structure in SQL' as
  completed.
#+end_quote

*** COMPLETED Add tenancy support                                      :code:
   :LOGBOOK:
   CLOCK: [2026-02-01 Sun 10:10]--[2026-02-01 Sun 11:30] =>  1:20
   CLOCK: [2026-01-31 Sat 23:00]--[2026-01-31 Sat 23:50] =>  0:50
   CLOCK: [2026-01-31 Sat 20:30]--[2026-01-31 Sat 21:55] =>  1:25
   CLOCK: [2026-01-29 Thu 10:35]--[2026-01-29 Thu 10:55] =>  0:20
   :END:

Do some analysis and prototyping around supporting multiple tenants on a single
database.

**** Initial tenant setup

#+begin_quote
This pull request lays the foundational groundwork for multi-tenancy within the
SQL schema. It systematically integrates tenant identification into the database
structure, ensuring that data is logically separated and managed on a per-tenant
basis. The changes span across table definitions, indexing strategies, data
validation logic, and data population scripts, providing a robust and scalable
solution for supporting multiple isolated client environments.

Highlights:

- Multi-Tenancy Core Infrastructure: Introduced new tables:
  'ores_iam_tenant_types_tbl' for tenant classifications,
  'ores_iam_tenant_statuses_tbl' for lifecycle states, and
  'ores_iam_tenants_tbl' as the central tenant management table, complete with
  bitemporal support.
- Tenant-Aware Schema Modifications: Added a 'tenant_id' column to approximately
  70 existing entity tables across various modules (assets, data quality, geo,
  IAM, refdata, telemetry, variability) to enable tenant-specific data
  partitioning.
- Enhanced Data Integrity and Uniqueness: Updated unique indexes and constraints
  on numerous tables to include 'tenant_id', ensuring uniqueness of records
  within each tenant rather than globally. New 'tenant_id' indexes were also
  added for improved query performance.
- Automated Tenant Validation: Modified all relevant insert triggers to
  automatically validate the 'tenant_id' using a new
  'ores_iam_validate_tenant_fn' function, preventing data insertion for invalid
  or inactive tenants.
- Updated Upsert Functions: Adjusted all upsert functions to accept 'tenant_id'
  as the first parameter, ensuring that seed data and new records are correctly
  associated with a specific tenant.
- System Tenant and Administrative Roles: Implemented a special 'system' tenant
  (with a well-known UUID) for platform-level governance data and
  administration. New 'SuperAdmin' and 'TenantAdmin' roles were introduced with
  appropriate tenant management permissions.
- Tenant-Specific Session Management: Added functions to retrieve the current
  session's 'tenant_id' and to look up tenants by hostname, facilitating tenant
  context management during user sessions.
#+end_quote

**** Tenancy and seeding

#+begin_quote
This pull request systematically modifies all database population scripts to
enforce multi-tenancy at the data seeding level. By introducing a system tenant
ID to every upsert operation, it guarantees that foundational data, such as
reference data, configurations, and metadata, is correctly scoped to the system
tenant. This is a fundamental architectural adjustment that supports the ongoing
development of a robust multi-tenant environment, ensuring data integrity and
isolation from the ground up.

Highlights:

- Multi-tenancy Support: All populate scripts have been updated to include
  ores_iam_system_tenant_id_fn() as the first parameter in upsert function
  calls, ensuring seeded data is associated with the system tenant.
- Data Association: This change is crucial for correctly scoping foundational
  data (reference data, configurations, metadata) to the system tenant,
  supporting a robust multi-tenant environment.
- Project Continuity: This pull request represents the second phase of a broader
  multi-tenancy implementation, building upon previous work in PR [sql] Add
  tenant infrastructure and tenant_id to all tables #395.
#+end_quote

**** Tenancy, login and tests

#+begin_quote
This pull request significantly enhances multi-tenancy support by automating the
assignment of tenant_id for login and session information based on the current
session context. It refines the tenant validation logic to be more robust when a
tenant ID is not explicitly provided, ensuring data integrity across tenants.
Additionally, it establishes a foundational testing framework by setting default
tenant contexts for test users and providing a C++ utility to manage this
context, which is crucial for transparently integrating existing C++ code with
the new multi-tenancy architecture.

Highlights:

- Automatic Tenant ID Population: Added BEFORE INSERT triggers to
  iam_login_info_tbl and iam_sessions_tbl to automatically populate the
  tenant_id from the session variable (app.current_tenant_id) if it's not
  explicitly provided during an insert operation. This ensures multi-tenancy
  context is maintained for these critical tables.
- Enhanced Tenant Validation Function: Modified the ores_iam_validate_tenant_fn
  to use coalesce(p_tenant_id, ores_iam_current_tenant_id_fn()). This change
  allows the function to accept a NULL p_tenant_id and gracefully fall back to
  using the tenant_id set in the current session, improving flexibility and
  reducing explicit tenant_id passing.
- Default Tenant Context for Test Users: Configured the ores_test_ddl_user and
  ores_test_dml_user roles in setup_template.sql to have a default
  app.current_tenant_id set to the system tenant UUID
  (00000000-0000-0000-0000-000000000000). This simplifies testing by providing a
  consistent tenant context for these roles.
- Test Infrastructure for Tenant Context: Introduced a new public method
  set_system_tenant_context() in the database_helper C++ class. This method
  programmatically sets the app.current_tenant_id session variable to the system
  tenant UUID, and is now called in the database_helper constructor,
  streamlining multi-tenancy setup for tests
#+end_quote

*** COMPLETED Use tenancy to isolate tests                             :code:
    :LOGBOOK:
    CLOCK: [2026-02-01 Sun 21:10]--[2026-02-01 Sun 21:30] =>  0:20
    CLOCK: [2026-02-01 Sun 19:35]--[2026-02-01 Sun 19:51] =>  0:16
    CLOCK: [2026-02-01 Sun 18:12]--[2026-02-01 Sun 19:13] =>  1:01
    CLOCK: [2026-02-01 Sun 15:40]--[2026-02-01 Sun 16:57] =>  1:17
    CLOCK: [2026-02-01 Sun 14:28]--[2026-02-01 Sun 15:33] =>  1:05
    CLOCK: [2026-02-01 Sun 12:27]--[2026-02-01 Sun 13:28] =>  1:01
    :END:

Now that we have tenancy support, a good way to isolate tests is to create
tenants. This has many advantages:

- we can use the same database for multiple test suites.
- we can check the results of the tests after running them to validate
  expectations
- it is faster than destroying databases.
- it is a more realistic test.

Notes:

- we need to ensure we destroy the tenant for a test suite to make sure the test
  starts with a clean slate.

**** Use tenancy in tests

#+begin_quote
This pull request introduces comprehensive multi-tenancy support across the
application's database and testing infrastructure. It establishes a centralized
C++ service for managing tenant context, integrates tenant-aware logic into the
CLI, and significantly enhances test isolation by provisioning unique tenants
for each test run. Furthermore, it refines database RLS policies to accommodate
system-level administrative access and provides SQL functions for tenant
lifecycle management, ensuring data separation and operational flexibility in a
multi-tenant environment.

Highlights:

- Centralized Tenant Context Service: Introduced a new tenant_context C++
  service in ores.database to centralize the management of multi-tenant context
  across all application components. This service allows setting the current
  tenant via code or UUID and provides utilities for tenant lookup.
- Multi-Tenant Test Isolation: Implemented robust multi-tenant test isolation
  within the C++ test infrastructure. Each test run now provisions a unique,
  isolated tenant, including copies of necessary reference data, and
  deprovisions it upon completion, ensuring clean and independent test
  environments.
- Enhanced Row-Level Security (RLS) Policies: Updated all existing RLS policies
  across assets, dq, iam, refdata, telemetry, and variability schemas to
  explicitly allow the 'system' tenant (UUID
  00000000-0000-0000-0000-000000000000) to access all tenant data for
  administrative and provisioning operations.
- CLI and Environment Variable Tenant Support: Added a --tenant command-line
  option to the ores.cli application and support for the ORES_TENANT environment
  variable, allowing users to specify the desired tenant context for CLI
  operations.
- psqlrc Enhancements for Tenant Management: Modified the psqlrc.sql
  configuration to automatically set the system tenant context on load, display
  the current tenant in the psql prompt, and introduced new macros (:tenant,
  :tenants) for convenient tenant inspection and listing.
- SQL Tenant Provisioning and Deprovisioning Functions: Added SQL functions
  ores_iam_provision_tenant_fn and ores_iam_deprovision_tenant_fn to
  programmatically create new tenants (copying base data from the system tenant)
  and soft-delete existing tenants and their associated data, respectively.
- Database Schema and Script Refinements: Removed obsolete metadata and
  production schema references from create_database_direct.sql, updated grants
  to the public schema, and adjusted unique constraints and triggers for
  ores_variability_feature_flags_tbl to properly incorporate tenant_id.
#+end_quote

*** COMPLETED Check for uses of raw libpq                              :code:

Claude has the habit of sneaking in uses of raw libpq. We need to do a review of
the code to make sure we are using sqlgen.

Notes:

- check for raw libpq in bitemporal operations.

All code has been moved into ores.database. Tickets have been raised in sqlgen.

*** COMPLETED Add NOTICE logging support to sqlgen                     :code:
    :LOGBOOK:
    CLOCK: [2026-02-01 Sun 22:45]--[2026-02-01 Sun 23:08] =>  0:23
    CLOCK: [2026-02-01 Sun 20:40]--[2026-02-01 Sun 21:10] =>  0:30
    :END:

- raised PR, waiting for review: [[https://github.com/getml/sqlgen/pull/120][#120: Add PostgreSQL notice processor support]]

Links:

- [[https://github.com/getml/sqlgen/issues/118][#118: Proposal: Add Notice Processor Support to sqlgen]]

*** BLOCKED Add bound parameters to sqlgen                             :code:

At present we are using libpq for assorted queries to avoid issues with SQL
injection. We should extend sqlgen to support this.

Links:

- [[https://github.com/getml/sqlgen/issues/119][#119: Support for bound parameters]]

*** COMPLETED Update codegen for tenancy                               :code:
    :LOGBOOK:
    CLOCK: [2026-02-02 Mon 09:00]--[2026-02-02 Mon 10:07] =>  1:07
    CLOCK: [2026-02-01 Sun 23:09]--[2026-02-02 Mon 01:34] =>  2:25
    :END:

We need to update code generation to take into account the new tenancy
infrastructure.

#+begin_quote
This pull request significantly enhances the multi-tenancy architecture by
standardizing how enum and lookup tables handle tenant identification. By
ensuring all shared reference data is associated with a system tenant and
implementing robust validation mechanisms, the changes promote a more
consistent, auditable, and scalable data model. The introduction of updated code
generation templates and new testing utilities streamlines the development and
maintenance of tenant-aware database schemas.

Highlights:

- Tenancy Consolidation Plan: A detailed plan has been added outlining the
  strategy to consolidate all enum/lookup tables to use a system tenant
  (tenant 0) for consistency, eliminating tenant-less tables and ensuring all
  shared data is auditable and flexible for future tenant-specific needs.
- Code Generation Template Updates: The sql_schema_domain_entity_create.mustache
  and sql_schema_table_create.mustache templates have been updated to
  conditionally include a tenant_id column, adjust primary key and exclusion
  constraints to incorporate tenant_id, and generate tenant validation logic
  within insert functions.
- New Tenant-Aware Entity Models: New JSON models have been introduced for
  artefact_type, tenant_status, tenant_type, currency, and rounding_type
  entities, explicitly defining them as tenant-aware with has_tenant_id: true
  and system_tenant_validation: true where appropriate.
- SQL Schema and Population Script Modifications: Numerous SQL schema creation
  scripts across dq, iam, and refdata components have been modified to implement
  bi-temporal and tenant-aware properties for their respective tables.
  Corresponding data population scripts have been updated to insert data with
  the system tenant ID.
- Introduction of pgTAP Testing Framework: A new section in the SKILL.org
  documentation details the use of pgTAP for database unit testing, covering
  test file organization, structure, common patterns for validation functions
  and trigger defaults, and execution instructions. Dedicated pgTAP test files
  have been added for artefact_type, tenant_status, tenant_type, currencies, and
  general refdata validations.
- New Utility Scripts: New shell scripts generate_refdata_schema.sh and
  recreate_entity.sh have been added to automate schema generation for refdata
  entities and to facilitate dropping and recreating individual database
  entities, respectively.
#+end_quote

*** COMPLETED Add entity types for tenants                             :code:
    :LOGBOOK:
    CLOCK: [2026-02-03 Tue 11:39]--[2026-02-03 Tue 12:12] =>  0:33
    CLOCK: [2026-02-03 Tue 07:30]--[2026-02-03 Tue 11:00] =>  3:30
    CLOCK: [2026-02-02 Mon 21:25]--[2026-02-02 Mon 21:55] =>  0:30
    CLOCK: [2026-02-02 Mon 17:08]--[2026-02-02 Mon 20:10] =>  3:02
    CLOCK: [2026-02-02 Mon 15:54]--[2026-02-02 Mon 16:37] =>  0:43
    CLOCK: [2026-02-02 Mon 14:30]--[2026-02-02 Mon 15:30] =>  1:00
    CLOCK: [2026-02-02 Mon 10:10]--[2026-02-02 Mon 10:35] =>  0:25
    :END:

We need to be able to load and save tenants from c++.

#+begin_quote
This pull request introduces comprehensive multi-tenancy support across the
system's database, code generation, and client-side interfaces. It establishes a
robust framework for isolating data and operations per tenant, enhancing
scalability and data governance. The changes include new tenant-specific
entities, updated code generation logic to enforce tenant awareness, and
extended client commands for tenant management, all while ensuring proper
versioning and backward compatibility where applicable.

Highlights:

- Multi-Tenancy Architecture Enhancement: Standardized enum and lookup tables to
  consistently use a system tenant (tenant 0), ensuring all shared reference
  data is auditable and flexible for future tenant-specific needs. This
  eliminates tenant-less tables and promotes a more consistent data model.
- Code Generation Template Updates: Modified
  sql_schema_domain_entity_create.mustache and sql_schema_table_create.mustache
  templates to conditionally include a tenant_id column, adjust primary key and
  exclusion constraints to incorporate tenant_id, and generate tenant validation
  logic within insert functions. This also includes handling different primary
  key types (UUID or text) for C++ serialization/deserialization.
- New Tenant-Aware Entity Models: Introduced new JSON models for artefact_type,
  tenant_status, tenant_type, currency, and rounding_type entities, explicitly
  defining them as tenant-aware with has_tenant_id: true and
  system_tenant_validation: true where appropriate.
- SQL Schema and Population Script Modifications: Numerous SQL schema creation
  scripts across dq, iam, and refdata components have been modified to implement
  bi-temporal and tenant-aware properties for their respective tables.
  Corresponding data population scripts have been updated to insert data with
  the system tenant ID.
- pgTAP Testing Framework Integration: A new section in the SKILL.org
  documentation details the use of pgTAP for database unit testing, covering
  test file organization, structure, common patterns for validation functions
  and trigger defaults, and execution instructions. Dedicated pgTAP test files
  have been added for artefact_type, tenant_status, tenant_type, currencies, and
  general refdata validations.
- New Utility Scripts: Added new shell scripts generate_refdata_schema.sh and
  recreate_entity.sh to automate schema generation for refdata entities and to
  facilitate dropping and recreating individual database entities, respectively.
- Protocol Version Bump: The PROTOCOL_VERSION_MAJOR has been incremented to 26
  and PROTOCOL_VERSION_MINOR to 1 to reflect the significant multi-tenancy
  support and backward-compatible changes introduced.
- Shell Command Enhancements: New commands (change-reason-categories,
  change-reasons, countries, tenants) have been added to the shell, and existing
  commands like bootstrap and login have been updated to support tenant
  management and display tenant-specific information.
- Tenant Context and Principal Parsing: Implemented tenant_context lookups by
  hostname and name, and enhanced user principal parsing (username@hostname) to
  correctly determine the target tenant for login and bootstrap operations,
  improving multi-tenant authentication flow.
#+end_quote

*** COMPLETED Add sink to log to database directly                     :code:
    :LOGBOOK:
    CLOCK: [2026-02-03 Tue 21:30]--[2026-02-03 Tue 22:24] =>  0:54
    CLOCK: [2026-02-03 Tue 17:30]--[2026-02-03 Tue 19:12] =>  1:42
    CLOCK: [2026-02-03 Tue 13:50]--[2026-02-03 Tue 15:34] =>  1:44
    CLOCK: [2026-02-03 Tue 12:20]--[2026-02-03 Tue 13:00] =>  0:40
    :END:

Now that tests will use tenants and we can get a picture of tests evolving over
time, it would be nice to be able to keep the logs for the tests as well. The
complicated way of doing this would be to add telemetry support to unit tests.
The simple way of doing this is to have a python script that just parses all the
log files in one go and upload them to the telemetry tables for the tenants.
With this we could also do reporting such as compare runs. Or maybe even better:
create a new sink which connects to database and uploads logs.

This feature useful for unit testing and for CLI tool as well.

**** Add database component

#+begin_quote
This pull request refactors the telemetry system by introducing a dedicated
ores.telemetry.database library. This change aims to resolve existing circular
dependencies between the core telemetry and database components, thereby
enhancing the modularity and testability of the system. A key outcome is the
ability to directly log telemetry data to the database, which is particularly
beneficial for unit testing and validation workflows.

Highlights:

- New Library Creation: A new library, ores.telemetry.database, has been
  introduced to encapsulate database-specific functionality related to
  telemetry, effectively separating concerns from the core ores.telemetry
  library.
- Repository File Relocation: All telemetry repository-related files (entity,
  mapper, and repository implementations) have been moved from ores.telemetry to
  the newly created ores.telemetry.database library. This includes corresponding
  header and source files.
- Circular Dependency Resolution: The architectural split eliminates circular
  dependencies between the ores.telemetry and ores.database components,
  improving modularity and maintainability.
- Database Logging Sink: A new Boost.Log sink backend (database_sink_backend)
  has been implemented within ores.telemetry to allow direct logging of
  telemetry data to the database. This is particularly useful for unit testing
  scenarios where logs need to be captured and validated against a database.
- Messaging Component Updates: Messaging components within ores.comms.service
  have been updated to correctly reference the new ores.telemetry.database.lib
  and adjust namespace usage for database contexts.
- Build System and Examples: CMake build configurations have been updated to
  include the new library and manage its dependencies. New example files
  demonstrate how to integrate and use the database logging sink.
#+end_quote

**** Add database logging for tests
#+begin_quote

This pull request significantly enhances the testing and telemetry
infrastructure by enabling direct logging of unit test telemetry data to the
database. It addresses critical tenant provisioning issues, ensuring tests
operate within their correct tenant contexts, and introduces a more granular
tenant lifecycle management system. Furthermore, the telemetry architecture has
been refactored to improve modularity and prevent recursive logging, making the
system more robust and maintainable.

Highlights:

- Telemetry Database Logging Integration: Integrated a database logging sink
  with the unit test framework, allowing test logs to be persisted to the
  database for debugging and analysis. This is controlled by the new
  ORES_TEST_LOG_DATABASE CMake option.
- Tenant Provisioning Fix: Corrected an issue in tenant provisioning where the
  wrong column was selected for the tenant ID, leading to tests incorrectly
  using the system tenant. The tenant_id is now reliably stored in the database
  context.
- Three-Tier Tenant Lifecycle: Introduced a new three-tier tenant lifecycle:
  'terminate' (marks inactive, preserves all data), 'deprovision' (soft-deletes
  temporal data, preserves non-temporal), and 'purge' (hard-deletes everything).
  A new SQL function ores_iam_terminate_tenant_fn was added for the 'terminate'
  stage.
- Recursive Logging Prevention: Implemented a skip_telemetry_guard (RAII
  attribute) to prevent recursive logging loops within telemetry components when
  telemetry operations themselves generate logs.
- Telemetry System Refactoring: Refactored the telemetry system by introducing a
  dedicated ores.telemetry.database library. This resolves circular dependencies
  between core telemetry and database components, enhancing modularity and
  testability.
- Unit Test Coverage: Added comprehensive unit tests for the
  database_sink_backend and telemetry_repository components to ensure the
  reliability of the new database logging and data persistence mechanisms.
#+end_quote

*** COMPLETED Add system accounts for services                         :code:
    :LOGBOOK:
    CLOCK: [2026-02-04 Wed 09:00]--[2026-02-04 Wed 12:32] =>  3:32
    :END:

Services should also "login" and start sessions. This is needed so we can
associate their log files with the session. Use the same account as we use for
database.

Notes:

- unit tests should also "log in" and create sessions so we can see stats.
- add performed by as per audit requirements.

#+begin_quote
This pull request significantly enhances the system's auditing capabilities by
distinguishing between the database user and the application account responsible
for changes. It also introduces a robust framework for managing service
accounts, enabling secure authentication for automated processes. Furthermore,
it addresses a critical deadlock in the telemetry system and refines several
core database bootstrap and tenant management processes for improved stability
and reliability.

Highlights:

- Performed By Audit Field: A new 'performed_by' field has been introduced
  across all 42 domain tables to track the application account initiating an
  action, complementing the existing 'modified_by' (database user). This change
  is propagated through codegen templates for C++ domain classes, mappers,
  protocol serialization, and Qt UI, ensuring comprehensive auditing.
- Service Account Management: New 'account_type' classifications (user, service,
  algorithm, LLM) are now supported, with dedicated service accounts created for
  non-human entities. Service accounts are designed to authenticate via sessions
  only, without passwords, and are integrated into the IAM schema and population
  scripts.
- Telemetry Deadlock Resolution: A critical fix has been implemented for a
  telemetry async sink deadlock by introducing a 'skip_telemetry_guard' and
  applying a filter to prevent recursive logging during database operations,
  enhancing system stability.
- SQL Bootstrap and Tenant Fixes: Various issues in SQL bootstrap and population
  scripts have been resolved, including proper versioning for tenant termination
  and ensuring system tenant context is set on service startup. A fail-fast
  validation was also added to 'tenant_aware_pool' acquisition to prevent
  operations without a defined tenant context.
#+end_quote

*** COMPLETED Test shell functionality with tenancy enabled            :code:
    :LOGBOOK:
    CLOCK: [2026-02-05 Thu 13:43]--[2026-02-05 Thu 15:39] =>  1:56
    CLOCK: [2026-02-05 Thu 11:10]--[2026-02-05 Thu 12:20] =>  1:10
    CLOCK: [2026-02-05 Thu 10:10]--[2026-02-05 Thu 11:10] =>  1:00
    CLOCK: [2026-02-04 Wed 22:51]--[2026-02-05 Thu 00:02] =>  1:11
    CLOCK: [2026-02-04 Wed 21:33]--[2026-02-04 Wed 22:50] =>  1:17
    CLOCK: [2026-02-04 Wed 21:00]--[2026-02-04 Wed 21:32] =>  0:32
    CLOCK: [2026-02-04 Wed 14:25]--[2026-02-04 Wed 16:26] =>  2:01
    CLOCK: [2026-02-03 Tue 22:50]--[2026-02-03 Tue 23:27] =>  0:37
    :END:

Ensure tenancy is working correctly with several scenarios:

- log in as super admin.
- create tenant admin account and login to tenant.
- create tenant user account and login.

Notes:

- bootstrap, stop service then start service. System is in bootstrap mode again.

**** Improve Authentication

#+begin_quote
This pull request significantly enhances the client-side authentication
experience by introducing dedicated helper functions for login and logout,
centralizing complex logic and simplifying client implementations. It also
undertakes a crucial refactoring of core messaging enums into more granular,
auto-generated headers, which improves code organization and maintainability
across the communication layer. The changes aim to provide a cleaner, more
robust API for client interactions with the IAM service.

Highlights:

- Client-Side Authentication Helpers: Introduced a new ores.iam::client
  namespace with high-level login() and logout() helper functions. These helpers
  encapsulate the full authentication flow, significantly reducing boilerplate
  code in client applications like the shell and Qt clients.
- Messaging Enum Refactoring: The monolithic
  ores.comms/messaging/message_types.hpp header has been refactored into three
  distinct headers: message_type.hpp (for message type enum),
  compression_type.hpp (for compression type enum), and protocol.hpp (for
  protocol constants like magic and version). This improves modularity and
  reduces include dependencies.
- C++ Enum Code Generation: Added a new code generation profile and template
  (cpp_enum.hpp.mustache) to ores.codegen. This enables automatic generation of
  C++ enum classes with string conversion and stream output operators from JSON
  model definitions, as demonstrated by the new compression_type_enum.json and
  message_type_enum.json.
- Client Code Simplification: The shell client's auto_login, process_login, and
  process_logout functions have been refactored to utilize the new client-side
  authentication helpers, reducing their code footprint and improving
  maintainability.
- Dependency Update: The ores.iam project now explicitly links against
  ores.comms.lib to support the new client-side authentication helpers.
#+end_quote

*** COMPLETED Fix apt-get failures on nightly build                    :code:
    :LOGBOOK:
    CLOCK: [2026-02-05 Thu 09:50]--[2026-02-05 Thu 10:10] =>  0:20
    :END:

#+begin_quote
This pull request significantly improves the robustness of Debian package
installations within the CI environment by introducing comprehensive retry
mechanisms and making the installation process more configurable. It streamlines
the install_debian_packages.sh script, enhances its reliability against
transient network issues, and adds a convenient option for installing Valgrind,
which is beneficial for memory debugging in nightly builds.

Highlights:

- Retry Logic: Implemented exponential backoff for apt-get operations in
  install_debian_packages.sh to enhance CI reliability, with 5 retries starting
  at a 5-second delay.
- APT Retries: Configured apt-get commands to use Acquire::Retries=3, providing
  download-level resilience for package fetching.
- Valgrind Option: Added a --with-valgrind flag to the installation script,
  allowing optional installation of Valgrind for specific build types like
  nightly builds.
- Script Refactoring and Bug Fix: Cleaned up the install_debian_packages.sh
  script, including converting packages to an array and fixing a bug where
  apt-get clean and apt-get autoremove were incorrectly placed on the same line.
- Nightly Workflow Update: The nightly build workflow was updated to utilize the
  new --with-valgrind flag, streamlining the Valgrind installation process.
#+end_quote

*** COMPLETED Refactor tenant lookup functions to accept const context :code:
    :LOGBOOK:
    CLOCK: [2026-02-05 Thu 21:02]--[2026-02-05 Thu 22:00] =>  0:58
    :END:

The tenant lookup functions (=resolve_tenant_id=, =lookup_by_code=,
=lookup_by_hostname=) currently take =context&= (non-const reference) even
though they only perform read operations. This forces callers to create
unnecessary mutable copies when they have a const context.

Current workaround in =tenant_context.cpp=:
#+begin_src cpp
// Creates unnecessary copy just to satisfy non-const parameter
auto lookup_ctx = ctx.with_tenant(ctx.tenant_id());
const auto resolved = resolve_tenant_id(lookup_ctx, tenant);
#+end_src

Refactoring these to accept =const context&= would:

- Eliminate unnecessary context copies
- Better express the read-only nature of lookups
- Allow callers to use const contexts directly

*** COMPLETED Refactor message handlers for per-request tenant context :code:
    :LOGBOOK:
    CLOCK: [2026-02-06 Fri 00:43]--[2026-02-06 Fri 01:49] =>  1:06
    CLOCK: [2026-02-05 Thu 23:49]--[2026-02-06 Fri 00:42] =>  0:53
    CLOCK: [2026-02-05 Thu 22:01]--[2026-02-05 Thu 23:48] =>  1:47
    CLOCK: [2026-02-05 Thu 17:00]--[2026-02-05 Thu 18:10] =>  1:10
    :END:

Message handlers currently use a fixed database context that is set at
construction time (typically with system tenant). When users from different
tenants authenticate and make requests, their operations execute in the wrong
tenant context, causing data isolation failures.

The session correctly stores the tenant_id from login, but handlers don't use it
to create per-request database contexts. This is a security issue that can lead
to cross-tenant data leakage.

See design document: =doc/design/multi_tenant_message_handling.org=

#+begin_quote
This pull request significantly enhances the multi-tenancy architecture by
introducing a type-safe tenant_id wrapper and refactoring message handlers to
use per-request database contexts. This ensures robust tenant isolation and
prevents data leakage by explicitly associating each request with its correct
tenant. The system tenant identifier has also been updated to a more
semantically appropriate value to avoid conflicts with uninitialized UUIDs.

Highlights:

- Per-Request Tenant Context: Message handlers now create database contexts
  per-request using the session's tenant_id, ensuring each request executes in
  the correct tenant's RLS context. This fixes potential cross-tenant data
  leakage. A new base class, tenant_aware_handler, has been introduced to
  encapsulate this logic.
- Type-Safe tenant_id Wrapper: A new strong type, utility::uuid::tenant_id, has
  been introduced to wrap boost::uuids::uuid. It includes factory methods
  (system(), from_uuid(), from_string()) that prevent construction with nil
  UUIDs, query methods (is_system(), is_nil()) for tenant identification, and
  conversion methods (to_uuid(), to_string()) for interoperability. This
  enhances type safety and prevents accidental nil UUID usage.
- System Tenant Change: The system tenant identifier has been changed from the
  nil UUID (00000000-...) to the max UUID (ffffffff-...) as defined by RFC 9562.
  This change prevents accidental confusion with uninitialized
  boost::uuids::uuid values, which default-construct to nil.
- Serialization Helpers: Serialization helpers have been added for the new
  tenant_id type in both the binary protocol and JSON (using reflect-cpp),
  ensuring seamless data transfer and persistence.
- Refactored Message Handlers and Repositories: Numerous message handlers and
  repository methods across ores.assets, ores.dq, ores.iam, ores.refdata,
  ores.telemetry, and ores.variability have been updated to leverage the new
  tenant_aware_handler base class and accept context objects directly, promoting
  per-request context creation and improving tenant isolation.
#+end_quote

**** Acceptance Criteria

- Handlers create per-request database contexts using session's tenant_id
- Each request executes in the correct tenant's RLS context
- Multi-tenant concurrent requests don't interfere with each other
- ThreadSanitizer build passes under concurrent load

**** Tasks

- [ ] Refactor =accounts_message_handler= to use per-request context
- [ ] Refactor =risk_message_handler= to use per-request context
- [ ] Refactor =dq_message_handler= to use per-request context
- [ ] Refactor =assets_message_handler= to use per-request context
- [ ] Refactor =telemetry_message_handler= to use per-request context
- [ ] Refactor =variability_message_handler= to use per-request context
- [ ] Add multi-tenant concurrent integration test
- [ ] Run ThreadSanitizer build and verify no races

**** Notes

PR #410 completed the foundation work:
- Added =tenant_id= to =session_data= and =session_info=
- Made =tenant_context= immutable
- Fixed RLS policies and raw query tenant context
- Added design document

The handler refactoring pattern is:
#+begin_src cpp
// Before: Fixed context at construction
class handler {
    database::context ctx_;
    service svc_{ctx_};  // Caches wrong tenant
};

// After: Per-request context from session
class handler {
    sqlgen::ConnectionPool<Connection> pool_;

    database::context make_context(const session_info& session) {
        return database::context(pool_, creds_, to_string(session.tenant_id));
    }
};
#+end_src

*** COMPLETED Review DQ metadata tables for multi-tenancy support  :analysis:
    :LOGBOOK:
    CLOCK: [2026-02-06 Fri 09:00]--[2026-02-06 Fri 10:41] =>  1:41
    :END:

Several DQ metadata tables have unique version indexes without =tenant_id=,
which prevents different tenants from having the same metadata entries:

Affected tables:
- =ores_dq_catalogs_tbl= (name, version)
- =ores_dq_change_reason_categories_tbl= (code, version)
- =ores_dq_change_reasons_tbl= (code, version)
- =ores_dq_coding_scheme_authority_types_tbl= (code, version)
- =ores_dq_data_domains_tbl= (name, version)
- =ores_dq_datasets_tbl= (id, version)
- =ores_dq_methodologies_tbl= (id, version)
- =ores_dq_nature_dimensions_tbl= (code, version)
- =ores_dq_origin_dimensions_tbl= (code, version)
- =ores_dq_subject_areas_tbl= (name, domain_name, version)
- =ores_dq_treatment_dimensions_tbl= (code, version)

Needs analysis to determine:
- Should DQ metadata be global (shared across tenants) or tenant-specific?
- If global, how should publishing work for DQ metadata tables?
- If tenant-specific, add =tenant_id= to all version unique indexes

Note: =ores_dq_coding_schemes_tbl= was fixed as part of the immediate publish
bug, but the broader design question remains.

#+begin_quote
This pull request significantly enhances the application's multi-tenancy
capabilities and improves the user experience in the Qt client. It introduces
robust mechanisms for tenant-specific data management in the database, refines
data publishing logic for images, and delivers several quality-of-life
improvements to the connection browser and login dialog. Additionally, a new
administrative shell command streamlines role assignment, and underlying
database functions are secured for proper cross-tenant operations.

Highlights:

- Multi-tenant Data Publishing: The database schema has been updated to support
  multi-tenant data publishing by adding tenant_id to unique version indexes
  across numerous tables, including assets (images, tags), DQ metadata
  (catalogs, change reasons, data domains, datasets, methodologies, dimensions),
  and reference data (countries). This ensures data uniqueness within each
  tenant's context.
- Image ID Resolution Fix: Publishing functions for currency and country data
  now correctly resolve image_id by looking up the image key from DQ images and
  then finding the corresponding image in the target tenant's assets table. This
  addresses issues where image UUIDs might differ across datasets or tenants
  during publishing.
- UI Usability Improvements: Several enhancements have been made to the Qt UI,
  particularly in the connection browser. Connections and folders are now sorted
  alphabetically, the tree expansion state is preserved after modifications
  (save, edit, delete), inline editing fields display existing names, and
  dialogs close the MDI sub-window instead of the main application window.
- New Shell Command for Role Assignment: A new permissions suggest command has
  been added to the ORE Studio Shell. This command generates a series of
  accounts assign-role commands, simplifying the process of assigning all
  available roles to a specified user account, identified by username and either
  hostname or tenant ID.
- Image Cache Management: The ImageCache now includes a clear() method, which is
  called before reloading the cache after an image dataset is published. This
  ensures a full refresh of image data, preventing potential issues with stale
  or incorrectly mapped image UUIDs following publishing operations.
- Database Security Enhancements: The ores_iam_generate_role_commands_fn
  PostgreSQL function has been updated with SECURITY DEFINER. This allows the
  function to execute with the privileges of the user who created it, enabling
  necessary cross-tenant access for administrative utility functions related to
  role assignment.
#+end_quote

*** COMPLETED vcpkg is still not caching correctly                     :code:
    :LOGBOOK:
    CLOCK: [2026-02-06 Fri 13:56]--[2026-02-06 Fri 14:55] =>  0:59
    CLOCK: [2026-02-06 Fri 13:30]--[2026-02-06 Fri 13:56] =>  0:26
    :END:

Investigate the issue.

#+begin_quote
- Replace the removed x-gha vcpkg binary caching backend with the files provider
  backed by actions/cache@v4 across all 5 CI workflow files
- The x-gha backend was silently removed from vcpkg, causing all 120 packages to
  be rebuilt from source on every run (~21 min wasted per build)
- First run will populate the cache (cold start); subsequent runs should see
  vcpkg install drop from ~21 min to seconds

Affected workflows:

- canary-linux.yml (PR trigger - will run immediately)
- continuous-linux.yml (push to main - after merge)
- continuous-windows.yml (push to main - after merge)
- continuous-macos.yml (push to main - after merge)
- nightly-linux.yml (scheduled - after merge)
#+end_quote

*** COMPLETED Check that data librarian can publish across tenants     :code:
    :LOGBOOK:
    CLOCK: [2026-02-06 Fri 10:41]--[2026-02-06 Fri 11:45] =>  1:04
    CLOCK: [2026-02-06 Fri 01:50]--[2026-02-06 Fri 03:37] =>  1:47
    :END:

Ensure publication still works as expected.

#+begin_quote
This pull request significantly enhances the application's multi-tenancy
capabilities and improves the user experience in the Qt client. It introduces
robust mechanisms for tenant-specific data management in the database, refines
data publishing logic for images, and delivers several quality-of-life
improvements to the connection browser and login dialog. Additionally, a new
administrative shell command streamlines role assignment, and underlying
database functions are secured for proper cross-tenant operations.

Highlights:

- Multi-tenant Data Publishing: The database schema has been updated to support
  multi-tenant data publishing by adding tenant_id to unique version indexes
  across numerous tables, including assets (images, tags), DQ metadata
  (catalogs, change reasons, data domains, datasets, methodologies, dimensions),
  and reference data (countries). This ensures data uniqueness within each
  tenant's context.
- Image ID Resolution Fix: Publishing functions for currency and country data
  now correctly resolve image_id by looking up the image key from DQ images and
  then finding the corresponding image in the target tenant's assets table. This
  addresses issues where image UUIDs might differ across datasets or tenants
  during publishing.
- UI Usability Improvements: Several enhancements have been made to the Qt UI,
  particularly in the connection browser. Connections and folders are now sorted
  alphabetically, the tree expansion state is preserved after modifications
  (save, edit, delete), inline editing fields display existing names, and
  dialogs close the MDI sub-window instead of the main application window.
- New Shell Command for Role Assignment: A new permissions suggest command has
  been added to the ORE Studio Shell. This command generates a series of
  accounts assign-role commands, simplifying the process of assigning all
  available roles to a specified user account, identified by username and either
  hostname or tenant ID.
- Image Cache Management: The ImageCache now includes a clear() method, which is
  called before reloading the cache after an image dataset is published. This
  ensures a full refresh of image data, preventing potential issues with stale
  or incorrectly mapped image UUIDs following publishing operations.
- Database Security Enhancements: The ores_iam_generate_role_commands_fn
  PostgreSQL function has been updated with SECURITY DEFINER. This allows the
  function to execute with the privileges of the user who created it, enabling
  necessary cross-tenant access for administrative utility functions related to
  role assignment.
#+end_quote

Errors:

#+begin_quote
=== Publication Results ===

[FAILED] slovaris.country_flags
  Target: assets_images_tbl
  Error: Query execution failed: ERROR: duplicate key value violates unique constraint "ores_assets_images_version_uniq_idx" DETAIL: Key (image_id, version)=(14e65ed1-2e75-4f27-8e05-ba13a65a279f, 1) already exists. CONTEXT: SQL statement "insert into ores_assets_images_tbl ( tenant_id, image_id, version, key, description, svg_data, modified_by, performed_by, change_reason_code, change_commentary ) values ( p_target_tenant_id, coalesce(v_existing_image_id, r.image_id), 0, r.key, r.description, r.svg_data, current_user, current_user, 'system.external_data_import', 'Imported from DQ dataset: ' || v_dataset_name ) returning version" PL/pgSQL function ores_dq_images_publish_fn(uuid,uuid,text) line 63 at SQL statement

[SUCCESS] slovaris.currencies
  Target: refdata_currencies_tbl
  Records: 100 inserted, 0 updated, 0 skipped, 0 deleted

[FAILED] slovaris.countries
  Target: refdata_countries_tbl
Error: Query execution failed: ERROR: duplicate key value violates unique constraint "ores_refdata_countries_version_uniq_idx" DETAIL: Key (alpha2_code, version)=(AL, 1) already exists. CONTEXT: SQL statement "insert into ores_refdata_countries_tbl ( tenant_id, alpha2_code, version, alpha3_code, numeric_code, name, official_name, coding_scheme_code, image_id, modified_by, performed_by, change_reason_code, change_commentary ) values ( p_target_tenant_id, r.alpha2_code, 0, r.alpha3_code, r.numeric_code, r.name, r.official_name, v_coding_scheme_code, v_resolved_image_id, current_user, current_user, 'system.external_data_import', 'Imported from DQ dataset: ' || v_dataset_name ) returning version" PL/pgSQL function ores_dq_countries_publish_fn(uuid,uuid,text) line 82 at SQL statement

[SUCCESS] geo.ip2country
  Target: geo_ip2country_tbl
  Records: 512186 inserted, 0 updated, 0 skipped, 0 deleted

=== Summary ===
Datasets processed: 4
Succeeded: 2, Failed: 2
Total records: 512286 inserted, 0 updated, 0 skipped, 0 deleted
#+end_quote

*** COMPLETED Check that eventing works correctly across tenants       :code:
    :LOGBOOK:
    CLOCK: [2026-02-06 Fri 18:07]--[2026-02-06 Fri 18:33] =>  0:26
    CLOCK: [2026-02-06 Fri 14:56]--[2026-02-06 Fri 18:06] =>  3:10
    :END:

Create events from different tenants and ensure they are processed correctly.

#+begin_quote
This pull request significantly enhances the multi-tenancy isolation within the
notification system. By integrating tenant_id across the entire notification
flow—from database triggers generating events, through the event bus, and
finally to the subscription manager—it ensures that sensitive entity change
notifications are strictly confined to their respective tenant boundaries. This
change is crucial for maintaining data segregation and security in a
multi-tenant environment, while also preserving backward compatibility for
existing broadcast mechanisms.

Highlights:

- Tenant ID Propagation: The tenant_id is now consistently passed through the
  entire notification pipeline, from SQL triggers to domain events and the
  subscription manager.
- SQL Trigger Enhancement: SQL triggers have been updated to embed the tenant_id
  within their JSONB notification payloads, enabling tenant-specific event
  sourcing.
- Subscription Manager Filtering: The subscription_manager::notify() method now
  incorporates tenant-aware filtering, ensuring that notifications are only
  delivered to sessions associated with the relevant tenant.
- Backward Compatibility: The system gracefully handles cases where tenant_id is
  empty or the session service is not configured, falling back to broadcasting
  notifications to all subscribers.
- Comprehensive Testing: Five new test cases have been added to validate tenant
  matching, broadcast behavior, cross-tenant isolation, pre-login session
  handling, and scenarios without a configured session service.
#+end_quote

* Footer

| Previous: [[id:154212FF-BB02-8D84-1E33-9338B458380A][Version Zero]] |
