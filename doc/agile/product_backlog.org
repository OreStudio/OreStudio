:PROPERTIES:
:ID: 558650A4-C3E5-8964-4193-7D9125E29B83
:END:
#+options: date:nil toc:nil author:nil num:nil
#+title: Product Backlog
#+tags: { reviewing(r) }
#+tags: { code(c) infra(i) doc(d) agile(a) }
#+startup: inlineimages

This document contains the [[http://www.mountaingoatsoftware.com/agile/scrum/product-backlog][product backlog]] for VisualOre.

* Product Vision

Here we define what we consider to be the [[http://www.scaledagileframework.com/vision/][the vision]] for the product; what
guides us when we think about the product and what can and cannot go into the
product backlog.

** Vision Statement

The vision for ORE Studio is to build on top of [[https://github.com/OpenSourceRisk/Engine][ORE]] with the aim of providing:

- a persistent database storage for all of its inputs and outputs;
- a graphical user interface both for data generation as well as data exploration;
- the ability to configure and orchestrate ORE execution.

** Vision Quotes

#+begin_quote
People think focus means saying yes to the thing you've got to focus on. But
that's not what it means at all. It means saying no to the hundred other good
ideas that there are. You have to pick carefully. I'm actually as proud of the
things we haven't done as the things I have done. Innovation is saying no to
1,000 things. -- Steve Jobs
#+end_quote

* Release Checklist

Steps to create a new release.

** Close previous sprint

To be done on the last Sunday of the sprint.

1. Make a copy of current sprint backlog and name it current sprint + 1.
2. Move all untouched stories into product backlog.
3. Close current sprint: close all open tasks, delete tasks we did not work on,
   update clocks.
4. Push commit and wait for builds. This ensures that if there are any failures
   you can fix them before the release tag.
4. Tag commit and sign it with key.
5. Push tag. You can generate new builds overnight.
6. When tag build is finished, unpack and copy binaries into release, announce
   twitter and linked in.

** Open new sprint

Note: use Claude to do this via the [[id:C5EEF144-BB9D-2F44-453B-4B7338D8A457][New Sprint Skill]].

1. Open new sprint, updating CMake version, README, GitHub (packages),
   =vcpkg.json=. Build all and run tests. This should all be in one commit.
2. Create a demo. Publish it on youtube.
3. Write up release notes, publish them in github.

* Stories

** Near

Stories we may get two in the next two or three sprints.

*** Add support for FIX                                                :code:

Links:

- [[https://github.com/jamesdbrock/hffix][GH: hffix]]: "The High Frequency FIX Parser library is an open source
  implementation of tagvalue FIX (classic FIX) intended for use by developers of
  high frequency, low latency financial software. The purpose of the library is
  to do fast, efficient encoding and decoding of FIX in place, at the location
  of the I/O buffer. The library does not use intermediate message objects, and
  it does no memory allocation on the free store (the ‚Äúheap‚Äù)."

*** Consider adding "global search" via typesense                      :code:

Typesense:

#+begin_quote
Typesense is a fast, typo-tolerant search engine for building delightful search
experiences.
#+end_quote

We could pump specially crafted documents into typesense with IDs and types and
then let users search across any type of entity.


Links:

- [[https://github.com/typesense/typesense][GH typesense]]


*** Add a generic tagging system                                       :code:

It should be possible to associate any entity with one or more tags and then do
a search by tags on that entity type. For example, tag a set of currencies as
emerging markets and then search by that.

Labels versus tags:

#+begin_src markdown
That is an **excellent question** that gets to the heart of cloud governance and
system design. You are correct that the underlying structure is fundamentally
the same‚Äîa **key-value pair attached to a resource**‚Äîbut the distinction is
necessary because of the **context, governance, and enforcement mechanisms**
applied to each one.

The distinction between GCP Labels and Tags boils down to **Annotation vs.
Policy**.

---

## ‚öñÔ∏è Why the Distinction is Necessary

| Feature              | GCP **Labels** (Annotation)                                                                          | GCP **Tags** (Policy/Governance)                                                                                                                                               |
|:---------------------|:-----------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Primary Goal**     | **Organization, filtering, cost allocation, and reporting.**                                         | **Policy enforcement, access control, and hierarchical governance.**                                                                                                           |
| **Structure**        | **Flexible/Arbitrary.** Key-Value pair set directly on the resource.                                 | **Structured/Centralized.** Key and Value are defined *centrally* as separate resources (at the Organization/Project level) and then *bound* to the resource.                  |
| **Hierarchy**        | **Flat.** A resource does not inherit labels from its parent folder.                                 | **Hierarchical.** Tags are inherited by child resources (like a VM inheriting a tag from its containing project).                                                              |
| **Access Control**   | **Low Control.** Any user with permissions to modify the resource can typically modify its labels.   | **High Control.** Dedicated **IAM Roles** are required to create, manage, and even attach Tag Keys and Values. This prevents users from "tagging" their way out of a policy.   |
| **Enforcement**      | **None.** Labels are metadata and cannot be used directly in IAM conditions to grant or deny access. | **High.** Tags are the *only* mechanism designed for **conditional IAM policies** and Organization Policies (e.g., "deny deletion unless resource has tag `environment:dev`"). |
| **Use Case Example** | Filtering the console: "Show me all resources labeled `owner:john_doe`."                             | Security: "Only allow network traffic from resources tagged `security_zone:trusted`."                                                                                          |

### Analogy: The Whiteboard vs. The Building Code

1.  **Labels are like a sticky note on a whiteboard:**
    ,* They are **flexible**, quickly written, and easy to change.
    ,* They are used for **informal organization** (cost center, app name, etc.).
    ,* Changing the note has **no impact on the resource's function** or security.

2.  **Tags are like a building code requirement:**
    ,* They are **highly structured** and defined by a central authority (the city/organization).
    ,* They are used to **enforce policy** (safety, compliance).
    ,* If a resource (a building) doesn't have the correct tag (e.g., a **fire-rating tag**), an automated system (the policy engine) will **deny an action** (e.g., deny occupation or modification).

---

## How This Relates to Your SVG System

Your current **three-table model** is structurally a **GCP Label** system‚Äîit's
excellent for annotation and filtering (e.g., "Give me all icons with the tag
'currency'").

If you wanted to implement a **GCP Tag** concept, you would need to:

1.  **Formalize the Tags:** Create certain tags as *official resources* (like
    `Status` with official values `Draft`, `Approved`, `Production`).
2.  **Add Permissions:** Implement **application logic** that checks a user's
    role against the tag. For example: "A user needs the `Approver` role to
    apply the `Status:Production` tag to an icon."

The need to distinguish them comes down to providing one system that is
,**flexible for organization (Labels)** and another that is **rigid for security
and compliance (Tags)**.
#+end_src

Examples:

- majors, minors, EM, latam, etc are tags we can have on currencies. On currency
  pairs, We could also have USD crosses, which is inferred by having USD as one
  of the pair. However these are not labels because we do not want everyone to
  start using them. When defining a report, you could associate currencies and
  currency pairs to the report via the tags.
- labels are things we could associate with images for example. Flags could have
  both "countries" and "currencies" labels so that when we want to select a flag
  as the image for a currency, we could ask for all images labelled
  "currencies". The labelling can be done by pretty much anyone.


*** Add "uptime" screen                                                :code:

See the claude page for ideas:

[[./v0/anthropic_uptime_page.jpeg]]

*** Mine dexter for ideas                                              :code:

#+begin_quote
Dexter is an autonomous financial research agent that thinks, plans, and learns
as it works. It performs analysis using task planning, self-reflection, and
real-time market data. Think Claude Code, but built specifically for financial
research.
#+end_quote

Links:

- [[https://github.com/virattt/dexter][GH dexter]]

*** Add support for PDF generation                                     :code:

A lot of legal documents require PDF support. This story keeps track of useful
PDF libraries.

Links:

- [[https://github.com/libharu/libharu][GH libharu]]: "Haru is a free, cross platform, open-sourced software library for
  generating PDF. It supports the following features."

*** Troubleshoot skills in claude                                     :infra:

We don't seem to be able to use skills reliably.

Links:

- [[https://code.claude.com/docs/en/skills][Claude: Agent Skills]]
- [[https://www.reddit.com/r/ClaudeCode/comments/1oywsa1/claude_code_skills_activate_20_of_the_time_heres/][reddit: Claude Code skills activate 20% of the time. Here's how I got to 84%.]]
- [[https://scottspence.com/posts/how-to-make-claude-code-skills-activate-reliably][How to Make Claude Code Skills Activate Reliably]]

*** BLOCKED Add support for offsets in pagination                      :code:

*Rationale*: we cannot work on this story until sqlgen reviews and merges our
PR, and releases it into vcpkg. PR now merged, awaiting release and availability
in vcpkg.

At present we disabled pagination in UI because sqlgen does not support offset.
We implemented this feature in sqlgen. When it is released to vcpkg we should
update our code to use it.

Remember also this:

#+begin_src c++
    // HACK: Using single connection instead of session because sqlgen sessions
    // doesn't seem to support SELECT FROM with aggregations. Plain connections
    // work fine. This is a temporary workaround until the sqlgen library is
    // fixed. See: https://github.com/getml/sqlgen/issues/99
    struct count_result {
        long long count;
    };
#+end_src

Links:

- [[https://github.com/getml/sqlgen/issues/100][GH #100: Feature request: offset support]]

*** Automated SQL generation                                           :code:

At present we are manually creating the SQL. We should be able to do it from
sqlgen.

*** Missing shell functionality                                        :code:

The job of the client is to exercise the entirety of the comms protocol, and to
provide a way to perform CRUD operations via command line. Note:

- client never access the repositories directly, it should do exactly the same as the qt client
  would do.
- client's only interface is the REPL.
- client will eventually be used by AI agents.

Client needs to have messages at the entity level:

- currencies:
  - import currencies from ORE Format. Given a path in the filesystem, it
    performs the import using the importer and appropriate comms messages.
  - export currencies to ORE format. Uses comms to obtain the currencies, then
    the exporter to convert, then dumps them into the terminal as ORE XML.
  - list existing currencies as a table or as JSON. We need support for latest,
    "at time point" and "all" (meaning every single version). It should be
    possible to supply some filtering by the entity's ID (e.g.
    =--iso-code=).
  - delete one or more currencies. User supplies a number of entity IDs (e.g.
    =--iso-code ABC --iso-code CDE --iso-code FGH= and so on).
  - add a currency supplying arguments (e.g. =--iso-code= and so forth).
  - add currencies from JSON.
- accounts:
  - list existing currencies as a table or as JSON. We need support for latest,
    "at time point" and "all" (meaning every single version). It should be
    possible to supply filtering by the entity's ID.
  - delete one or more accounts. User supplies a list of entity IDs.
  - add an account supplying arguments.
  - add accounts from JSON.
- feature flags:
  - list existing feature flags as a table or as JSON. We need support for
    latest, "at time point" and "all" (meaning every single version). It should
    be possible to supply some filtering by the entity's ID
  - delete one or more feature flags. User supplies a list of entity IDs.
  - add feature flags supplying arguments.
  - add feature flags from JSON.

Notes:

- update recipes with the new client commands.

*** Invalid password should not throw                                  :code:

At present in the unlock test we have:

#+begin_src c++
    BOOST_LOG_SEV(lg, info) << "Locking account by failing 5 login attempts";
    auto ip = internet::ipv4();
    for (int i = 0; i < 5; ++i) {
        try {
            sut.login(account.username, "wrong_password", ip);
        } catch (...) {}
    }
#+end_src

This is very suspicious; a failed login should just return false or the modern
c++ equivalent (=std::expected=?).

*** Faker with seeds                                                   :code:

As suggested by phi4:

#+begin_quote
Faker Usage:

Randomness: Ensure that the use of faker data is appropriate for testing.
Consider seeding the random generator for reproducibility in tests.
#+end_quote

Notes:

#include "faker-cxx/generator.h"
void setSeed(std::mt19937_64::result_type seed)
Catch::rngSeed()


*** Improve handling of error responses                                :code:

As per Gemini code review:

#+begin_src markdown
Certainly. Point #2 from the review of `CurrencyHistoryDialog.cpp` addressed
the potential complexity of error checking by suggesting that relying on the
specific response message type is **fragile**.

The goal is to move from:

1.  Client sends **Request A**.
2.  Server returns **Response A** (Success) OR **Error Response** (Failure) OR
    ,**Response B** (Unexpected success type).
3.  Client checks: *Is the message type exactly **Response A**?*

to a more robust pattern where the client checks for a generic failure response
first.

-----

## üêû Fragile Error Check (Current Code)

The current code in `loadHistory` checks for success by expecting *only* the
specific success message type:

```cpp
// Current Fragile Logic
if (result->header().type != comms::protocol::message_type::get_currency_history_response) {
    onHistoryLoadError(QString("Server does not support currency history (received message type %1)")
        .arg(static_cast<int>(result->header().type)));
    return;
}
```

This logic has two main problems:

1.  **Hiding Server Errors:** If the server returns a generic protocol error
    (`message_type::error_response`) because, for example, the client's session
    timed out, the client logs a misleading message: "Server does not support
    currency history." It should be reporting the actual error message sent by
    the server.
2.  **Lack of Standardization:** Every client method needs to implement its own
    logic to handle unexpected types.

-----

## üõ†Ô∏è Suggested Improvement: Standardized Error Handling

The improvement is to check for a generic **`error_response`** message type
first, and report its payload/message, before attempting to deserialize the
successful response.

Assuming your system has a standard `error_response` message:

```cpp
void CurrencyHistoryDialog::handleHistoryResponse(const HistoryResult& result) {
    if (!result) {
        onHistoryLoadError(QString::fromStdString(result.error()));
        return;
    }

    // 1. Check for a generic server-side error response
    if (result->header().type == comms::protocol::message_type::error_response) {
        // Assume error_response contains a readable message payload
        auto error_response = risk::messaging::error_response::deserialize(result->payload());
        if (error_response) {
            onHistoryLoadError(QString::fromStdString(error_response->message));
        } else {
            onHistoryLoadError("Server returned a malformed error response.");
        }
        return;
    }

    // 2. Check for the specific SUCCESS response type
    if (result->header().type == comms::protocol::message_type::get_currency_history_response) {
        auto response = risk::messaging::get_currency_history_response::deserialize(result->payload());

        if (!response || !response->success) {
            // Handle success=false within the expected response type
            onHistoryLoadError(QString::fromStdString(response ? response->message : "Invalid or failed history response."));
            return;
        }

        history_ = std::move(response->history);
        onHistoryLoaded();
        return;
    }

    // 3. Handle truly unexpected message type
    onHistoryLoadError(QString("Received unexpected message type %1 from server.")
        .arg(static_cast<int>(result->header().type)));
}
```

By standardizing the **`error_response`** type, the client can always extract
and display the relevant server-side failure reason, leading to much clearer
logging and user feedback.
#+end_src

*** Do not disable cert verification                                   :code:

At present we've hacked cert verify to false. We should not do this. Gemini:

#+begin_quote
You cannot use Let's Encrypt for development purposes because it requires a
public domain name that Let's Encrypt can verify, and your local development
server is not publicly accessible. The recommended approach is to create a local
certificate authority (CA) using a tool like mkcert to sign your certificates,
which allows you to bypass browser warnings for local domains like localhost.

Option 1: Use mkcert for local development

- Install mkcert: Follow the instructions to install the mkcert tool on your
  system.
- Install the local CA: Run the command to install the local CA root certificate
  into your system's trust store. This is a one-time setup.
- Generate a local certificate: Use mkcert to generate certificates for your
  local development domains (e.g., localhost, my-app.local). The generated
  certificates will be signed by your trusted local CA and will not cause
  browser warnings.

Option 2: Use Let's Encrypt with a real public domain

Purchase a domain: Buy a public domain name (e.g., mydomain.dev).

- Use an ACME client: Use an ACME client like Certbot to automate the
  certificate process. You can run certbot on a server that is accessible to the
  public internet.
- Complete the validation: The client will need to verify your ownership of the
  domain through a DNS or HTTP challenge, which requires the domain to be
  publicly reachable.
- Deploy the certificate: Let's Encrypt will issue a certificate that you can
  then deploy to your development server.

Why Let's Encrypt doesn't work for local development

- Let's Encrypt's primary purpose is to secure public-facing websites by
  automatically verifying domain ownership.
- They use ACME protocol challenges (DNS or HTTP) that require the public
  internet to access your server at the specified domain.
- Since your local server is not on the public internet, it cannot respond to
  these challenges, and Let's Encrypt cannot verify your ownership of the
  domain.
#+end_quote

*** Add =[[nodiscard]]= to repository operations returning data        :code:

At present we can create an account and ignore the result, etc. We should be
forced to look at the result.

*** CLI Importing needs to read from database                          :code:

After we do the import into the database, we need to read the currencies again
to get the valid from/to.

*** Add output option to repl                                          :code:

It should be possible to set the "output type" or format in the shell, from json
to table. Find the correct terminology for this.

*** Add more account commands                                          :code:

See the azeroth account commands for inspiration.

Links:

- [[https://www.azerothcore.org/wiki/gm-commands][GM Commands]]

*** Improve error message when server is not running                   :code:

At present we get:

#+begin_quote
Failed to connect to server: Failed to connect to server
#+end_quote

If we try again after the error, "authenticating..." shows up in red.

*** Update currency details to use tabs                                :code:

We need a main tab with the currency related properties, then a "system" tab
with temporal data which is read-only even on edit and a "image" tab with the
image used to represent the currency. It could also contain some description or
notes.

*** Consider adding log command line options to qt                     :code:

At present we have hard-coded logging options. However, maybe users should be
able to change the logging settings from the UI rather than having to restart
the app and supply command line options.



*** Troubleshoot skills in claude                                     :infra:

We don't seem to be able to use skills reliably.

Links:

- [[https://code.claude.com/docs/en/skills][Claude: Agent Skills]]
- [[https://www.reddit.com/r/ClaudeCode/comments/1oywsa1/claude_code_skills_activate_20_of_the_time_heres/][reddit: Claude Code skills activate 20% of the time. Here's how I got to 84%.]]
- [[https://scottspence.com/posts/how-to-make-claude-code-skills-activate-reliably][How to Make Claude Code Skills Activate Reliably]]

*** Add entity related charts                                          :code:

Have a think on things that could benefit from a graphical display at the entity
level. Some ideas:

- entity history: number of additions, edits, deletions over time. Bar chart.
  Makes it easier to pick up weird system problems. This is overall across all
  instances.
- single entity history. In the history tab for that entity, graph showing the
  changes to the entity over time.

In addition, we need to be able to support charts in ASCII so that we can see
them in the REPL. This will be used by the AI agents.

Links:

- [[https://github.com/Civitasv/asciichart][GH asciichart]]

*** Add skill to review product backlog                               :infra:

We could get claude to review the stories, add more details, etc. Needs more
thinking.

*** Add skill to update vcpkg                                         :infra:

As per instructions in [[id:CB42DFE5-804B-E1C4-E1E3-0A6C4766609C][readme]].

*** Ensure applications work under OSX using github images             :code:

We need to install the DMG and run the app.

We think the package does not have all of the dependencies, but this did not
work:

#+begin_src cmake
if(APPLE)
    install(CODE "
        # make sure the bundle is already on disk
        set(BU_CHMOD_BUNDLE_ITEMS TRUE)
        include(BundleUtilities)

        # full path to the real executable inside the bundle
        set(app_exe \"\${CMAKE_INSTALL_PREFIX}/OreStudio.app/Contents/MacOS/OreStudio\")

        # directory where 3rd-party libraries will be copied
        set(libs_dir \"\${CMAKE_INSTALL_PREFIX}/OreStudio.app/Contents/Frameworks\")

        # discover all prerequisites and copy/fix them
        fixup_bundle(\"\${app_exe}\" \"\" \"\${libs_dir}\")
    " COMPONENT Runtime)
endif()
#+end_src

We should ask someone with an OSX machine to test this.

Links:

- [[https://stackoverflow.com/questions/17974439/cant-use-fixup-bundle-to-create-a-portable-bundle-with-qt][SO: Can't use fixup_bundle() to create a portable bundle with Qt]]



*** Make UI/UX look more professional                                  :code:

Links:

- [[https://www.claude.com/blog/improving-frontend-design-through-skills][Improving frontend design through Skills]]
- [[https://github.com/VoltAgent/awesome-claude-skills][Awesome Claude Skills]]
- [[https://devexperts.com/blog/ui/][Designing User Interface in the Trading Software]]
- [[https://www.businesswire.com/news/home/20240109821427/en/The-New-B2Core-v4---Modern-Interfaces-and-Revamped-Designs][The New B2Core v4 - Modern Interfaces and Revamped Designs]]

Analysis from Gemini:

#+begin_src markdown
To make your Qt application look like an advanced trading system‚Äîeven for a
simple CRUD operation screen‚Äîrequires moving beyond basic desktop application
styles toward the dense, high-contrast, data-rich aesthetic of platforms like
Bloomberg or professional broker terminals.

The current look (a dark table with simple data rows) is a great foundation.
Here are targeted suggestions for your Qt UI to elevate it to a professional,
advanced trading system aesthetic:

## I. Color and Contrast (The Dark Theme)

Your current dark gray background is good, but trading systems use specific
contrast to highlight data significance.

1.  **Define a Palette:** Adopt a limited, functional color palette:

      ,* **Primary Background:** A very dark, near-black charcoal (`#1A1A1A` or
        `#1E1E1E`). This is the foundation.
      ,* **Foreground/Text:** Clean white or light gray (`#F0F0F0`).
      ,* **Accent Color (Neutral):** A subdued corporate blue/cyan (`#007ACC` or
        a subtle green/gold from your branding) for selected rows, borders, and
        input focus.
      ,* **Data Status Colors:**
          ,* **Positive (Gains):** Bright, high-contrast green (`#00C853`).
          ,* **Negative (Losses):** High-contrast red (`#FF3333`).
          ,* *(While CRUD isn't about gains/losses, you can use these colors for
            status, like 'Active' vs. 'Inactive' currencies).*

2.  **Subtle Depth:** Avoid flat black. Use a slightly lighter shade of gray
    (`#2A2A2A`) for embedded panels, sidebars, and control areas to create
    visual segmentation, giving the impression of modularity.

## II. Typography and Data Presentation

Trading UIs prioritize density and scannability.

1.  **Monospace Font:** For the currency codes and numerical columns, switch to
    a clear, legible **monospace font** (like Consolas, Fira Code, or a custom
    font in Qt). Monospace fonts ensure that all numbers align perfectly in
    columns, which is essential for rapid data comparison.
2.  **Font Sizing:** Use a small, consistent font size (e.g., 10pt or 11pt) to
    fit more data on screen. Use bolding sparingly, primarily for the Currency
    Code (e.g., USD, EUR).
3.  **Visual Alignment:**
      ,* **Text Columns** (Currency Name): Left-aligned.
      ,* **Code Columns** (ISO Code, Symbol): Center-aligned.
      ,* **Numerical Columns** (Rounding, Precision): Right-aligned. **This is
        critical** for financial UIs, as it allows users to compare magnitude
        instantly.

## III. Advanced Table View Enhancements (QTableView/QTableWidget)

Since the core of this screen is a table, focus on making the table look
high-tech.

1.  **Header Styling:**

      ,* Make column headers slightly stand out with a subtle dark gradient or a
        distinct, slightly brighter background color (e.g., `#282828`).
      ,* Ensure the header font is crisp (perhaps slightly bolder than the row
        data).
      ,* Add tiny, clear **sort indicators** to show the current sort direction.

2.  **Row Selection:**

      ,* The selected row should use your accent color (e.g., a thin blue left
        border or a light blue background fill) with white or light gray text
        for high visibility.
      ,* Introduce **subtle, faint horizontal rules** (1px in a color like
        `#333333`) to separate rows, which aids readability in dense tables.

3.  **Interactive Elements (Hover):** Implement a very subtle change on row
    hover (e.g., the background darkens by 5%) to indicate interactivity, even
    if clicking doesn't change the view.

## IV. UI Layout and Modularity

Advanced UIs are rarely monolithic; they are built from modular panels.

1.  **Toolbar (Top):** Create a clean, dedicated toolbar area at the top for
    your CRUD operations (`Add`, `Edit`, `Delete`) and your system icons
    (Connection, Reference Data).

      ,* Use the Fluent UI System Icons you researched (`globe-32-regular`,
        `money-32-regular`).
      ,* Buttons should be flat, high-contrast text or icons only. On hover, they
        should reveal a subtle gray background or a thin accent border.

2.  **Side Panel (Right or Left):** Instead of a simple dialog for *editing*,
    use a dedicated side panel that slides out or appears next to the table when
    a row is selected.

      ,* This panel would house the detail view for the selected currency. This
        makes the UI feel like a single workspace rather than navigating modal
        windows.
      ,* Give this panel a slightly different background shade (`#2A2A2A`).

3.  **Status Bar (Bottom):** Add a sleek, minimal status bar at the bottom. This
    is where you would place your connection status icon (using your proposed
    `globe-32-regular` or `plug-connected-32-regular` icon). It reinforces the
    "system is live" feel.

## V. Qt-Specific Implementation via Stylesheets

In Qt, you achieve this professional look primarily through **QSS (Qt Style
Sheets)**. You will be targeting specific widgets (like `QTableView`,
`QPushButton`, `QLineEdit`) with CSS-like rules.

```css
/* Example QSS Snippets for the Trading Look */

QTableView {
    /* Base style for the data area */
    background-color: #1A1A1A; /* Primary Background */
    gridline-color: #333333; /* Faint row separators */
    color: #F0F0F0;
    border: 1px solid #007ACC; /* Subtle border using accent color */
    selection-background-color: #007ACC; /* Accent Color for selection */
    selection-color: white;
}

QHeaderView::section {
    /* Style for Column Headers */
    background-color: #282828; /* Slightly lighter shade for headers */
    color: #FFFFFF;
    border: none;
    padding: 6px;
    font-size: 11pt;
    font-weight: bold;
}

QLineEdit {
    /* Style for input fields (e.g., in the side panel or search) */
    background-color: #1A1A1A;
    border: 1px solid #444444;
    color: #F0F0F0;
    padding: 5px;
}

QPushButton {
    /* Flat button style for toolbar */
    background-color: transparent;
    border: none;
    color: #F0F0F0;
    padding: 8px 12px;
}

QPushButton:hover {
    /* Hover effect */
    background-color: #2A2A2A;
    border: 1px solid #007ACC;
}
```
#+end_src

*** Current issues with package install in debian                      :code:

At present we have several issues with packaging:

- debs are built on ubuntu so they cannot install on latest debian testing as
  the t64 migration has been completed. Error:

#+begin_src sh
root@lovelace:~# apt install /home/marco/Downloads/orestudio_0.0.4_amd64.deb
You might want to run 'apt --fix-broken install' to correct these.
Unsatisfied dependencies:
 orestudio : Depends: libqt6gui6t64 (>= 6.1.2) but it is not installable
             Depends: libqt6widgets6t64 (>= 6.1.2) but it is not installable
Error: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).
root@lovelace:~# apt install libqt6widgets6t64 libqt6gui6t64
Package libqt6gui6t64 is not available, but is referred to by another package.
This may mean that the package is missing, has been obsoleted, or
is only available from another source
However the following packages replace it:
  libqt6gui6:i386  libqt6gui6


Package libqt6widgets6t64 is not available, but is referred to by another package.
This may mean that the package is missing, has been obsoleted, or
is only available from another source
However the following packages replace it:
  libqt6widgets6:i386  libqt6widgets6


Error: Package 'libqt6widgets6t64' has no installation candidate
Error: Package 'libqt6gui6t64' has no installation candidate
#+end_src

- when starting the package from a directory, it tries to create the log
  relative to that directory:

#+begin_src sh
[marco@lovelace ~]$ /opt/OreStudio/0.0.4/bin/ores.qt
terminate called after throwing an instance of 'boost::filesystem::filesystem_error'
  what():  boost::filesystem::create_directories: Permission denied [system:13]: "/home/marco/../log", "/home/marco/../log"
Aborted                    /opt/OreStudio/0.0.4/bin/ores.qt
#+end_src


    :LOGBOOK:
    CLOCK: [2025-11-09 Sun 21:00]--[2025-11-09 Sun 21:14] =>  0:14
    :END:

When investigating a crash we noticed the app is not exiting cleanly. Fix all of
these crashes before we go any further.



*** Add UI for log viewing                                             :code:

We should be able to see the log from qt.

Notes:

- it should be possible to change the log level from the UI for both the Qt app
  and the service.

Links:

- [[https://github.com/Dingola/Qt-LogViewer/tree/main][GH: Qt-LogViewer]]

*** Add support for simple log shipping                                :code:

It would be very useful to be able to browse both client and server logs from
the client (either command line or qt). This will be even more useful with AI
agents. Add a simple component that periodically loads up the logs to the
database.

Possible names: log shipping, log forwarding, etc.

*** Add skill to improve UI design                                     :code:

Make the UI more professional.

Links:

- [[https://github.com/VoltAgent/awesome-claude-skills][Awesome Claude Skills]]
- [[https://github.com/ComposioHQ/awesome-claude-skills][another awesome-claude-skills]]
- [[https://github.com/diet103/claude-code-infrastructure-showcase/tree/main][claude-code-infrastructure-showcase]]

*** Create basic manual                                                :code:

We should start populating the manual from the start. Ensure there is a claude
skill that updates the manual as we add new entities. Create a PDF build for it.
We can use templates from thesis. Link it to site so that yuo can browse it.

*** Do not return sensitive fields                                     :code:

As per code review:

#+begin_quote
Major Security Flaw (list_accounts_response): The serialization format
explicitly includes highly sensitive fields (password_hash, password_salt,
totp_secret) for every domain::account returned. This is a severe security risk.
These fields must not be exposed over any messaging protocol, even internal
ones, unless it is a dedicated, highly protected replication channel.

Proposed Change: Create a protocol-safe subset structure, e.g.,
domain::account_summary, which contains only non-sensitive data (id, username,
email, is_admin, version, modified_by). Update list_accounts_response to use
std::vector<domain::account_summary>.

Change list_accounts_response::accounts to use a non-sensitive type like
std::vector<domain::account_summary>.
#+end_quote
*** Merge toolbars when you maximise currencies                        :code:

At present we end up with two tool bars, one below the other.

*** Local versus remote connectivity                                   :code:

In some cases it makes sense to use the UI directly against the database - for
example, users may just want to create a simple setup to play around and the
complexity of having to have a server is not helpful. In addition, they may not
even require a full blown postgres - sqlite is enough. It should be possible to
setup a connection to a database in this manner. Ideally the client should
support both at the same time.

*** History should have a revert button                                :code:

It should be possible to choose a given version and ask the system to revert the
currency to that version. It just makes an update with a new version to look
like that version. It should also be possible to open at version. It shows the
edit dialog in "read only mode" with the entity at that version. The tool bar
should indicate this. It should also have a revert in that dialog.

*** Assorted UI polish work                                            :code:

Break these down into their own stories:

- icons for CRUD are not enabling when on detached mode.
- no status bar in dettached mode.
- should we just have toolbars at the detached window level?
- application should exit when main window is closed.
- is it possible to dock windows like visual studio?
- add a detach current window that just detaches that window.
- disabled menu options are not properly greyed out. Done.

*** Allow in place editing of currencies                               :code:

For expediency users should be able to edit multiple currencies and save them in
one go directly in the grid. Shift enter to edit a field seems interesting.

Users need to be made aware when there are changes in CRUD objects, and there
needs to be a reload button to reload data from the database in that case. This
could be done by making the reload button a different colour when data is
available.

Make the reload button blue when there are changes.

Notes:

- history windows should also have the notification.

*** Light system theme results in mix of dark and light                :code:

We need to ensure we can have both light and dark themes and they work
consistently.

*** Setup Qt properly on Windows                                       :code:

Seems like our package is still missing Qt DLLs. Use the windows tool to
determine what is missing. Consider installing Qt in the build machine via the
built packages.

*** Add SC script on windows to install ores.service                   :code:

We should package a trivial batch file that sets up the service on windows. We
should also consider adding a simple script to setup the service on Linux.
Ideally it should be done via the packaging step.

*** Package SQL scripts                                                :code:

We need to initialise the database on installation. The package should contain
all of the necessary SQL as well as a script to do it.

Or maybe we should do everything from within sqlgen and generate the scripts for
the cases where we need manual work in database.

*** Remove postgres passwords from github workflows                    :code:

As a quick hack we added the dev passwords to the workflows. We should really
generate these on the fly and supply them to the tests.

*** Allow supplying the postgres connection URI                        :code:

At present we are supplying all of the components for the connection. It may be
easier to allow the entire URI:

- connection-uri: The connection URI to connect to PostgreSQL. Example:
  =postgresql://postgres:postgres@localhost/postgres=.

*** Consider adding MCP support                                        :code:

From Kaggle course:

#+begin_quote
Model Context Protocol (MCP) is an open standard that lets agents use
community-built integrations. Instead of writing your own integrations and API
clients, just connect to an existing MCP server.

MCP enables agents to:

- Access live, external data from databases, APIs, and services without custom
  integration code
- Leverage community-built tools with standardized interfaces
- Scale capabilities by connecting to multiple specialized servers

2.1: How MCP Works

MCP connects your agent (the client) to external MCP servers that provide tools:

- MCP Server: Provides specific tools (like image generation, database access)
- MCP Client: Your agent that uses those tools

All servers work the same way - standardized interface Architecture:

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Your Agent     ‚îÇ
‚îÇ   (MCP Client)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ Standard MCP Protocol
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ        ‚îÇ        ‚îÇ
    ‚ñº         ‚ñº        ‚ñº        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ GitHub ‚îÇ ‚îÇSlack‚îÇ ‚îÇ Maps ‚îÇ ‚îÇ ... ‚îÇ
‚îÇ Server ‚îÇ ‚îÇ MCP ‚îÇ ‚îÇ MCP  ‚îÇ ‚îÇ     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
#+end_quote

Links:

- [[https://github.com/hkr04/cpp-mcp][GH: cpp-mcp]]
- [[https://github.com/Qihoo360/TinyMCP][GH: TinyMCP]]

*** Add country support                                                :code:

We will probably need country support at some point. We should link the country
to the currencies, where applicable.

*** Log file location for Qt application is non-standard on Linux      :code:

At present we need to manually create the log directory for the gui to fix this
error:

#+begin_quote
[marco@lovelace bin]$ ./ores.qt
terminate called after throwing an instance of 'boost::filesystem::filesystem_error'
  what():  boost::filesystem::create_directories: Permission denied [system:13]: "/opt/OreStudio/0.0.3/bin/../log", "/opt/OreStudio/0.0.3/bin/../log"
Aborted                    ./ores.qt
#+end_quote

We should really output the log file in a standard location such as /var/log or
something.

*** Create shared object interfaces                                    :code:

At present we are building shared objects / DLLs for the ores components, but we
did not bother defining proper interfaces, exporting symbols etc. This causes
problems on windows:

#+begin_src sh
LINK : fatal error LNK1104: cannot open file 'projects\ores.utility\ores.utility.lib'
#+end_src

This is happening because we are not exporting explicitly any symbols. To fix
this we did a hack:

#+begin_src cmake
if(WIN32 AND MSVC)
    # Export all symbols on windows for now. Bit of a hack.
    set(CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS ON)
endif()
#+end_src

The right solution for this is to annotate all the public types of each SO
correctly, exporting symbols for all platforms:

Deep seek analysis:

#+begin_src markdown
Yes, Boost provides a cross-platform wrapper for exporting symbols using the
`BOOST_SYMBOL_EXPORT` macro from the **Boost.DLL** library. This macro abstracts
away the compiler-specific keywords required for different platforms.

### üóÇÔ∏è Boost's Cross-Platform Symbol Exporting

To export a symbol, you use the `BOOST_SYMBOL_EXPORT` macro in your code. Under
the hood, it expands to the correct compiler-specific attribute:

- On **Windows** with MSVC, it becomes `__declspec(dllexport)`
- On **macOS** and **Linux** with GCC/Clang, it becomes `__attribute__((visibility("default")))`

Here is a basic example of how to use it to export a global variable:

```cpp
#include <boost/config.hpp> // For BOOST_SYMBOL_EXPORT

class my_plugin_api {
    // Your interface definition
};

namespace my_namespace {
    class my_plugin_sum : public my_plugin_api {
        // Implementation
    };

    // Export the 'plugin' variable
    extern "C" BOOST_SYMBOL_EXPORT my_plugin_sum plugin;
    my_plugin_sum plugin;
}
```
,*Note: The `extern "C"` is used here to prevent C++ name mangling, making the symbol name
predictable for tools that use C linkage. This is often crucial for a library's public API.*

For exporting factory functions, Boost offers the `BOOST_DLL_ALIAS` macro, which
is often more convenient:

```cpp
#include <boost/dll/alias.hpp> // For BOOST_DLL_ALIAS

namespace my_namespace {
    class my_plugin_aggregator : public my_plugin_api {
        // Implementation
    };

    // Factory function
    boost::shared_ptr<my_plugin_api> create() {
        return boost::shared_ptr<my_plugin_aggregator>(new my_plugin_aggregator());
    }

    // Export the factory function with the alias "create_plugin"
    BOOST_DLL_ALIAS(my_namespace::create, create_plugin)
}
```

### üí° A Complementary Approach: Controlling Visibility

While Boost's macro solves the declaration problem, for finer control and to
minimize your shared library's public API, combine it with compiler flags that
hide all symbols by default.

- **On Linux and other ELF platforms**, use the `-fvisibility=hidden` flag. You
  can then use a **linker version script** to explicitly list the symbols you
  want to export.
- **On macOS**, use the `-fvisibility=hidden` flag and an **exported symbols
  list** with `-exported_symbols_list` during linking.
- **On Windows**, symbol visibility is typically controlled explicitly via
  `__declspec(dllexport)` or a module definition (.def) file, which
  `BOOST_SYMBOL_EXPORT` already handles.

Setting default visibility to hidden helps create a cleaner, more efficient
library by reducing its footprint, improving load times, and avoiding potential
symbol conflicts.

### üîß Summary

For a complete cross-platform solution:

1. **Use Boost.DLL macros**: Incorporate `BOOST_SYMBOL_EXPORT` or
   `BOOST_DLL_ALIAS` in your code to handle platform-specific export keywords.
2. **Hide symbols by default**: Compile your shared library with
   `-fvisibility=hidden` on Linux and macOS. This works in conjunction with the
   Boost macros.
3. **Use version scripts (optional)**: For maximum control on ELF platforms
   (Linux) or via an exported symbols list on macOS, use these linker features
   to define a precise public API.

I hope this helps you build your cross-platform shared library! If you have more
questions about using the Boost.DLL library for loading these symbols at
runtime, feel free to ask.
#+end_src

Links:

- [[https://stackoverflow.com/questions/76338106/cmake-how-to-produce-both-dll-and-lib-as-outputs][SO: "CMAKE" - how to produce both ".dll" and ".lib" as outputs]]

*** Update timestamps to use timezone                                  :code:

Links:

- [[https://justatheory.com/2012/04/postgres-use-timestamptz/][Always Use TIMESTAMP WITH TIME ZONE]]

*** Add support for JWT                                                :code:

When we add support for HTTP/REST, we need to ensure it uses JWT.

Links:

- [[https://iniakunhuda.medium.com/building-secure-jwt-authentication-in-go-with-postgresql-94b6724f9b75][Building Secure JWT Authentication in Go with PostgreSQL]]
- [[https://github.com/Thalhammer/jwt-cpp][GH jwt-cpp]]

*** Read up on ECS                                                 :analysis:

Links:

- [[https://en.wikipedia.org/wiki/Entity_component_system][wikipedia: Entity component system]]
- [[https://github.com/skypjack/entt][GH entt]]: "EnTT is a header-only, tiny and easy to use library for game
  programming and much more written in modern C++."

*** Consider adding otel support                                       :code:

Links:

- [[https://github.com/destrex271/postgresexporter][GH postgresexporter]]: "Unofficial Postgres Exporter for OTEL"
- [[https://opentelemetry-cpp.readthedocs.io/en/latest/otel_docs/classopentelemetry_1_1sdk_1_1trace_1_1SpanExporter.html][SpanExporter]]: create your own exporter.

*** Instrument components with telemetry context                        :code:

Now that logging has been integrated with telemetry, the next step is to
instrument key components with the =TLOG_SEV= macro to enable trace correlation.

Tasks:

- Instrument =server_session= with root span on connection, child spans per
  request.
- Instrument =client_session= with spans for outgoing requests.
- Pass =telemetry_context= through message handlers in ores.iam, ores.risk, etc.
- Add spans for database operations in ores.database.

*** Add trace context propagation to messaging protocol                 :code:

To enable distributed tracing across client and server, trace context needs to
be propagated in the messaging protocol.

Tasks:

- Extend frame header to include optional trace_id and span_id fields.
- Update frame serialization/deserialization.
- Client includes trace context in outgoing request frames.
- Server extracts trace context and creates child spans linked to client's
  trace.

*** Create span collection and export infrastructure                    :code:

The telemetry component has span types defined but no infrastructure to collect
and export completed spans.

Tasks:

- Create =span_collector= interface for accumulating completed spans.
- Implement =span_exporter= interface (similar to =log_exporter=).
- Create =file_span_exporter= that writes spans as JSON Lines.
- Integrate span export with =lifecycle_manager= or create =telemetry_provider=.

*** Add OTLP exporter for OpenTelemetry collector                       :code:

For production observability, export telemetry data to an OpenTelemetry
collector using the OTLP protocol.

Tasks:

- Add OTLP protocol buffer definitions or use existing C++ OTLP library.
- Implement =otlp_log_exporter= for log records.
- Implement =otlp_span_exporter= for traces.
- Add configuration for collector endpoint.
- Consider gRPC vs HTTP transport.

Links:

- [[https://opentelemetry.io/docs/specs/otlp/][OTLP Specification]]
- [[https://github.com/open-telemetry/opentelemetry-cpp][opentelemetry-cpp]]

*** Add chat support                                                   :code:

Links:

- [[https://github.com/communi/libcommuni][GH libcommuni]]: "A cross-platform IRC framework written with Qt."
- [[https://github.com/inspircd/inspircd/tree/insp4][GH insp4]]: "InspIRCd is a modular C++ Internet Relay Chat (IRC) server for
  UNIX-like and Windows systems."
- https://www.inspircd.org/

*** Consider exposing end points via HTTP                              :code:

Having a binary protocol is helpful for performance but it may make life easier
to expose some functionality via HTTP.

Links:

- [[https://github.com/dfleury2/beauty][GH: beauty]]: "Beauty is a layer above Boost.Beast which provide facilities to
  create Http server or client. Beauty allows the creation of synchronous or
  asynchronous server and client, and adds some signals and timer management
  based on Boost.Asio"
- [[https://www.boost.org/doc/libs/latest/libs/beast/doc/html/beast/examples.html#beast.examples.servers][Boost beast examples]]
- [[https://www.boost.org/doc/libs/latest/libs/json/doc/html/index.html][Boost JSON]]

Merged:

*Create HTTP end point for currencies*

Add a basic HTTP server using boost beast. Then we just need a couple of verbs:

- GET: return all currencies in database.
- POST: add one or more currencies.

*** Consider using getML to integrate ML                               :code:

Links:

- [[https://github.com/getml/getml-community][GH: getml]]: "getML is a tool for automating feature engineering on relational
  data and time series. It includes a specifically customized database Engine
  for this very purpose."
- [[https://getml.com/latest/user_guide/quick_start/][user guide quick start]]

*** Configure postgres with async IO                                   :code:

Links:

- [[https://neon.com/postgresql/postgresql-18/asynchronous-io][PostgreSQL 18 Asynchronous I/O]]

*** Consider using sqls for LSP                                        :code:

We are presently testing postgrestools. If that does not work well, we should
consider sqls.

Links:

- [[https://www.reddit.com/r/emacs/comments/ijbvwv/eglot_sqls_sql_client/][eglot + sqls = SQL client?]]

*** Add workspace as a container                                       :code:
    :LOGBOOK:
    CLOCK: [2025-02-13 Thu 22:18]--[2025-02-13 Thu 22:35] =>  0:17
    CLOCK: [2025-02-13 Thu 21:21]--[2025-02-13 Thu 22:17] =>  0:56
    :END:

Core needs to have a container for all of the data stored within a context.

Actually, according to Data Priented Principles, we may not need it. This may be
a UI concept but not a code concept.

*** Add portfolio support                                              :code:

Links:

- [[https://leonardqmarcq.com/posts/modeling-hierarchical-tree-data][Modeling Hierarchical Tree Data in PostgreSQL]]

*** Setup code quality actions                                        :infra:

We added a test password to the repo on purpose to see if it was going to be
detected by the github actions:

#+begin_src c++
    std::string connection_string("postgresql://ores:ores@localhost:5433/oresdb");
#+end_src

It wasn't. We need to figure out which actions need to be setup for this. Add
any other actions we may be missing.

The build seems to be failing:

#+begin_src sh
-- SCCache NOT found.
 CMake Error at /usr/local/share/cmake-3.30/Modules/CMakeDetermineSystem.cmake:152 (message):
   Could not find toolchain file:
   /home/runner/work/OreStudio/OreStudio/vcpkg/scripts/buildsystems/vcpkg.cmake
 Call Stack (most recent call first):
 CMakeLists.txt:61 (project)


 CMake Error: CMake was unable to find a build program corresponding to "Unix Makefiles".  CMAKE_MAKE_PROGRAM is not set.  You probably need to select a different build tool.
 CMake Error: CMAKE_CXX_COMPILER not set, after EnableLanguage
 -- Configuring incomplete, errors occurred!
 ~/work/OreStudio/OreStudio ~/work/OreStudio/OreStudio
 ~/work/OreStudio/OreStudio
 cpp/autobuilder: No supported build command succeeded.
 cpp/autobuilder: autobuild summary.
 Error: We were unable to automatically build your code. Please replace the call to the autobuild action with your custom build steps. Encountered a fatal error while running "/opt/hostedtoolcache/CodeQL/2.18.0/x64/codeql/cpp/tools/autobuild.sh". Exit code was 1 and last log line was: cpp/autobuilder: autobuild summary. See the logs for more details.
#+end_src

This may be due to a missing sub-module for vcpkg.

*** Add a message queue                                                :code:

Links:

- [[https://www.oliverlambson.com/pgmq][Use what you already have: Building a message queue on Postgres]]

*** Starting UI from file manager does not work                       :infra:

At present we can't start the Qt UI because the file manager thinks its a video.
Maybe we need a desktop file.

Example desktop file:

#+begin_src conf
[Desktop Entry]
Comment=
Terminal=true
Name=fixvideo
Exec=/home/user/fixvideo.sh %f
Type=Application
Icon=/usr/share/icons/gnome/48x48/apps/gnome-settings-theme.png
Encoding=UTF-8
Hidden=false
NoDisplay=false
Categories=AudioVideo;Player;Recorder;
MimeType=video/dv;v
#+end_src

Source: [[https://emacs.stackexchange.com/questions/58037/is-there-a-standard-mode-for-ini-files][Is there a standard mode for .ini files?]]

Tasks:

- create a desktop file for the application.
- add an icon.

*** Consider adding the update copyrights action from quantlib        :infra:

We should remove copyrights from each file and instead have it only at the
top-level to make maintenance easier.

See [[https://github.com/OpenSourceRisk/QuantLib/blob/master/.github/workflows/copyrights.yml][=copyrights.yml=]] in QuantLib repo.

*** Investigate git UIs for history display                           :infra:

Links:

- [[https://github.com/Murmele/Gittyup][Gittyup]]: "Gittyup is a graphical Git client designed to help you understand
  and manage your source code history. "

*** Investigate GoldenCheetah for ideas on graph displays              :code:

Seems particularly useful for report overviews and headline positions.

Links:

- [[https://github.com/GoldenCheetah/GoldenCheetah][GH GoldenCheetah]]: "GoldenCheetah is a desktop application for cyclists and
  triathletes and coaches."

*** Add support for protocol debugging in Qt                           :code:

We should add a view of all messages sent and received like the comms champ
tools. It should be possible to record a session to file (maybe all the
requests?) and then replay that session. You should be able to do it from the
UI.

Links:

- [[https://github.com/commschamp/cc_tools_qt][GH: cc_tools_qt]]: "This project contains tool application(s), which can be used
  to develop, monitor and debug custom binary communication protocols, that were
  developed using the COMMS Library. All the applications are plug-in based,
  i.e. plug-ins are used to define I/O socket, data filters, and the custom
  protocol itself. The tools use Qt framework for GUI interfaces as well as
  loading and managing plug-ins."
- [[https://github.com/commschamp/cc_tools_qt/wiki/How-to-Use-CommsChampion-Tools][How to Use CommsChampion Tools]]: screenshots of the UI to explore the protocol.

*** Investigate the toolbar icon style in serial studio                :code:

Links:

- [[https://github.com/Serial-Studio/Serial-Studio][GH Serial-Studio]]

*** Investigate the graphs used in dirstat                             :code:

Seems like a good way of showing deal contribution to position.

Links:

- [[https://github.com/shundhammer/qdirstat][GH qdirstat]]

*** Consider adding clang-tidy build                                  :infra:

As per QuantLib build: [[https://github.com/OpenSourceRisk/QuantLib/blob/master/.github/workflows/tidy.yml][=tidy.yml=]].

*** Consider adding test times build                                  :infra:

As per QuantLib build: [[https://github.com/OpenSourceRisk/QuantLib/blob/master/.github/workflows/test-times.yml][=test-times.yml=]].

*** Consider adding sanitizer build                                   :infra:

As per QuantLib build: [[https://github.com/OpenSourceRisk/QuantLib/blob/master/.github/workflows/sanitizer.yml][=sanitizer.yml=]].

*** Use string views for static strings                               :infra:

We are creating =std::strings= where we don't need them, use string views
instead.

This is not trivial, when we tried a lot of things were borked.

*** Add discord support to app                                        :infra:

It would be nice if we could post messages from the app into discord.

Links:

- [[https://github.com/RealTimeChris/DiscordCoreAPI][DiscordCoreAPI]]

*** Recipes do not show variables in org-babel                        :infra:

At present when we look at a recipe in the site, we cannot tell what the
environment variables are:

#+begin_src sh
./ores.console import ${log_args} --currency-configuration ${currency_config_dir}/currencies.xml
#+END_SRC

It would be nice if =log_args= etc showed up in the recipe.

Links:

- [[https://kitchingroup.cheme.cmu.edu/blog/2019/02/12/Using-results-from-one-code-block-in-another-org-mode/][Using results from one code block in another org-mode]]

*** Install OSX package on OSX machine                                :infra:

We need to install and run the windows package and make sure it works. Check
console and GUI start.

*** Work through all types required for Example 1                      :code:

We want to be able to visualise all the data types needed in order to be able to
run the most basic example of ORE. For each of these types, create a stories.

The files are as follows. First, there are the files in the =Input= directory:

- [[https://github.com/OpenSourceRisk/Engine/tree/master/Examples/Example_1/Input][Example 1 Inputs]]

Specifically:

- =currencies.xml=
- =netting.xml=
- =ore.xml=
- =ore_swaption.xml=
- =plot.gp=
- =portfolio.xml=
- =portfolio_swap.xml=
- =portfolio_swap_20151023.xml=
- =portfolio_swaption.xml=
- =portfolio_swaption_20151023.xml=
- =simulation.xml=

In addition, we need all of the common inputs under:

- [[https://github.com/OpenSourceRisk/Engine/tree/master/Examples/Input][Examples - Common Inputs]]

These are:

- =calendaradjustment.xml=
- =conventions.xml=
- =currencies.xml=
- =curveconfig.xml=
- =fixings_20160205.txt=
- =market_20160205.txt=
- =market_20160205_flat.txt=
- =pricingengine.xml=
- =todaysmarket.xml=

Finally, we need support for the outputs. We can grab these from the expected
outputs:

- [[https://github.com/OpenSourceRisk/Engine/tree/master/Examples/Example_1/ExpectedOutput][Example 1 Expected Outputs]]

These are:

- =colva_nettingset_CPTY_A.csv=
- =curves.csv=
- =exposure_nettingset_CPTY_A.csv=
- =exposure_trade_Swap_20y.csv=
- =flows.csv=
- =log_progress.json=
- =netcube.csv=
- =npv.csv=
- =swaption_npv.csv=
- =xva.csv=

*** Consider adding support for A/B testing                            :code:

At present feature flags are global. However, we may want to enable a feature
for a subset of the population. Analysis:

#+begin_src markdown
To support **gradual rollout (ramping)** of features‚Äîe.g., enabling a feature
for 10% of users, then 50%, then 100%‚Äîyou need to extend your feature flag
system beyond a simple boolean toggle. The current temporal table design
(`feature_flags` with validity periods) is great for time-based control, but
,**not sufficient for user-based targeting**.

Here‚Äôs a practical, scalable approach that integrates well with your C++23/Qt/PostgreSQL stack:

---

### üéØ Goal
Enable a feature **conditionally** based on:
- User identity (e.g., user ID, tenant ID, or client ID)
- A **rollout percentage** (e.g., 10%)
- Optional: user attributes (role, region, etc.)

---

### ‚úÖ Step 1: Enhance the Feature Flag Schema

Add **rollout strategy metadata** to your `feature_flags` table:

```sql
ALTER TABLE oresdb.feature_flags
ADD COLUMN rollout_percentage INTEGER CHECK (rollout_percentage BETWEEN 0 AND 100) DEFAULT 100,
ADD COLUMN targeting_criteria JSONB; -- optional, for advanced rules
```

Now each flag version can specify:
- `rollout_percentage = 10` ‚Üí enable for ~10% of users
- `targeting_criteria = '{"role": "beta_tester"}'` ‚Üí (future extensibility)

> Keep your temporal primary key and exclusion constraint ‚Äî they still apply.

---

### ‚úÖ Step 2: Determine a Stable User Identifier

Your client must provide a **consistent, hashable ID** per user or session, such as:
- User ID (if authenticated)
- Device ID / client UUID (if anonymous)
- Tenant ID (for multi-tenant apps)

This ID must be **stable** across sessions so the same user doesn‚Äôt see the feature flicker on/off.

> üí° In your Qt client, generate or retrieve this ID at startup and pass it to the feature flag service.

---

### ‚úÖ Step 3: Implement Consistent Hash-Based Sampling in C++

Use a **deterministic hash** to map user IDs into a 0‚Äì99 bucket:

```cpp
#include <functional>
#include <string>

bool should_enable_for_user(std::string_view feature_name,
                            std::string_view user_id,
                            int rollout_percentage) {
    if (rollout_percentage <= 0) return false;
    if (rollout_percentage >= 100) return true;

    // Combine feature name + user ID to avoid correlation across features
    std::string key = std::string(feature_name) + ":" + std::string(user_id);

    // Use a stable hash (e.g., std::hash, but note: not guaranteed consistent across runs)
    // For production, prefer a consistent hash like FNV-1a or CityHash
    auto hash = std::hash<std::string>{}(key);
    int bucket = static_cast<int>(hash % 100);
    return bucket < rollout_percentage;
}
```

> ‚ö†Ô∏è **Warning**: `std::hash` is **not guaranteed to be stable across program runs or platforms**.
> For reliable rollout, use a **stable hashing algorithm** like **FNV-1a**, **MurmurHash3**, or **xxHash**.

Example with a simple FNV-1a (C++23-friendly):

```cpp
constexpr uint32_t fnv1a_32(std::string_view s) {
    uint32_t hash = 2166136261u; // FNV offset basis
    for (char c : s) {
        hash ^= static_cast<uint8_t>(c);
        hash *= 16777619u; // FNV prime
    }
    return hash;
}

bool should_enable_for_user(std::string_view feature_name,
                            std::string_view user_id,
                            int rollout_percentage) {
    if (rollout_percentage <= 0) return false;
    if (rollout_percentage >= 100) return true;

    std::string key{feature_name};
    key += ':';
    key += user_id;

    uint32_t hash = fnv1a_32(key);
    return (hash % 100) < static_cast<uint32_t>(rollout_percentage);
}
```

This ensures:
- Same user ‚Üí same decision
- Uniform distribution across users
- Independent per-feature rollout

---

### ‚úÖ Step 4: Update Your Feature Flag Service

Modify your C++ `FeatureFlagService`:

```cpp
class FeatureFlagService {
public:
    // Returns true if the feature is enabled AND user qualifies
    bool is_enabled_for_user(Feature f, std::string_view user_id) const;

private:
    struct FlagConfig {
        bool enabled;
        int rollout_percentage; // 0‚Äì100
        // add targeting_criteria later if needed
    };
    std::unordered_map<Feature, FlagConfig> cache_;
};
```

Implementation:

```cpp
bool FeatureFlagService::is_enabled_for_user(Feature f, std::string_view user_id) const {
    auto it = cache_.find(f);
    if (it == cache_.end() || !it->second.enabled) {
        return false;
    }
    return should_enable_for_user(to_string(f), user_id, it->second.rollout_percentage);
}
```

---

### ‚úÖ Step 5: Integrate in Qt UI

```cpp
QString userId = getCurrentUserId(); // from auth, settings, etc.

if (featureFlagService.is_enabled_for_user(Feature::ExperimentalUI, userId.toStdString())) {
    ui->experimentalPanel->show();
}
```

---

### ‚úÖ Optional: Advanced Targeting (Future-Proofing)

Use the `targeting_criteria JSONB` column to store rules like:
```json
{
  "min_version": "2.1.0",
  "regions": ["EU", "NA"],
  "roles": ["admin", "beta"]
}
```

Then evaluate these in C++ (or push filtering to DB with JSONB queries if you fetch per-user flags).

But for **simple ramp-up**, percentage-based hashing is sufficient and efficient.

---

### ‚úÖ Operational Benefits

- **No client-side config changes** needed to ramp from 10% ‚Üí 50% ‚Üí 100% ‚Äî just update the DB.
- **Auditability**: Every rollout change is versioned in your temporal table.
- **Safety**: You can instantly roll back by setting `rollout_percentage = 0`.

---

### Summary

| Component           | Change |
|---------------------|--------|
| **Database**        | Add `rollout_percentage INT` to `feature_flags` |
| **C++ Service**     | Add `is_enabled_for_user(feature, user_id)` |
| **Hashing**         | Use stable hash (e.g., FNV-1a) over `feature:user_id` |
| **Qt UI**           | Pass user ID to flag checks |

This gives you **safe, gradual, observable rollouts** while keeping your architecture clean and performant.
#+end_src



** Far

Stories that we want to capture, but won't work on for a while.

*** LLM Integration                                                    :code:

LLMs can be useful when learning a new subject as they can provide additional
context to the information displayed in the screen. For example, a user can ask
the LLM to explain a graph or a table. It would probably be fairly straight
forward to allow dumping some of the information in a format that is friendly to
LLMs (.e.g./ PNG, Markdown, plain text) and then make an API call to a local or
remote LLM. We could probably create a set of useful canned prompts (explain
this report, explain this chart).

On a more blue skies approach, one could conceive asking the LLM for suggestions
on how to act, on the basis of the analysis. This could result in suggestions
for action the user could implement, or even on actions directly taken based on
the LLM's suggestions. This is conceptually straightforward: the LLM could for
example generate a well defined JSON with the proposed action, and the system
would look for some predefined markers in the LLM output:

#+begin_src text
----- ACTION START
<JSON>
----- ACTION END
#+end_src

The JSON payload would describe the action:

#+begin_src json
{
    "action": "some_action_type",
    "key1": "value1",
    ....
#+end_src

A trivial lookup table could de-serialise the JSON and execute the action. All
that is required is for the LLM to "learn" how to generate JSON compliant with
the desired format, which should be quite straightforward (perhaps with the help
of fine-tuning). Agents probably provide most of this infrastructure already.
The key thing is to ensure all functionality in the core becomes UI agnostic
such that one could bolt an NLP UI around it.

Links:

- [[https://llama.meta.com/docs/how-to-guides/prompting/][How-to guides: Prompting]]
- [[https://mychen76.medium.com/practical-techniques-to-constraint-llm-output-in-json-format-e3e72396c670][Practical Techniques to constraint LLM output in JSON format]]

*** Support multiple ORE "toolchains"                                  :code:

Much like with an IDE, where one can have multiple toolchains configured, we
need to also support multiple versions of ORE. Unlike with IDEs, it may be
desirable to run computations with more than one version of ORE for comparison
purposes. This means we need a way to associate outputs with their ORE version.
This approach does not necessarily fit the existing example code, because these
have a single "output directory". However, we just need  way to associate N
toolchains with a given workspace or possibly component; when present, the
output directory starts to reflect the toolchain configuration. For example,
with CMake we use presets:

- =linux-clang-debug=
- =linux-clang-release=
- =linux-gcc-debug=
- =linux-gcc-release=

For ORE the only dimension under which variability is possible is the version.
We can then have pricing engine configurations that are either the same, or
possibly different:

- for a workspace;
- for a component;
- for a toolchain version.



*** Add faker support to model                                         :code:

vcpkg will support faker soon:

- [[https://github.com/microsoft/vcpkg/pull/38583][#38583: [faker-cxx] add new port]]

When that is available, we should try to add support for it.

*** Base the compute approach on BOINC                                 :code:

Copy the BOINC data model.

Links:

- [[https://boinc.berkeley.edu/trac/wiki/DataBase][wiki: DataBase]]
- [[https://wiki.debian.org/BOINC/ServerGuide][BOINC Debian Server Guide]]
- [[https://boinc.berkeley.edu/trac/wiki/ProjectMain][wiki: BOINC Project Main]]
- [[https://www.reddit.com/r/BOINC/][BOINC reddit]]


*** Create a set of fake currencies                                    :code:

We need to create fake data so we can explore the problem domain. This is
something to work on in the future. We can use LLMs to help with the fake data,
where it makes sense.

Example:

| Country code | Country name | Currency Code | Currency Number | Currency           |
|--------------+--------------+---------------+-----------------+--------------------|
| AL           | Aerilon      | ALD           |           10001 | Aerilonian Dollar  |
| AR           | Arcturia     | ARA           |           10002 | Arcturian Arct     |
| BA           | Balthoria    | BAF           |           10003 | Balthorian Florin  |
| BE           | Belloria     | BEB           |           10004 | Bellorian Bell     |
| CA           | Calandria    | CAC           |           10005 | Calandrian Crown   |
| CD           | Caledonia    | CDC           |           10006 | Caledonian Caled   |
| DA           | Daeloria     | DAD           |           10007 | Daelorian Dinar    |
| DE           | Delvadia     | DED           |           10008 | Delvadian Delv     |
| ER           | Eriador      | ERE           |           10009 | Eriadoran Euro     |
| ES           | Esteria      | ESE           |           10010 | Esterian Est       |
| FE           | Feloria      | FEF           |           10011 | Felorian Franc     |
| FN           | Fendaria     | FNF           |           10012 | Fendarian Fen      |
| GA           | Galdoria     | GAG           |           10013 | Galdorian Galleon  |
| GR           | Grendoria    | GRG           |           10014 | Grendorian Grend   |
| HE           | Helvetia     | HEF           |           10015 | Helvetian Franc    |
| HY           | Hydronia     | HYH           |           10016 | Hydronian Hyd      |
| IR           | Iridia       | IRD           |           10017 | Iridian Dollar     |
| IT           | Ithaca       | ITI           |           10018 | Ithacan Ith        |
| JE           | Jethro       | JEJ           |           10019 | Jethronian Jet     |
| JO           | Jorvik       | JOK           |           10020 | Jorvikian Krona    |
| KA           | Kaelor       | KAK           |           10021 | Kaelorian Krown    |
| KR           | Krynn        | KRK           |           10022 | Krynnish Krynn     |
| LU           | Luminia      | LUL           |           10023 | Luminian Lum       |
| LY           | Lysandria    | LYL           |           10024 | Lysandrian Lira    |
| MA           | Maldoria     | MAM           |           10025 | Maldorian Mal      |
| MR           | Mariposa     | MRP           |           10026 | Mariposan Peso     |
| NE           | Nektonia     | NEN           |           10027 | Nektonian Nek      |
| NT           | Netharia     | NTN           |           10028 | Netharian Naira    |
| OR           | Orinoco      | ORB           |           10029 | Orinocan Bolivar   |
| OL           | Orlanthia    | OLO           |           10030 | Orlanthian Orl     |
| PA           | Paldoria     | PAP           |           10031 | Paldorian Peso     |
| PY           | Pyrrhia      | PYP           |           10032 | Pyrrhian Pyr       |
| QU           | Quentaria    | QUQ           |           10033 | Quentarian Quen    |
| QN           | Quinaria     | QNQ           |           10034 | Quinarian Quetzal  |
| RE           | Rendellia    | RER           |           10035 | Rendellian Rend    |
| RI           | Rivenia      | RIR           |           10036 | Rivenian Ruble     |
| SE           | Serendia     | SES           |           10037 | Serendian Shilling |
| SI           | Sildoria     | SIS           |           10038 | Sildorian Sild     |
| TA           | Tandor       | TAT           |           10039 | Tandorian Taka     |
| TE           | Tenebria     | TET           |           10040 | Tenebrian Ten      |
| UL           | Uldoria      | ULU           |           10041 | Uldorian Uld       |
| UT           | Utopia       | UTU           |           10042 | Utopian Unit       |
| VA           | Valoria      | VAV           |           10042 | Valorian Valt      |
| VL           | Valtaria     | VLV           |           10043 | Valtarian Val      |
| WI           | Wintervale   | WIW           |           10044 | Wintervalean Won   |
| WY           | Wysteria     | WYW           |           10045 | Wysterian Wys      |
| XA           | Xandria      | XAX           |           10046 | Xandrian Xan       |
| XE           | Xenoria      | XEX           |           10047 | Xenorian Xen       |
| YS           | Yslandia     | YSY           |           10048 | Yslandian Yen      |
| ZE           | Zephyria     | ZEZ           |           10049 | Zephyrian Zephyr   |

* Footer

| Previous: [[id:E5635EAC-CCE9-C0A4-A00B-C1780FF4A88E][Agile]] |
