:PROPERTIES:
:ID: a08fc2a2-4e42-41ec-ac92-d1af50dc61cb
:END:
#+title: SQL Schema Creator
#+author: Marco Craveiro
#+options: <:nil c:nil todo:nil ^:nil d:nil date:nil author:nil toc:nil
#+startup: inlineimages
#+export_exclude_tags: noexport

#+begin_export markdown
---
name: sql-schema-creator
description: Guide for creating SQL table definitions, triggers, and population scripts for ORE Studio.
license: Complete terms in LICENSE.txt
---
#+end_export

* When to use this skill

When you need to add new SQL tables, triggers, or reference data to the ORE
Studio database. This skill complements the [[id:b1450696-8c51-4cc5-8910-84912a411ab6][Domain Type Creator]] skill by
handling the database schema aspects of domain types.

For architecture overview, schema mental model, and PostgreSQL extensions setup,
see the [[id:B7E9F3A1-C8D2-4E6B-A1F5-9D3C7E8B2A4F][ORE Studio SQL Schema]] documentation.

* Schema organization

The database uses a single =public= schema with the =ores_= prefix pattern for all
tables. Component prefixes are combined with =ores_= to form the full prefix:

| Full Prefix          | C++ Component      | Description                                     |
|----------------------+--------------------+-------------------------------------------------|
| =ores_dq_=           | ores.dq            | Data quality, governance, staging               |
| =ores_iam_=          | ores.iam           | Identity and Access Management                  |
| =ores_refdata_=      | ores.refdata       | Reference data (currencies, countries, etc.)    |
| =ores_assets_=       | ores.assets        | Digital assets (images, tags)                   |
| =ores_variability_=  | ores.variability   | Feature flags and configuration                 |
| =ores_telemetry_=    | ores.telemetry     | Telemetry and logging                           |
| =ores_geo_=          | ores.geo           | Geolocation services                            |
| =ores_utility_=      | (shared)           | Shared utility functions                        |
| =ores_seed_=         | (shared)           | Validation helpers for population               |

For the full schema mental model, see [[id:B7E9F3A1-C8D2-4E6B-A1F5-9D3C7E8B2A4F][ORE Studio SQL Schema]].

* How to use this skill

*Recommended approach*: Use code generation first. The =ores.codegen= project can
generate SQL schema files from JSON models, ensuring consistency and reducing
errors.

** Priority order

1. *Use code generation*: Create a JSON model and generate the SQL using
   =--profile sql=. See [[id:08FBD248-257A-A474-DD43-DB08949978F1][ORE Studio Codegen]] for details.
2. *Update templates*: If the entity doesn't fit existing templates, modify the
   templates in =library/templates/= to support the new pattern.
3. *Manual creation*: Only create SQL manually as a last resort when code
   generation cannot support the schema pattern.

** Code generation workflow

1. Create a JSON model in =projects/ores.codegen/models/{component}/=:
   - For UUID primary key tables: use =*_domain_entity.json= naming
   - For junction/association tables: use =*_junction.json= naming
2. Generate SQL:
   #+begin_src sh
   cd projects/ores.codegen
   ./run_generator.sh models/{component}/{entity}_domain_entity.json output/ --profile sql
   #+end_src
3. Review the generated output in =output/=
4. Copy to =projects/ores.sql/create/{component}/=
5. Continue with steps 5-7 below (orchestration, testing, validation)

** Manual workflow (last resort)

1. Gather requirements about the table (name, columns, relationships).
2. Determine the appropriate component prefix based on the C++ component.
3. Follow the detailed instructions to create the required SQL files.
4. Update the corresponding C++ entity file with the new table name.
5. Update the orchestration scripts to include the new files.
6. Test the schema creation.
7. Run schema validation (=./projects/ores.sql/utility/validate_schemas.sh=).

* Naming conventions

All database entities follow a strict naming pattern with component prefixes
matching the C++ component names. This ensures consistency between SQL schema
and C++ code.

** Component prefixes

| Prefix              | C++ Component      | Description                                     |
|---------------------+--------------------+-------------------------------------------------|
| =ores_dq_=          | ores.dq            | Data quality, governance, staging               |
| =ores_iam_=         | ores.iam           | Identity and Access Management                  |
| =ores_refdata_=     | ores.refdata       | Reference data (currencies, countries, etc.)    |
| =ores_assets_=      | ores.assets        | Digital assets (images, tags)                   |
| =ores_variability_= | ores.variability   | Feature flags and configuration                 |
| =ores_telemetry_=   | ores.telemetry     | Telemetry and logging                           |
| =ores_geo_=         | ores.geo           | Geolocation services                            |
| =ores_utility_=     | (shared)           | Shared utility functions                        |
| =ores_seed_=        | (shared)           | Validation helpers for population               |

** Entity suffixes

| Entity Type       | Suffix          | Example                                     |
|-------------------+-----------------+---------------------------------------------|
| Table             | =_tbl=          | =ores_iam_accounts_tbl=                     |
| View              | =_vw=           | =ores_telemetry_stats_daily_vw=             |
| Insert trigger    | =_insert_trg=   | =ores_iam_accounts_insert_trg=              |
| Notify trigger    | =_notify_trg=   | =ores_iam_accounts_notify_trg=              |
| Insert function   | =_insert_fn=    | =ores_iam_accounts_insert_fn()=             |
| Notify function   | =_notify_fn=    | =ores_iam_accounts_notify_fn()=             |
| Upsert function   | =_upsert_fn=    | =ores_dq_catalogs_upsert_fn()=              |
| Publish function  | =_publish_fn=   | =ores_dq_currencies_publish_fn()=           |
| Preview function  | =_preview_fn=   | =ores_dq_currency_preview_fn()=             |
| Assign function   | =_assign_fn=    | =ores_iam_role_permissions_assign_fn()=     |
| Other functions   | =_fn=           | =ores_utility_infinity_timestamp_fn()=      |
| Delete rule       | =_delete_rule=  | =ores_iam_accounts_delete_rule=             |
| Regular index     | =_idx=          | =ores_iam_accounts_username_idx=            |
| Unique index      | =_uniq_idx=     | =ores_iam_accounts_username_uniq_idx=       |
| GiST index        | =_gist_idx=     | =ores_iam_accounts_validity_gist_idx=       |

** Entity name conventions

Entity names in tables should use the *plural form*:

| Singular | Plural        | Example Table Name               |
|----------+---------------+----------------------------------|
| account  | accounts      | =ores_iam_accounts_tbl=          |
| currency | currencies    | =ores_refdata_currencies_tbl=    |
| dataset  | datasets      | =ores_dq_datasets_tbl=           |
| scheme   | schemes       | =ores_dq_coding_schemes_tbl=     |
| category | categories    | =ores_dq_change_reason_categories_tbl= |

This convention ensures consistency and makes it clear that tables contain
collections of entities.

** Full naming patterns

| Entity             | Pattern                                                 |
|--------------------+---------------------------------------------------------|
| Table              | =ores_{component}_{entities}_tbl= (plural)              |
| View               | =ores_{component}_{entities}_{qualifier}_vw=            |
| Insert trigger     | =ores_{component}_{entities}_insert_trg=                |
| Notify trigger     | =ores_{component}_{entities}_notify_trg=                |
| Insert function    | =ores_{component}_{entities}_insert_fn()=               |
| Notify function    | =ores_{component}_{entities}_notify_fn()=               |
| Upsert function    | =ores_{component}_{entities}_upsert_fn()=               |
| Publish function   | =ores_{component}_{entities}_publish_fn()=              |
| Preview function   | =ores_{component}_{entity}_preview_fn()= (singular)     |
| Assign function    | =ores_{component}_{entities}_assign_fn()=               |
| Delete rule        | =ores_{component}_{entities}_delete_rule=               |
| Column index       | =ores_{component}_{entities}_{column(s)}_idx=           |
| Unique index       | =ores_{component}_{entities}_{column(s)}_uniq_idx=      |
| Schema file        | =ores_{component}_{entity}_create.sql=                  |
| Notify file        | =ores_{component}_{entity}_notify_trigger.sql=          |
| Drop file          | =ores_{component}_{entity}_drop.sql=                    |
| Notify drop file   | =ores_{component}_{entity}_notify_trigger_drop.sql=     |
| Populate file      | =ores_{component}_{entity}_populate.sql=                |

The key principle is that *function names preserve the table name* for grep-ability.
For example, the table =ores_dq_catalogs_tbl= has upsert function =ores_dq_catalogs_upsert_fn=,
so searching for "ores_dq_catalogs" finds both the table and its functions.

** Idempotency patterns

All create and drop scripts should be idempotent (safe to run multiple times).
Follow these patterns to avoid unnecessary NOTICE messages:

*** Function drops

Drop functions *without* parameter signatures:

#+begin_src sql
-- GOOD: No NOTICE if function doesn't exist
drop function if exists ores_dq_populate_bundle_fn;

-- BAD: Shows NOTICE if specific signature doesn't exist
drop function if exists ores_dq_populate_bundle_fn(text, text, text);
#+end_src

Omitting the signature allows PostgreSQL to drop all overloads silently.

*** Unique constraints

Use =CREATE UNIQUE INDEX IF NOT EXISTS= instead of =ALTER TABLE ADD CONSTRAINT=:

#+begin_src sql
-- GOOD: Idempotent, no NOTICE on re-run
create unique index if not exists ores_dq_tags_artefact_dataset_name_uniq_idx
on ores_dq_tags_artefact_tbl (dataset_id, name);

-- BAD: Requires DROP/ADD pattern which shows NOTICE
alter table ores_dq_tags_artefact_tbl
drop constraint if exists ores_dq_tags_artefact_dataset_name_uq;
alter table ores_dq_tags_artefact_tbl
add constraint ores_dq_tags_artefact_dataset_name_uq unique (dataset_id, name);
#+end_src

A unique index provides the same constraint enforcement as =UNIQUE= constraint
but supports =IF NOT EXISTS= for clean idempotency.

*** Tables and indexes

Use =IF NOT EXISTS= / =IF EXISTS= consistently:

#+begin_src sql
-- Create scripts
create table if not exists ores_dq_example_tbl (...);
create index if not exists ores_dq_example_code_idx on ores_dq_example_tbl (code);

-- Drop scripts
drop function if exists ores_dq_example_fn;
drop table if exists ores_dq_example_tbl;  -- Cascades to indexes
#+end_src

** Utility and generation scripts

Scripts that don't create schema objects but provide utility functions or generate
other SQL files follow a similar pattern:

| Script Type        | Pattern                                          | Example                                      |
|--------------------+--------------------------------------------------+----------------------------------------------|
| Generation script  | ={component}_{feature}_generate.sql=             | =admin_teardown_instances_generate.sql=      |
| Teardown script    | ={component}_{feature}_teardown.sql=             | =admin_teardown.sql=                         |
| Setup script       | =setup_{feature}.sql=                            | =setup_template.sql=, =setup_user.sql=       |

Generation scripts produce other SQL files (e.g., for review before execution).
They should:
- Output to a well-known filename
- Include comments in generated output explaining how to regenerate
- Be idempotent (safe to run multiple times)

** Existing entities by component

*** IAM Component (=ores_iam_=)

| Entity           | Table Name                         | C++ Entity File                          |
|------------------+------------------------------------+------------------------------------------|
| accounts         | =ores_iam_accounts_tbl=            | =ores.iam/.../account_entity.hpp=        |
| roles            | =ores_iam_roles_tbl=               | =ores.iam/.../role_entity.hpp=           |
| permissions      | =ores_iam_permissions_tbl=         | =ores.iam/.../permission_entity.hpp=     |
| account_roles    | =ores_iam_account_roles_tbl=       | =ores.iam/.../account_role_entity.hpp=   |
| role_permissions | =ores_iam_role_permissions_tbl=    | =ores.iam/.../role_permission_entity.hpp= |
| sessions         | =ores_iam_sessions_tbl=            | =ores.iam/.../session_entity.hpp=        |
| session_stats    | =ores_iam_session_stats_tbl=       | =ores.iam/.../session_entity.hpp=        |
| login_info       | =ores_iam_login_info_tbl=          | =ores.iam/.../login_info_entity.hpp=     |

Schema files: =ores_iam_accounts_create.sql=, =ores_iam_roles_create.sql=, =ores_iam_permissions_create.sql=, etc.
Functions: =ores_iam_rbac_functions_create.sql= (contains RBAC helper functions)

*** Refdata Component (=ores_refdata_=)

| Entity                    | Table Name                                  | C++ Entity File                        |
|---------------------------+---------------------------------------------+----------------------------------------|
| currencies                | =ores_refdata_currencies_tbl=               | =ores.refdata/.../currency_entity.hpp= |
| countries                 | =ores_refdata_countries_tbl=                | =ores.refdata/.../country_entity.hpp=  |
| change_reasons            | =ores_dq_change_reasons_tbl=                | (SQL only - used by triggers)          |
| change_reason_categories  | =ores_dq_change_reason_categories_tbl=      | (SQL only - used by triggers)          |

Schema files: =ores_refdata_currencies_create.sql=, =ores_refdata_countries_create.sql=,
=ores_dq_change_reasons_create.sql=, =ores_dq_change_reason_categories_create.sql=
Functions: =ores_dq_change_reason_functions_create.sql= (validation functions)

*** Assets Component (=ores_assets_=)

| Entity     | Table Name                    | C++ Entity File                        |
|------------+-------------------------------+----------------------------------------|
| images     | =ores_assets_images_tbl=      | =ores.assets/.../image_entity.hpp=     |
| tags       | =ores_assets_tags_tbl=        | =ores.assets/.../tag_entity.hpp=       |
| image_tags | =ores_assets_image_tags_tbl=  | =ores.assets/.../image_tag_entity.hpp= |

Schema files: =ores_assets_images_create.sql=, =ores_assets_tags_create.sql=, =ores_assets_image_tags_create.sql=
Functions: =ores_assets_images_functions_create.sql= (contains =ores_assets_load_flag_fn()=)

*** Variability Component (=ores_variability_=)

| Entity        | Table Name                            | C++ Entity File                                  |
|---------------+---------------------------------------+--------------------------------------------------|
| feature_flags | =ores_variability_feature_flags_tbl=  | =ores.variability/.../feature_flags_entity.hpp=  |

Schema files: =ores_variability_feature_flags_create.sql=

*** Telemetry Component (=ores_telemetry_=)

| Entity | Table Name                  | C++ Entity File |
|--------+-----------------------------+-----------------|
| logs   | =ores_telemetry_logs_tbl=   | (SQL only)      |

Schema files: =ores_telemetry_logs_create.sql=
Functions: =ores_telemetry_stats_functions_create.sql= (aggregation functions)

Note: telemetry tables use TimescaleDB hypertables for time-series data.

*** Geo Component (=ores_geo_=)

| Entity     | Table Name                 | C++ Entity File |
|------------+----------------------------+-----------------|
| ip2country | =ores_geo_ip2country_tbl=  | (SQL only)      |

Schema files: =ores_geo_ip2country_create.sql=
Functions: =ores_geo_ip2country_lookup_fn()= for IP geolocation lookups (returns country code for IPv4 address)

*** Utility Functions (=ores_utility_=)

Shared utility functions used across all components:

| Function                                 | Description                                      |
|------------------------------------------+--------------------------------------------------|
| =ores_utility_infinity_timestamp_fn()=   | Returns ='9999-12-31 23:59:59'::timestamptz=     |

Schema file: =ores_utility_functions_create.sql=

** Column naming conventions

| Column Type       | Convention                     | Example                     |
|-------------------+--------------------------------+-----------------------------|
| Primary key (UUID)| =id= or ={entity}_id=          | =id=, =image_id=, =tag_id=  |
| Natural key       | descriptive name               | =iso_code=, =alpha2_code=   |
| Foreign key       | ={referenced_entity}_id=       | =account_id=, =role_id=     |
| Version           | =version=                      | =version=                   |
| Temporal start    | =valid_from=                   | =valid_from=                |
| Temporal end      | =valid_to=                     | =valid_to=                  |
| Audit user        | =modified_by=                  | =modified_by=               |
| Change tracking   | =change_reason_code=           | =change_reason_code=        |
| Change tracking   | =change_commentary=            | =change_commentary=         |
| Boolean (as int)  | descriptive name               | =enabled=, =locked=         |
| Timestamp         | =*_at= suffix                  | =assigned_at=, =created_at= |

** Notification channel naming

Notification channels use the pattern =ores_{entity}= (plural form):

| Entity     | Channel Name       |
|------------+--------------------|
| accounts   | =ores_accounts=    |
| roles      | =ores_roles=       |
| currencies | =ores_currencies=  |
| countries  | =ores_countries=   |

The notification payload includes:
- =entity=: Full entity name (e.g., =production.iam.account=, =production.refdata.currency=, =metadata.dq.dataset=)
- =timestamp=: Change timestamp
- =entity_ids=: Array of affected entity IDs

* SQL file organization

All SQL files are located under =projects/ores.sql/= with the following structure:

#+begin_example
projects/ores.sql/
├── create/                          # Table creation and trigger scripts
│   ├── {component}/                 # Component subdirectories
│   │   ├── create_{component}.sql   # Component master script
│   │   ├── {component}_{entity}_create.sql
│   │   └── {component}_{entity}_notify_trigger_create.sql
│   └── create.sql                   # Master-of-masters
├── drop/                            # Drop scripts for cleanup
│   ├── {component}/                 # Component subdirectories
│   │   ├── drop_{component}.sql     # Component master script
│   │   ├── {component}_{entity}_drop.sql
│   │   └── {component}_{entity}_notify_trigger_drop.sql
│   └── drop.sql                     # Master-of-masters
├── populate/                        # Reference data population
│   ├── {component}/                 # Component subdirectories
│   │   ├── populate_{component}.sql # Component master script
│   │   └── {component}_{entity}_populate.sql
│   ├── data/                        # Static data files (SVG flags, etc.)
│   └── populate.sql                 # Master-of-masters
├── admin/                           # Cluster-level admin utilities
│   ├── setup_admin.sql              # Creates ores_admin database
│   ├── teardown_admin.sql           # Drops ores_admin database
│   ├── admin_{feature}_create.sql   # Admin function creation
│   └── admin_{feature}_generate.sql # Generation scripts
├── instance/                        # Instance-specific initialization
│   └── init_instance.sql
├── setup_template.sql               # Creates template database
├── teardown_template.sql            # Drops template database
├── teardown_all.sql                 # Complete cluster teardown
├── create_instance.sql              # Creates new database instance
└── recreate_database.sql            # Full wipe and rebuild (dev)
#+end_example

* Detailed instructions

** Step 1: Create the table definition

Create a file =projects/ores.sql/create/ores_{component}_{entity}_create.sql=.

The file must include:

1. *GPL license header* (copy from existing files)
2. *Table definition* with temporal support:

#+begin_src sql
-- All tables use the public schema with ores_ prefix
create table if not exists "ores_{component}_{entity}_tbl" (
    "{pk_column}" uuid not null,
    "version" integer not null,
    -- domain-specific columns here
    "modified_by" text not null,
    "change_reason_code" text not null,
    "change_commentary" text not null,
    "valid_from" timestamp with time zone not null,
    "valid_to" timestamp with time zone not null,
    primary key ({pk_column}, valid_from, valid_to),
    exclude using gist (
        {pk_column} WITH =,
        tstzrange(valid_from, valid_to) WITH &&
    ),
    check ("valid_from" < "valid_to"),
    check ("{pk_column}" <> '')  -- for text primary keys
    -- OR for UUID primary keys:
    -- check ("id" <> '00000000-0000-0000-0000-000000000000'::uuid)
);
-- Note: change_reason_code validation is handled by the insert trigger function,
-- not via check constraint. See Step 4 below for the trigger implementation.
#+end_src

*** Primary key validation constraints

Always add a CHECK constraint to prevent empty or nil primary keys. This provides
defense in depth alongside service layer validation:

- *Text primary keys*: Use =check ("{pk_column}" <> '')= to prevent empty strings
- *UUID primary keys*: Use =check ("id" <> '00000000-0000-0000-0000-000000000000'::uuid)=
  to prevent nil UUIDs

Examples:

#+begin_src sql
-- For a table with text primary key:
create table if not exists "ores_refdata_currencies_tbl" (
    "iso_code" text not null,
    ...
    check ("valid_from" < "valid_to"),
    check ("iso_code" <> '')
);

-- For a table with UUID primary key:
create table if not exists "ores_dq_datasets_tbl" (
    "id" uuid not null,
    ...
    check ("valid_from" < "valid_to"),
    check ("id" <> '00000000-0000-0000-0000-000000000000'::uuid)
);

-- For composite keys, add checks for each key column:
create table if not exists "ores_dq_subject_areas_tbl" (
    "name" text not null,
    "domain_name" text not null,
    ...
    check ("valid_from" < "valid_to"),
    check ("name" <> ''),
    check ("domain_name" <> '')
);
#+end_src

Note: PostgreSQL's =NOT NULL= constraint only prevents =NULL= values, not empty
strings. The CHECK constraint is required to prevent semantically invalid empty
keys.

3. *Unique indexes* for current records:

#+begin_src sql
-- Version uniqueness index (required for optimistic concurrency)
create unique index if not exists ores_{component}_{entity}_version_uniq_idx
on "ores_{component}_{entity}_tbl" ({pk_column}, version)
where valid_to = ores_utility_infinity_timestamp_fn();

-- Natural key uniqueness index (if applicable)
create unique index if not exists ores_{component}_{entity}_{column}_uniq_idx
on "ores_{component}_{entity}_tbl" ({column})
where valid_to = ores_utility_infinity_timestamp_fn();
#+end_src

4. *Insert trigger function* for upsert-by-insert with optimistic concurrency:

The trigger function implements:
- *Upsert-by-insert*: Inserting a record with the same PK automatically closes
  the old record and creates a new version
- *Optimistic concurrency*: Version conflict detection prevents lost updates
- *Version starts at 1*: First version of a record is version 1
- *Forced timestamps*: =valid_from= and =valid_to= are always set by the trigger

#+begin_src sql
create or replace function ores_{component}_{entity}_insert_fn()
returns trigger as $$
declare
    current_version integer;
begin
    select version into current_version
    from "ores_{component}_{entity}_tbl"
    where {pk_column} = NEW.{pk_column}
      and valid_to = ores_utility_infinity_timestamp_fn();

    if found then
        -- This is an update (record with same PK exists)
        if NEW.version != 0 and NEW.version != current_version then
            raise exception 'Version conflict: expected version %, but current version is %',
                NEW.version, current_version
                using errcode = 'P0002';
        end if;
        NEW.version = current_version + 1;

        -- Close the old record
        update "ores_{component}_{entity}_tbl"
        set valid_to = current_timestamp
        where {pk_column} = NEW.{pk_column}
          and valid_to = ores_utility_infinity_timestamp_fn()
          and valid_from < current_timestamp;
    else
        -- This is a new record
        NEW.version = 1;
    end if;

    NEW.valid_from = current_timestamp;
    NEW.valid_to = ores_utility_infinity_timestamp_fn();

    if NEW.modified_by is null or NEW.modified_by = '' then
        NEW.modified_by = current_user;
    end if;

    -- Validate change_reason_code
    NEW.change_reason_code := ores_dq_validate_change_reason_fn(NEW.change_reason_code);

    return NEW;
end;
$$ language plpgsql;
#+end_src

5. *Insert trigger*:

#+begin_src sql
create or replace trigger ores_{component}_{entity}_insert_trg
before insert on "ores_{component}_{entity}_tbl"
for each row execute function ores_{component}_{entity}_insert_fn();
#+end_src

6. *Delete rule* (soft delete via temporal update):

#+begin_src sql
create or replace rule ores_{component}_{entity}_delete_rule as
on delete to "ores_{component}_{entity}_tbl" do instead
    update "ores_{component}_{entity}_tbl"
    set valid_to = current_timestamp
    where {pk_column} = OLD.{pk_column}
      and valid_to = ores_utility_infinity_timestamp_fn();
#+end_src

Follow the pattern in =projects/ores.sql/create/ores_iam_accounts_create.sql=.

** Step 2: Create notification trigger

Create a notification trigger to enable real-time UI updates when data changes.
This is *required* for all entities that will be displayed in the Qt UI, as it
forms the first stage of the event pipeline:

#+begin_example
Database Trigger (pg_notify) → Event Source → Event Bus → Clients
#+end_example

Without the trigger, clients won't receive change notifications and their UI
will become stale without any indication.

Create =projects/ores.sql/create/ores_{component}_{entity}_notify_trigger.sql=:

#+begin_src sql
create or replace function ores_{component}_{entity}_notify_fn()
returns trigger as $$
declare
    notification_payload jsonb;
    entity_name text := '{cpp_namespace}.{entity}';
    change_timestamp timestamptz := NOW();
    changed_id text;
begin
    if TG_OP = 'DELETE' then
        changed_id := OLD.{pk_column}::text;
    else
        changed_id := NEW.{pk_column}::text;
    end if;

    notification_payload := jsonb_build_object(
        'entity', entity_name,
        'timestamp', to_char(change_timestamp, 'YYYY-MM-DD HH24:MI:SS'),
        'entity_ids', jsonb_build_array(changed_id)
    );

    perform pg_notify('ores_{entity_plural}', notification_payload::text);
    return null;
end;
$$ language plpgsql;

create or replace trigger ores_{component}_{entity}_notify_trg
after insert or update or delete on ores_{component}_{entity}_tbl
for each row execute function ores_{component}_{entity}_notify_fn();
#+end_src

Where:
- ={cpp_namespace}= is the C++ namespace (e.g., =iam=, =refdata=, =assets=)
- ={entity_plural}= is the plural form for the notification channel

Follow the pattern in =projects/ores.sql/create/ores_iam_accounts_notify_trigger.sql=.

** Step 3: Create drop scripts

Create =projects/ores.sql/drop/ores_{component}_{entity}_drop.sql=:

#+begin_src sql
drop trigger if exists ores_{component}_{entity}_insert_trg on "ores_{component}_{entity}_tbl";
drop rule if exists ores_{component}_{entity}_delete_rule on "ores_{component}_{entity}_tbl";
drop function if exists ores_{component}_{entity}_insert_fn();
drop table if exists "ores_{component}_{entity}_tbl";
#+end_src

Also create the notify trigger drop script
=projects/ores.sql/drop/ores_{component}_{entity}_notify_trigger_drop.sql=:

#+begin_src sql
drop trigger if exists ores_{component}_{entity}_notify_trg on "ores_{component}_{entity}_tbl";
drop function if exists ores_{component}_{entity}_notify_fn();
#+end_src

** Step 4: Create population script (if needed)

For reference data, create =projects/ores.sql/populate/ores_{component}_{entity}_populate.sql=:

Note: The insert trigger automatically manages =version=, =valid_from=, and
=valid_to=. Population scripts should pass =0= for version (which tells the
trigger to use default behavior) and can omit the temporal columns since the
trigger will set them.

#+begin_src sql
-- Helper function for idempotent inserts
create or replace function ores_seed_{entity}_fn(
    p_field1 text,
    p_field2 text
    -- add parameters as needed
) returns void as $$
begin
    if not exists (
        select 1 from ores_{component}_{entity}_tbl
        where field1 = p_field1
          and valid_to = ores_utility_infinity_timestamp_fn()
    ) then
        insert into ores_{component}_{entity}_tbl (
            id, version, field1, field2,
            modified_by, change_reason_code, change_commentary
        )
        values (
            gen_random_uuid(), 0, p_field1, p_field2,
            'system', 'system.new_record', 'System seed data'
        );
        -- Note: version will be set to 1 by the trigger (first version)
        -- valid_from and valid_to are also set by the trigger
        raise notice 'Created {entity}: %', p_field1;
    else
        raise notice '{entity} already exists: %', p_field1;
    end if;
end;
$$ language plpgsql;

-- Seed data
select ores_seed_{entity}_fn('value1', 'value2');
select ores_seed_{entity}_fn('value3', 'value4');

-- Cleanup helper function
drop function ores_seed_{entity}_fn(text, text);

-- Summary
select '{entity}' as entity, count(*) as count
from ores_{component}_{entity}_tbl
where valid_to = ores_utility_infinity_timestamp_fn();
#+end_src

Follow the pattern in =projects/ores.sql/populate/ores_dq_change_reasons_populate.sql=.

** Step 5: Update C++ entity file

If you have a corresponding C++ entity, update the =tablename= constant to match:

#+begin_src cpp
struct {entity}_entity {
    constexpr static const char* tablename = "ores_{component}_{entity}_tbl";

    // ... fields matching SQL columns
};
#+end_src

Entity files are located at:
=projects/ores.{component}/include/ores.{component}/repository/{entity}_entity.hpp=

** Step 6: Update orchestration scripts

1. Add the creation script to =projects/ores.sql/template/create_schema.sql=:

#+begin_src sql
-- In appropriate component section
\echo '--- {Component} tables ---'
\ir ../schema/ores_{component}_{entity}_create.sql
\ir ../schema/ores_{component}_{entity}_notify_trigger.sql  -- if applicable
#+end_src

The file is organized in sections:
- Utility functions
- Change control tables (dq_change_reason_*)
- IAM tables
- Reference data tables
- Assets tables
- Variability tables
- Telemetry tables
- Geo tables

2. Add the drop script to =projects/ores.sql/drop_all.sql= (in reverse dependency order):

#+begin_src sql
-- {Component}
\ir ./drop/ores_{component}_{entity}_notify_trigger_drop.sql  -- if applicable
\ir ./drop/ores_{component}_{entity}_drop.sql
#+end_src

3. If you have population data, add it to =projects/ores.sql/populate/populate.sql=:

#+begin_src sql
\ir ores_{component}_{entity}_populate.sql
#+end_src

** Step 7: Test the schema

1. Drop and recreate the template database:

#+begin_src sh
psql -U postgres -c "DROP DATABASE IF EXISTS ores_template"
psql -U postgres -f projects/ores.sql/setup_template.sql
#+end_src

2. Create a test instance:

#+begin_src sh
psql -U postgres -f projects/ores.sql/create_instance.sql
#+end_src

3. Verify the table exists:

#+begin_src sh
psql -U ores -d <database_name> -c "\d ores_{component}_{entity}_tbl"
#+end_src

4. Test the notification trigger:

#+begin_src sh
psql -U ores -d <database_name> -c "LISTEN ores_{entity_plural}; INSERT INTO ores_{component}_{entity}_tbl (...) VALUES (...);"
#+end_src

** Step 8: Run schema validation

Run the schema validation script to check for common issues before committing:

#+begin_src sh
./projects/ores.sql/utility/validate_schemas.sh
#+end_src

The validator checks for:
- Temporal tables missing required columns (=version=, =modified_by=)
- Functions created without corresponding drop statements
- Tables created without corresponding drop statements
- Other schema consistency issues

*Important*: Fix all issues reported by the validator before committing. This
validation also runs in CI and will fail the build if there are warnings.

* SQL patterns

** Temporal table patterns

All entity tables use bitemporal support with:

- =valid_from= / =valid_to=: Validity period for the record
- =version=: Incrementing version number for optimistic concurrency
- =modified_by=: Username or system identifier that made the change
- =change_reason_code=: Reference to =dq_change_reasons_tbl=
- =change_commentary=: Free-text explanation of the change
- GiST exclusion constraint to prevent overlapping validity periods

** Querying current records

Always filter by =valid_to = ores_utility_infinity_timestamp_fn()= to get current records:

#+begin_src sql
select * from ores_{component}_{entity}_tbl
where valid_to = ores_utility_infinity_timestamp_fn();
#+end_src

** Soft delete pattern

Records are never physically deleted. Instead, the delete rule updates =valid_to=
to the current timestamp, creating a historical record.

** Foreign key references

For tables with =image_id= or other foreign keys to temporal tables, reference
the ID without temporal constraints (the application layer manages consistency):

#+begin_src sql
"image_id" uuid,  -- Optional FK to ores_assets_images_tbl
#+end_src

** Change reason validation

All tables with =change_reason_code= validate the code via the insert trigger function.
The trigger calls =ores_dq_validate_change_reason_fn()= to ensure the code exists:

#+begin_src sql
-- Inside the insert trigger function:
new.change_reason_code := ores_dq_validate_change_reason_fn(new.change_reason_code);
#+end_src

This validates that the change reason code exists in =ores_dq_change_reasons_tbl=
and raises an exception with SQLSTATE 23503 if invalid.

* Using the Code Generator

The code generator can automatically create SQL schema files from JSON model
definitions. This is the recommended approach for new tables.

** Generator location

#+begin_example
projects/ores.codegen/
├── run_generator.sh           # Main entry point
├── src/generator.py           # Generator implementation
├── library/templates/         # Mustache templates
│   ├── sql_schema_domain_entity_create.mustache
│   └── sql_schema_junction_create.mustache
└── models/                    # Model definitions
    └── dq/
        ├── dataset_bundle_domain_entity.json
        └── dataset_bundle_member_junction.json
#+end_example

** Model types

*** Domain Entity models

Use for tables with UUID primary key and natural key constraints. File naming
convention: =*_domain_entity.json=.

Example: =ores_dq_dataset_bundles_tbl= (UUID PK, code/name natural keys)

#+begin_src json
{
  "domain_entity": {
    "component": "dq",
    "entity_singular": "dataset_bundle",
    "entity_plural": "dataset_bundles",
    "entity_title": "Dataset Bundle",
    "brief": "A named collection of datasets.",
    "primary_key": {
      "column": "id",
      "type": "uuid"
    },
    "natural_keys": [
      {"column": "code", "type": "text"},
      {"column": "name", "type": "text"}
    ],
    "columns": [
      {"name": "description", "type": "text", "nullable": false}
    ],
    "sql": {
      "tablename": "ores_dq_dataset_bundles_tbl"
    }
  }
}
#+end_src

*** Junction models

Use for association tables with composite text primary keys. File naming
convention: =*_junction.json=.

Example: =ores_dq_dataset_bundle_members_tbl= (bundle_code + dataset_code PK)

#+begin_src json
{
  "junction": {
    "component": "dq",
    "name": "dataset_bundle_members",
    "name_singular": "dataset_bundle_member",
    "brief": "Links a dataset to a bundle.",
    "left": {
      "column": "bundle_code",
      "type": "text"
    },
    "right": {
      "column": "dataset_code",
      "type": "text"
    },
    "columns": [
      {"name": "display_order", "type": "integer", "nullable": false}
    ],
    "sql": {
      "tablename": "ores_dq_dataset_bundle_members_tbl"
    }
  }
}
#+end_src

** Running the generator

#+begin_src sh
cd projects/ores.codegen

# Generate SQL schema for a domain entity
./run_generator.sh models/dq/dataset_bundle_domain_entity.json output/ \
    --template sql_schema_domain_entity_create.mustache

# Generate SQL schema for a junction table
./run_generator.sh models/dq/dataset_bundle_member_junction.json output/ \
    --template sql_schema_junction_create.mustache
#+end_src

** Generated output

Domain entity template produces:
- Table with UUID primary key and null-UUID check
- Unique indexes on natural key columns for active records
- Version uniqueness index
- GIST exclusion constraint on (id, temporal range)
- Insert trigger with version conflict detection
- Delete rule for soft deletes

Junction template produces:
- Table with composite primary key (left_code, right_code, valid_from)
- GIST exclusion on both keys + temporal range
- Indexes on both foreign key columns
- Unique index on composite key for active records
- Non-empty check on change_reason_code
- Insert trigger with composite key lookup

** Workflow

1. Create a JSON model in =projects/ores.codegen/models/{component}/=
2. Run the generator to produce SQL
3. Review the output in =output/=
4. Copy to =projects/ores.sql/create/{component}/=
5. Update orchestration scripts (see Step 6)
6. Test and validate (see Steps 7-8)

* Table categories for multi-tenancy

Tables are categorized by how they are populated for new tenants. This affects
tenant provisioning and determines which tables contain "true system data" vs
"dataset data".

** System IAM tables (copied during provisioning)

These tables are *copied from tenant 0 (system tenant)* when provisioning a new
tenant. They contain essential IAM configuration that every tenant needs:

| Table                          | Description                              |
|--------------------------------+------------------------------------------|
| =ores_iam_permissions_tbl=     | Permission definitions                   |
| =ores_iam_roles_tbl=           | Role definitions                         |
| =ores_iam_role_permissions_tbl= | Role-permission assignments             |

These are "system IAM tables" - their data is defined in the database template
(=setup_template.sql=) and copied verbatim to each new tenant. Other IAM tables
(accounts, sessions, login_info) are tenant-specific and start empty.

** Dataset tables (populated via Data Librarian)

These tables are *NOT copied* during tenant provisioning. Instead, they are
populated via the dataset library using the "Publish Datasets" feature in the
Data Librarian window:

| Table                                        | Description                    |
|----------------------------------------------+--------------------------------|
| =ores_refdata_currencies_tbl=                | ISO currencies                 |
| =ores_refdata_countries_tbl=                 | ISO countries                  |
| =ores_refdata_business_centres_tbl=          | Business/trading centres       |
| =ores_refdata_account_types_tbl=             | Account type codes             |
| =ores_refdata_asset_classes_tbl=             | Asset class codes              |
| =ores_refdata_asset_measures_tbl=            | Asset measure codes            |
| =ores_refdata_benchmark_rates_tbl=           | Benchmark rate codes           |
| =ores_refdata_business_processes_tbl=        | Business process codes         |
| =ores_refdata_cashflow_types_tbl=            | Cashflow type codes            |
| =ores_refdata_entity_classifications_tbl=    | Entity classification codes    |
| =ores_refdata_local_jurisdictions_tbl=       | Local jurisdiction codes       |
| =ores_refdata_party_relationships_tbl=       | Party relationship codes       |
| =ores_refdata_party_roles_tbl=               | Party role codes               |
| =ores_refdata_person_roles_tbl=              | Person role codes              |
| =ores_refdata_regulatory_corporate_sectors_tbl= | Regulatory sector codes     |
| =ores_refdata_reporting_regimes_tbl=         | Reporting regime codes         |
| =ores_refdata_supervisory_bodies_tbl=        | Supervisory body codes         |
| =ores_assets_images_tbl=                     | Image assets (flags, icons)    |

Dataset tables flow: DQ artefact tables → Publish → Production (refdata) tables.

** Tenant-specific tables (empty for new tenants)

These tables start empty for new tenants and are populated by user actions:

| Table                          | Description                              |
|--------------------------------+------------------------------------------|
| =ores_iam_accounts_tbl=        | User accounts                            |
| =ores_iam_account_roles_tbl=   | User-role assignments                    |
| =ores_iam_sessions_tbl=        | User sessions                            |
| =ores_iam_login_info_tbl=      | Login tracking                           |
| All =ores_dq_*_tbl= tables     | Data quality/governance metadata         |

** Implications for provisioning

When implementing tenant provisioning:
1. Copy only *system IAM tables* (permissions, roles, role_permissions)
2. Do NOT copy refdata tables - tenants publish their own datasets
3. Tenant-specific tables start empty

When implementing tenant deprovisioning:
1. Use dynamic table discovery to clean up ALL tenant data
2. Soft-delete temporal tables (set =valid_to= to current timestamp)
3. Hard-delete non-temporal tables

* Integration with Domain Type Creator

When creating a new domain type using the [[id:b1450696-8c51-4cc5-8910-84912a411ab6][Domain Type Creator]] skill, the SQL
schema creation is typically done as part of Step 5 (Create repository entity
and mapper). Use this skill to:

1. Create the table definition matching the entity structure
2. Add appropriate triggers for versioning and notifications
3. Update orchestration scripts
4. Add any reference data population
5. Ensure the C++ entity =tablename= matches the SQL table name

* Artefacts                                                        :noexport:

** Licence

#+BEGIN_SRC fundamental :tangle LICENCE.txt
This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program; if not, write to the Free Software
Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
MA 02110-1301, USA.
#+END_SRC
